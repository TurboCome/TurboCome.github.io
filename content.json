{"meta":{"title":"TurboCome","subtitle":"Wang Hongqiang","description":"淡泊明志，宁静致远","author":"TurboCome","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2022-03-29T12:33:50.000Z","updated":"2022-03-30T12:47:48.008Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2022-04-05T06:47:56.000Z","updated":"2022-04-05T06:48:34.205Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-03-29T12:38:52.000Z","updated":"2022-04-04T17:05:26.037Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"repository","date":"2022-04-05T04:27:05.000Z","updated":"2022-04-05T04:52:06.952Z","comments":false,"path":"repository/index.html","permalink":"http://example.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"数组小和","slug":"Y-LeetCode/A-排序算法/4.数组小和","date":"2022-04-20T01:55:19.000Z","updated":"2022-04-20T01:57:52.664Z","comments":true,"path":"2022/04/20/Y-LeetCode/A-排序算法/4.数组小和/","link":"","permalink":"http://example.com/2022/04/20/Y-LeetCode/A-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/4.%E6%95%B0%E7%BB%84%E5%B0%8F%E5%92%8C/","excerpt":"","text":"归并排序类型题（美团实习二面原题） 数组小和 定义如下：给定一个数组 s，实现 函数返回 s 的小和 例如： 数组s&#x3D;[1,3,5,2,4,6] s[0] 左边 &lt; &#x3D; s[0]的数的和为0， s[1]左边 &lt;&#x3D; s[1] 的数的和为1， s[2]左边 &lt;&#x3D; s[2]的数的和为1+3&#x3D;4， s[3]左边 &lt;&#x3D; s[3]的数的和为1， s[4]左边 &lt;&#x3D; s[4]的数的和为1+3+2&#x3D;6， s[5]左边 &lt;&#x3D; s[5]的数的和为1+3+5+2+4&#x3D;15， 所以s 小和为 0+1+4+1+6+15&#x3D;27 In: arr&#x3D;[1, 3, 5, 2, 4, 6] Out: 27 要求：时间复杂度O( NlogN)，额外空间复杂度O(N) 123456789101112131415161718192021222324252627282930313233343536public static int smallSum2(int[] arr)&#123; if(arr==null || arr.length==0) return 0; return func(arr, 0, arr.length-1); //归并排序&#125;private static int func(int[] s, int l, int r) &#123; if(l==r) return 0; int mid=(l+r)/2; //归并排序的过程会进行拆组再合并，即：拆左组，拆右组，合并左右组 return func(s,l,mid) +func(s, mid+1,r) + merge(s, l,mid,r);&#125;private static int merge(int[] s, int left, int mid, int right) &#123; int[] h = new int[right-left+1]; int hi=0; // h 的首位 int i= left; // 左组首位 int j= mid+1; // 右组首位 int sum= 0; while( i&lt;=mid &amp;&amp; j&lt;=right)&#123; if( s[i]&lt;=s[j])&#123; sum += s[i]*(right-j+1);//生成小和 h[hi++] =s[i++]; //左组动 &#125; else h[hi++]=s[j++]; //右组动 &#125; for( ; (j&lt;right+1)||(i&lt;mid+1); j++,i++)&#123; h[hi++]= i&gt;mid? s[j]:s[i]; //左右组合成h &#125; for(int k=0; k!=h.length; k++) s[left++]=h[k]; // 合成s return sum;&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"排序","slug":"LeetCode/排序","permalink":"http://example.com/categories/LeetCode/%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"01背包--目标和_494","slug":"Y-LeetCode/D-动态规划/2.0-1背包-目标和_494","date":"2022-04-20T01:55:19.000Z","updated":"2022-04-20T02:56:51.054Z","comments":true,"path":"2022/04/20/Y-LeetCode/D-动态规划/2.0-1背包-目标和_494/","link":"","permalink":"http://example.com/2022/04/20/Y-LeetCode/D-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/2.0-1%E8%83%8C%E5%8C%85-%E7%9B%AE%E6%A0%87%E5%92%8C_494/","excerpt":"","text":"给定一个非负整数数组 { a1, a2, …, an } 和一个目标数 S, 现有两个符号 + 和 - , 对于数组中的任意一个整数，可以从 + 或 - 中选择一个符号添加在前面。返回可以使最终数组和 为目标数 S 的所有 添加符号的方法数 输入：nums: [1, 1, 1, 1, 1], S: 3 ； 不一定都是 1输出：5解释： -1+1+1+1+1 &#x3D; 3 +1-1+1+1+1 &#x3D; 3 +1+1-1+1+1 &#x3D; 3 +1+1+1-1+1 &#x3D; 3 +1+1+1+1-1 &#x3D; 3一共有5种方法让最终目标和为 3 思路：换种理解方式：就是从数组中挑出一部分数，作为正数，其余数为负，使其加和为S的所有方案关键是这个选出哪些数作为正数呢？设选出 正数的所有数求和 x ， 选出负数的所有数求和 y （不计符号）x + y &#x3D; sum ( 数组中所有元素和 )x - y &#x3D; Sx &#x3D; (sum + S ) &#x2F; 2之后此题便转化为一个 0-1背包问题； 即：装满背包容量X 的条件下，有多少种方案 设 dp(i)(j)表示在 数组中元素个数为 i 的条件下，背包容量为 j 的所有方案第 i 个元素 有 2中可能 &#x3D; 不选 + 选dp(i)(j)&#x3D;dp(i-1)(j)+dp(i-1)(j-nums[i]) 123456789101112131415161718public int findTargetSumWays(int[] nums, int S) &#123; int sum=0; for(int v: nums) sum +=v; if( (sum+S)%2!=0 ) return 0; if( S&gt;sum) return 0; int W = (sum+S)/2; int[][] dp=new int[nums.length+1][ W+1]; dp[0][0] = 1; for(int i=1;i&lt;=nums.length;i++)&#123; for(int j=0;j&lt;=W;j++)&#123; if(j&lt; nums[i-1]) dp[i][j] = dp[i-1][j]; else dp[i][j] = dp[i-1][j] + dp[i-1][j-nums[i-1]]; &#125; &#125; return dp[nums.length][W];&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"动态规划","slug":"LeetCode/动态规划","permalink":"http://example.com/categories/LeetCode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"剑指 Offer 57 - II.和为s的连续正数序列","slug":"Y-LeetCode/B-滑动窗口/3.剑指 Offer 57 - II. 和为s的连续正数序列","date":"2022-04-20T01:55:19.000Z","updated":"2022-04-20T02:19:31.787Z","comments":true,"path":"2022/04/20/Y-LeetCode/B-滑动窗口/3.剑指 Offer 57 - II. 和为s的连续正数序列/","link":"","permalink":"http://example.com/2022/04/20/Y-LeetCode/B-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/3.%E5%89%91%E6%8C%87%20Offer%2057%20-%20II.%20%E5%92%8C%E4%B8%BAs%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97/","excerpt":"","text":"输入一个 正整数 target ，输出 所有和为 target 的 连续 ***正整数序列*（至少含有两个数） 序列内的 数字由小到大排列，不同序列按照首个数字从小到大排列 输入：target &#x3D; 9 输出：[[2,3,4],[4,5]] 输入：target &#x3D; 15 输出：[[1,2,3,4,5],[4,5,6],[7,8]] 思路： 当窗口的和 &lt; target 时: 右边界向右移动 ，增加 当窗口的和 &gt; target 时: 左边界向右移动 ，减少 当窗口的和 &#x3D;&#x3D; target 时， 记录结果 1234567891011121314151617181920212223public List&lt;List&lt;Integer&gt;&gt; findContinuousSequence(int target) &#123; int l = 1, r=1; int sum=0; List&lt; List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); while(l &lt;= target/2 )&#123; if(sum&lt;target)&#123; sum+=r; r++; &#125;else if(sum&gt;target)&#123; sum-=l; l++; &#125;else&#123; List&lt;Integer&gt; tmp = new ArrayList&lt;&gt;(); for(int k=l; k&lt;r; k++) tmp.add(k); res.add(tmp); // 左边界继续右移，仍要继续前进 sum-=l; l++; &#125; &#125; return res;&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"滑动窗口","slug":"LeetCode/滑动窗口","permalink":"http://example.com/categories/LeetCode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}]},{"title":"最小覆盖子串_76","slug":"Y-LeetCode/B-滑动窗口/4.最小覆盖子串_76","date":"2022-04-20T01:55:19.000Z","updated":"2022-04-20T02:25:56.856Z","comments":true,"path":"2022/04/20/Y-LeetCode/B-滑动窗口/4.最小覆盖子串_76/","link":"","permalink":"http://example.com/2022/04/20/Y-LeetCode/B-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/4.%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2_76/","excerpt":"","text":"一个字符串 s , 一个字符串 t ， 返回 s 中 涵盖 t 所有字符的最小子串? 如果 s 中 不存在涵盖 t 所有字符的子串，则返回空字符串 “” 注意：如果 s 中存在这样的子串，保证它是唯一的答案。 输入：s &#x3D; “ADOBECODEBANC”, t &#x3D; “ABC” 输出：”BANC” 输入：s &#x3D; “a”, t &#x3D; “a” 输出：”a” 提示： 1 &lt;&#x3D; s.length, t.length &lt;&#x3D; 105 s 和 t 由英文字母组成 思路：左右指针，依次截取判断是否包含。 1234567891011121314151617181920212223242526272829303132333435363738public String minWindow(String s, String t) &#123; if( s.length() &lt; t.length() ) return &quot;&quot;; Map&lt;Character,Integer&gt; map_test = new HashMap&lt;&gt;(); Map&lt;Character,Integer&gt; map = new HashMap&lt;&gt;(); for(char c: t.toCharArray()) map_test.put( c, map_test.getOrDefault(c,0)+1); String res=&quot;&quot;; int l=0, len=Integer.MAX_VALUE; for(int r=0; r&lt; s.length(); r++)&#123; char c = s.charAt(r); // 包括的话，就添加进来 if( map_test.containsKey(c)) map.put(c, map.getOrDefault(c,0)+1); while( l&lt;=r &amp;&amp; check(map_test, map) )&#123; if(len&gt; r-l+1)&#123; res= s.substring(l, r+1); len = r-l+1; &#125; // 内部缩减， 左指针前移 if(map_test.containsKey(s.charAt(l))) map.put(s.charAt(l), map.getOrDefault( s.charAt(l),0)-1 ); l++; // 可以考虑使用 map&lt;v, id&gt; 优化 &#125; &#125; return res;&#125;private boolean check(Map&lt;Character, Integer&gt; map_test, Map&lt;Character, Integer&gt; map) &#123; for( Map.Entry&lt;Character,Integer&gt; it: map_test.entrySet())&#123; char key = it.getKey(); int value = it.getValue(); if(map.getOrDefault(key, 0)&lt; value) return false; &#125; return true;&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"滑动窗口","slug":"LeetCode/滑动窗口","permalink":"http://example.com/categories/LeetCode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}],"tags":[{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}]},{"title":"二叉树路径总和-112-113-437","slug":"Y-LeetCode/C-递归/2.二叉树路径总和_112_113_437","date":"2022-04-20T01:55:19.000Z","updated":"2022-04-20T02:36:36.822Z","comments":true,"path":"2022/04/20/Y-LeetCode/C-递归/2.二叉树路径总和_112_113_437/","link":"","permalink":"http://example.com/2022/04/20/Y-LeetCode/C-%E9%80%92%E5%BD%92/2.%E4%BA%8C%E5%8F%89%E6%A0%91%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C_112_113_437/","excerpt":"","text":"给定一个二叉树和一个 目标和，判断该树中 是否存在 根节点到叶子节点的路径，这条路径上所有节点值 相加等于目标和说明: 叶子节点是指没有 子节点的节点。 示例:给定如下二叉树，以及目标和 sum &#x3D; 22， ​ 5 ​ &#x2F; \\ ​ 4 8 ​ &#x2F; &#x2F; \\ ​ 11 13 4 ​ &#x2F; \\ \\ ​ 7 2 1 {5,4,8,11,null, 13, 4, 7, 2, null, 1} 返回 true, 因为存在目标和为 22 的根节点到叶子节点的路径 5-&gt;4-&gt;11-&gt;2 123456// 递归public boolean hasPathSum(TreeNode root, int sum) &#123; if(root==null) return false; else if(root.left==null &amp;&amp; root.right==null &amp;&amp; sum-root.val==0) return true; else return hasPathSum(root.left, sum-root.val) || hasPathSum(root.right, sum-root.val);&#125; 给定一个二叉树和一个目标和，找到所有从 根节点到 叶子节点路径总和 &#x3D;&#x3D;给定目标和的路径说明: 叶子节点是指没有子节点的节点。 示例:给定如下二叉树，以及目标和 sum &#x3D; 22， ​ 5​ &#x2F; ​ 4 8​ &#x2F; \\ &#x2F; \\​ 11 N 13 4​ &#x2F; \\ &#x2F; \\ &#x2F;\\ &#x2F;​ 7 2 N N N N 5 1 {5,4,8, 11, null, 13, 4, 7,2, null, null,null, null, 5,1} 返回: [ [5,4,11,2], [5,8,4,5] ] 12345678910111213141516171819202122List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; List&lt;Integer&gt; item = new ArrayList&lt;&gt;(); pathSum(root, sum, item); return res;&#125;private void pathSum(TreeNode root, int sum, List&lt;Integer&gt; item) &#123; if(root==null) return ; item.add(root.val); if(root.left==null &amp;&amp; root.right==null &amp;&amp; sum-root.val==0)&#123; res.add( new ArrayList(item) ); // 一定要重新赋值，注意深浅copy //此处不要 return; 会导致item中末尾节点没有删除 &#125; // 此处 不能放在 else 中，否则在 添加满足条件后，无法将最后一个元素删除： 回溯 pathSum(root.left, sum-root.val, item); pathSum(root.right, sum-root.val, item); item.remove(item.size()-1); // 回溯&#125; 437.链接：https://leetcode-cn.com/problems/path-sum-iii二叉树的每个结点都存放着一个整数值, 找出 路径和 等于 给定数值的路径总数路径不需要从根节点开始，也不需要在叶子节点结束，但是路径方向必须是向下的（只能从父节点到子节点）。 root &#x3D; [10,5,-3,3,2,null,11,3,-2,null,1] , sum &#x3D; 8 10 / \\ 5 -3 / \\ / \\ 3 2 N 11 / \\ / \\ 3 -2 N 1 {10,5,-3,3,2,null,11,3,-2,null,1} 返回 3和等于 8 的路径有: 5 -&gt; 3 5 -&gt; 2 -&gt; 1 -3 -&gt; 11 思路：1.以当前节点为起始，dfs深搜遍历左右几点，找到所有sum&#x3D;target2.递归遍历root.left ; root.right 1234567891011121314151617int res = 0;public int pathSum(TreeNode root, int sum) &#123; if(root==null) return 0; dfs(root, sum); //加入 root 节点 // 不加入root 节点 pathSum(root.left, sum); pathSum(root.right, sum); return res;&#125;public void dfs(TreeNode root, int sum)&#123; if(root==null) return ; if(sum-root.val==0) res++; dfs(root.left, sum-root.val); dfs(root.right, sum-root.val);&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"递归","slug":"LeetCode/递归","permalink":"http://example.com/categories/LeetCode/%E9%80%92%E5%BD%92/"}],"tags":[{"name":"递归","slug":"递归","permalink":"http://example.com/tags/%E9%80%92%E5%BD%92/"}]},{"title":"防止怠慢，经常自勉","slug":"Z-随笔/自勉","date":"2022-04-19T13:55:19.000Z","updated":"2022-04-19T13:31:01.550Z","comments":true,"path":"2022/04/19/Z-随笔/自勉/","link":"","permalink":"http://example.com/2022/04/19/Z-%E9%9A%8F%E7%AC%94/%E8%87%AA%E5%8B%89/","excerpt":"","text":"防止怠慢，经常自勉 不受些挫，永远不知道自己有多差劲！ 你已不再年轻，请别把自己当作一个孩子了！ 做什么事情，请用心去做，不是什么事都那么随便就可以成功的！ 以后的路还很长，你需要走的路还很远，我不希望看到一个这样的你！ 这一路走来容易么？你经历了什么？你得到了什么？你想要什么？ 不要那么鲁莽，生活终究会为你的粗心而付出代价！ 有些时候，原谅自己就是在纵容自己，有些错误，不值得原谅！ 平平淡淡是一生，风风雨雨是一生，常问一下自己，这是你想要的生活吗？这是你想要的人生吗？ 要有自己的梦想，你的潜力不止于此！ 抱怨没有任何意义，那是曾经！我要的是未来！ 经常总结经验，失败并不可怕，但一定要有所成长！ 今天的怠慢在以后一定会让你加倍偿还！","categories":[{"name":"随笔","slug":"随笔","permalink":"http://example.com/categories/%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://example.com/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"快速排序","slug":"Y-LeetCode/A-排序算法/2.快速排序","date":"2022-04-19T13:55:19.000Z","updated":"2022-04-20T01:56:34.456Z","comments":true,"path":"2022/04/19/Y-LeetCode/A-排序算法/2.快速排序/","link":"","permalink":"http://example.com/2022/04/19/Y-LeetCode/A-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/2.%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","excerpt":"","text":"思路： 取第一个元素，右–&gt;左：直到碰到&lt; 赋值给左； 再 左–&gt;右：直到碰到&gt; 赋值给右； 一次遍历完划分左右 2部分 12345678910111213141516171819public static void quick_sort(int[] nums, int l, int r)&#123; if(l&gt;=r) return ; // 终止条件 // 不对数组进行截取时，要定义 起止下标 int high=r, low=l; int base=nums[l]; while(l&lt;r)&#123; while(l&lt;r &amp;&amp; base&lt;=nums[r]) r--; nums[l]=nums[r]; while(l&lt;r &amp;&amp; base&gt;nums[l]) l++; nums[r]=nums[l]; &#125; nums[l]=base; // 分支递归 quick_sort(nums,low,l-1); quick_sort(nums,l+1,high);&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"排序","slug":"LeetCode/排序","permalink":"http://example.com/categories/LeetCode/%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"堆排序算法","slug":"Y-LeetCode/A-排序算法/3.堆排序","date":"2022-04-19T13:55:19.000Z","updated":"2022-04-19T13:50:44.370Z","comments":true,"path":"2022/04/19/Y-LeetCode/A-排序算法/3.堆排序/","link":"","permalink":"http://example.com/2022/04/19/Y-LeetCode/A-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/3.%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"堆排序算法：123456789101112131415161718192021222324252627282930313233343536public static void swap(int arr[] ,int i, int j)&#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp;&#125;// 以 i 作为节点时， 进行的左 右子树的调整public static void heapify(int[] arr, int i, int len)&#123; int l= 2*i+1; int r= 2*i+2; int base = i; if(l&lt;len &amp;&amp; arr[base]&lt;arr[l]) base=l; if(r&lt;len &amp;&amp; arr[base]&lt;arr[r]) base=r; if(base!= i)&#123; swap(arr, i, base); heapify(arr, base, len); &#125;&#125;public static int[] heap_sort(int[] arr)&#123; int len=arr.length; int parent = (len-1)/2; //最后一个节点的父节点 // 建堆 for(int i=parent; i&gt;=0; i--)&#123; heapify(arr, i, len); &#125; // 排序 for(int i=len-1; i&gt;=0;i--)&#123; swap(arr,0, i); heapify(arr, 0, i); &#125; return arr;&#125; 类型题： 查找第K大的数 123456789101112131415public static int find_K_nums(int[] nums, int K)&#123; int len=nums.length; int parent=(len-1)/2; for(int i=parent; i&gt;=0; i--)&#123; heapify(nums, i, len); &#125; int res=nums[0]; for(int i=len-1; i&gt;len-K; i--)&#123; swap(nums, 0, i); heapify(nums, 0, i); res = nums[0]; &#125; return res;&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"排序","slug":"LeetCode/排序","permalink":"http://example.com/categories/LeetCode/%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"MySQL优化实践","slug":"B-数据库/Mysql/A5-MySQL优化实践","date":"2022-04-13T13:55:19.000Z","updated":"2022-04-19T13:05:26.808Z","comments":true,"path":"2022/04/13/B-数据库/Mysql/A5-MySQL优化实践/","link":"","permalink":"http://example.com/2022/04/13/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/A5-MySQL%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"MySQL优化实践1.大数据量拆分：123update coupons set status = 1 where status= 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59&#x27;; 问题： 一个 SQL只能使用一个 cpu core去处理，如果 SQL很复杂或执行很慢，就会阻塞后面的 SQL请求，造成活动连接数暴增，MySQL CPU 100%，相应的接口Timeout，同时对于主从复制架构，做了业务读写分离，更新500w数据需要5分钟，Master上执行了5分钟，binlog传到了slave也需要执行5分钟，那就是Slave延迟5分钟，在这期间会造成 业务脏数据，比如重复下单等。1.先获取 where 条件中的 最小id ，最大id，2.然后 分批次去更新，每个批次 1000条，这样既能快速完成更新，又能保证 主从复制不会出现延迟 先获取要更新的 数据范围内的 最小id和最大id（表没有物理delete，所以id是连续的） 1234567891011select min(id) min_id, max(id) max_id from coupons where status=0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59’; current_id = min_id;for current_id &lt; max_id do update coupons set status=1 where id&gt;= current_id and id&lt;= current_id + 1000; //通过主键id更新1000条很快commit;current_id += 1000;done 充分利用 辅助索引包含主键id的特性，先通过索引获取主键 id走覆盖索引扫描，不需要回表，然后再通过id去关联操作是高效的，同时根据 MySQL的特性 使用分而治之的思想既能高效完成操作，又能避免主从复制延迟产生的业务数据混乱。 2.分解多表连接：例如，使用 IN() 代替连接查询（in 等价于等值查询）可排序，让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效 12345678SELECT * FROM tag JOIN tag_post ON tag_post.tag_id= tag.id JOIN post ON tag_post.post_id= post.id WHERE tag.tag=&#x27;mysql’;SELECT * FROM tag WHERE tag=&#x27;mysql&#x27;; --&gt; tag_id = 1234SELECT * FROM tag_post WHERE tag_id=1234; —&gt; (123,456,567,9098,8904)SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904); 3.MRR优化：应用实例一：（mysql优化器改变where 条件顺序—&gt;匹配联合索引） 1SELECT * FROM t WHERE key_part1&gt;=1000 and key_part1&lt;2000 AND key_part2=1000; 表 t 有 ( key_part1, key_part2 ) 的联合索引 ，因此索引根据 key_part1, key_part2 的位置关系进行排序。没有MRR：SQL优化器会先将 key_part1&gt;1000 and key_part2&lt;2000 的数据查询出来，待取出的数据后，再根据key_part2的条件进行过滤。这会导致无用的数据被取出，如果有大量的数据是 key_part2 !&#x3D;1000，则启用MRR优化会使性能有巨大的提升.启用MRR优化：优化器会先 将查询条件进行拆分，然后在进行数据查询。优化器会将查询条件拆分为(1000,1000),(1001,1000),(1002,1000),…,(1999,1000)，然后在根据这些拆分出的条件，使用索引下推进行数据查询，避免回表。 应用实例二： 在没有MRR之前,或没有开启 MRR特性时，MySQL 针对基于辅助索引的查询策略是这样的： 12select non_key_column from tb where key_column=x; MySQL 执行查询的伪代码第一步 先根据 where 条件中的 辅助索引，获取辅助索引与主键的集合，结果集为 rest 12select key_column, pk_column from tb where key_column=x order by key_column 第二步 通过第一步获取的主键来获取 对应的值 12for each pk_column value in rest do:select non_key_column from tb where pk_column=val 由于MySQL存储数据的方式： 辅助索引的存储顺序并非与主键的顺序一致，从图中可以看出,根据辅助索引获取的主键来访问表中的数据会导致随机的IO . 不同主键不在同一个page 里面时必然导致多次IO 和随机读。在使用 MRR优化特性的情况下，MySQL 针对基于辅助索引的查询策略是这样的：第一步 先根据 where条件中的辅助索引获取辅助索引与主键的集合，结果集为rest 1select key_column, pk_column from tb where key_column = x order by key_column 第二步 将结果集rest 放在buffer里面(read_rnd_buffer_size 大小直到buffer满了)，然后对结果集 rest按照pk_column排序，得到结果集是rest_sort第三步 利用已经排序过的结果集，访问表中的数据，此时是顺序IO. 1select non_key_column fromtb where pk_column in ( rest_sort ) ​ 从图示MRR原理，MySQL 将根据 辅助索引获取的结果集根据主键进行排序，将乱序化为有序，可以用-主键顺序访问基表，将随机读转化为顺序读，多页数据记录可一次性读入或 根据此次的主键范围分次读入，以减少IO操作，提高查询效率。MRR的使用与否，是由 MySQL中的开关控制，只要设置开启，它会自动在 read_rnd_buffer_size 缓冲区 内，对primaryKey进行排序。但这个开关并不是一直开着，因为对于 大多数的单条查询，重新在中间添加一步排序，是对性能的损失，没有必要。所以Mysql 中还有一个 mrr_cost_based 开关，如果设置关闭，则完全按照 mrr 开关来执行了；如果设为开启，MySQL的优化器会通过 CBO算法确定是否开启MRR特性（进行对 primaryKey的排序）​ mrr&#x3D;{on|off}​ mrr_cost_based&#x3D;{on|off} 4.大数据量下分页查询 limit offset, batchSize:12345select * from trade_info where status = 0 and create_time &gt;= &#x27;2020-10-01 00:00:00&#x27; and create_time &lt;= &#x27;2020-10-07 23:59:59’ order by id desc limit 102120, 20; 表 trade_info 上有索引 idx_status_create_time(status, create_time); 等价于索引（status, create_time,id)对于典型的 分页 limit m, n来说，越往后翻页越慢( m越大会越慢); 因为要 定位 m位置需要扫描的数据越来越多，导致IO开销比较大。这里可以利用 辅助索引的覆盖扫描来进行优化，先获取id，这一步就是 索引覆盖扫描，不需要回表，然后通过 id 跟原表 trade_info进行关联&#x2F;&#x2F; 改写后的SQL如下： 1234567select * from trade_info a , (select id from trade_info where status = 0 and create_time &gt;=&#x27;2020-10-01 00:00:00&#x27; and create_time &lt;=&#x27;2020-10-07 23:59:59’ order by id desc limit 102120, 20) as b -- 这一步走的是索引覆盖扫描，不需要回表 where a.id = b.id; 问题： 分页查询时，MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回 N 行，而且在取offset+N 行数据时，因为是select * … 的操作，所以是需要回表的，查询到索引叶子节点数据，根据叶子节点上的主键值去聚簇索引上查询需要的全部字段值。那当 offset 特别大的时候，此时使用 limit m,n 效率就非常的低下，因为回表了 M 行无用的数据，并且占用了大量的 buffer pool 缓存。 解决方案:1.控制返回的总页数；2.对超过特定阈值的页数进行 SQL 改写SELECT a.* FROM USER a INNER JOIN (SELECT id FROM USER WHERE age &#x3D; 10 LIMIT 100000,10) b ON a.id &#x3D; b.id; 结果0.53s需要对 where条件增加索引，id 因为是主键自带索引，select返回减少回表可以提升查询性能, 所以采用查询主键字段后进行关联大幅度提升了查询效率。3.使用Redis 来保存lastMaxtId, 下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。 常见慢查询问题： 1.确定主键，索引字段，将它们作为查询条件2.数据量过大，使用 limit 做分页处理， limit 起始id, 条数count3.当 limit 起始行数很大时， 查询效率会降低， 可以考虑使用自增 id 123Select *. From table limit 150000 , 5000优化： Select * from table where id&gt;150000 and id&lt;200000; -- 速度会有提升 4.数据导入，可尝试批量导入数据 ；性能：Load &gt; insert.load 只操作一次，之后数据 批量插入insert 每个数据操作一次，’就要遍历 一次字段索引","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"TCP/UDP/Http","slug":"E-网络/2.TCP-UDP-Http知识点","date":"2022-04-10T13:55:19.000Z","updated":"2022-04-19T13:04:25.708Z","comments":true,"path":"2022/04/10/E-网络/2.TCP-UDP-Http知识点/","link":"","permalink":"http://example.com/2022/04/10/E-%E7%BD%91%E7%BB%9C/2.TCP-UDP-Http%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"TCP&#x2F;UDP&#x2F;Httphttp 中的长，短链接：​ 在 HTTP&#x2F;1.0中 默认短连接，客户端和 服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就 中断连接。当客户端浏览器访问某个Web页中包含有其他的 Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 ​ 从HTTP&#x2F;1.1起，默认长连接，用以 保持连接特性。使用长连接的 HTTP协议，会在 响应头加入这行代码：Connection:keep-alive；使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间 用于传输 HTTP数据的 TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，有一个保持时间，可以设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP 协议的长，短连接，实质上是 TCP协议的长，短连接。http 长连接：设置 connection 为 keep-alive ；在 header 中有个超时时间，超过此时间就断开长连接长连接： 多个 http 请求复用同一个 TCP ； 频繁通信短链接： 一个 http 用一个 TCP； 长时间不通信，创建，关闭都会浪费时间 长优点： 省去较多的 TCP建立和关闭操作，减少浪费，节约时间，对于 频繁请求资源的客户端较适合短优点： 管理起来简单，存在的连接都是有用的连接，不需要额外的控制手段 像 Web 网站的 http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像 web网站有大量的客户端连接 用 短连接会省一些资源，如果用长连接，同时有成千上万的用户，每个 用户都占用一个连接的话，并发量很大，资源消耗很大； 而且每个用户无需频繁操作。 浏览器中输入一个网址 url，执行过程：1.应用层：浏览器看是否有缓存（浏览器，本地）; 没有则通过 DNS 解析，将 域名 转成其所对应的 服务器 ip地址，确定从浏览器到服务器的一条路径2.传输层：将 http 会话通过 TCP 协议封装成数据包，在 源，目的端添加 对应的端口号, 来保证端到端的可靠传输3.网络层：通过 IP 协议，查找 路由表，确定如何路由线路，到达服务器4.数据链路层： 通过 邻居发现协议 ND， 查找到 给定 IP 地址的 mac 地址，发送 ARP 请求查找目的地址5.物理层：将 ip 数据包转换成比特流，在物理链路上传输 Web 页面请求过程：1.浏览器进行DNS域名解析，得到对应的IP地址2.根据这个IP，找到对应的服务器，建立连接（三次握手）3.建立TCP连接后发起 HTTP请求（一个完整的 http请求报文）4.服务器响应HTTP请求，浏览器得到 html代码（服务器如何响应）5.浏览器解析 html代码，并请求 html代码中的资源（如js，css，图片等）6.浏览器对页面进行渲染呈现给用户7.服务器关闭 TCP连接（四次挥手） DNS解析1.首先会搜索浏览器自身的 DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存） 2.如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存 3.如果还没有找到，那么尝试从 hosts文件里面去找 4.在前面三个过程都没获取到的情况下，浏览器会发起一个DNS的系统调用，向本地配置的首选DNS服务器（一般是电信运营商提供）发起域名解析请求（通过 UDP协议向 DNS的 53端口发起请求，这个请求是递归的，就是要求运营商的DNS服务器必须提供给我们该域名的IP地址）DNS优化两个方面： DNS缓存, DNS负载均衡 TCP 与 UDP 区别：1.基于 TCP有连接； UDP 无连接；2.TCP数据正确性，可靠传输，无差错，不丢失，不重复，且按序到达； UDP可能丢包，不可靠传输，UDP 尽最大努力交付，即不保 证可靠交付 UDP没有拥塞控制，因此网络出现 拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）3.UDP 程序结构较简单，速度快，适合传输大数据； TCP 速度慢，适合小数据传输4.TCP面向字节流; UDP是面向报文的5.每一条 TCP连接只能是点到点的; UDP支持一对一，一对多，多对一和多对多的交互通信6.TCP首部开销 20字节; UDP的首部开销 8个字节7.TCP通信 信道是 全双工的可靠信道，UDP则是 不可靠信道 流量控制：点对点 让发送速率不要过快，使接收方来得及接收; 利用 滑动窗口机制就可以实施流量控制原理：运用 TCP报文段中的 窗口大小字段来控制，发送方的发送窗口不能 &gt; 接收方发回的窗口大小滑动窗口协议是传输层进行流控的一种措施，接收方告知发送方自己可以接受缓冲区大小（此字段越大–网络吞吐量越高），从而控制发送方的发送速度，如果接收端缓冲区面临数据溢出，窗口大小值会被设置一个更小的值通知给发送端，从而控制数据发送量（发送端根据接收端指示，进行流量控制） 拥塞控制：整个网络解决 过多的 数据注入到网络, 导致网络崩溃, 超过负荷, 拥塞控制包含四个策略防止过多的数据注入到网络中，导致网络中的 路由器或链路过载；发送方控制 拥塞窗口的原则是：只要网络 没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去； 但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 拥塞控制四个策略：1.慢开始：发送的最初执行慢开始，令 cwnd &#x3D; 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2,4,8 …； 慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;&#x3D; ssthresh 时，慢开始结束。 2.拥塞避免：慢开始结束后 是 拥塞避免, 此时拥塞窗口 每个传输轮次 + 1, 直到 触发网络拥塞；如果出现超时，则令 ssthresh &#x3D; cwnd &#x2F; 2，然后重新执行慢开始。 3.快重传：在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 快重传要求接收方在 收到一个失序的报文段后 ，立即发出重复确认，而 不是等到自己发送数据时 捎带确认；发送方只要一连收到三个重复确认ACK， 就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。4.快恢复：配合快重传使用，在收到三个重复确认ACK后，这种情况下只是丢失个别报文段，不是网络拥塞。因此执行快恢复，设ssthresh &#x3D; cwnd&#x2F;2 ，cwnd &#x3D; ssthresh，注意到此时直接进入 拥塞避免。 注意：在采用快恢复算法时，慢开始算法只是在 TCP连接建立时和网络出现超时时才使用 流量控制与拥塞控制 区别：相同点： 都会丢包；实现机制都是让发送方发的 慢一点，发的少一点； 提高网络性能不同点：1.丢包位置不同，流量控制丢包位置是在接收端上； 拥塞控制丢包：在路由器上2.作用对象不同：流量控制对象是 接收方，防止发送方发的太快，来不及接受； 拥塞控制对象是 网络，防止发送方发的太快，造成网络拥塞，超过网络负荷。3.联系：拥塞控制是一个全局性的过程，涉及网络中的所有主机，所有路由器，考虑网络负荷；流量控制是局部的，发生在端和端之间，是点到点的控制。 TCP三次握手： 客户端和 服务器建立的是可靠的 全双工连接：客户端：确定，服务器是可以接受，发送数据服务器：确定，客户端是可以接受，发送数据 第一次握手：建立连接时，客户端发送 syn包 (syn&#x3D;j)到服务器，并进入 SYN_SEND状态，等待服务器确认；此时对于服务器而言，服务器知道自己的 “接收”能力正常，客户端的 “发送”能力正常。第二次握手：服务器收到 syn包，确认客户 SYN（ack&#x3D;j+1），同时自己也发送一个SYN包(syn&#x3D;k)，即SYN+ACK包 ，此时服务器进入 SYN_RECV状态；此时对于客户端而言，客户端知道自己的“发送”能力正常；客户端的“接收”能力正常； 知道服务器的“发送”、“接收”能力正常此时对于服务器而言，服务器知道客户端“发送”能力正常，但客户端“接收”能力不确定，同时，服务器知道自己“接收”能力正常，但“发送”能力不确定 。第三次握手：客户端收到服务器SYN＋ACK包，向服务器发送确认包ACK(ack&#x3D;k+1)，发送完毕后客户端和服务器进入 ESTABLISHED状态，完成三次握手。此时对于服务器而言，服务器就能确定自己的“发送”能力正常，客户端的“接收”能力正常。通过这样的三次握手，双方都能确定自己和对方的收，发能力正常，客户端与 服务端建立起 可靠的双工的连接，开始传送数据。 TCP 协议为实现可靠传输， 通信双方需要判断自己已经发送的数据包是否都被接收方收到， 如果没收到， 就需要 重传。 为了实现这个需求，就涉及到 序号（sequence number） 和 确认号（acknowledgement number） 这2个概念 。序列号 seq：TCP 连接中传送的数据流中每一个字节都编上一个序号，序号字段的值是 本报文段所发送的数据的第一个字节的序号。确认号 ack：期望收到对方下一个报文段数据的第一个字节的序号。 四次挥手： 第一次：A 应用进程先向其 TCP发出连接释放报文段（FIN&#x3D;1，序号seq&#x3D;u），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。第二次：B 收到连接释放报文段后即发出确认报文段，（ACK&#x3D;1，确认号ack&#x3D;u+1，序号seq&#x3D;v），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。A 收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。此时客户端不再向服务器发送数据，服务器不再接受数据； 但服务器还会将没发送完的数据发给客户端，客户端可以继续接受服务器发来的数据。第三次：当B没有要发的数据时，释放报文段(FIN&#x3D;1，ACK&#x3D;1，序号seq&#x3D;w，确认号ack&#x3D;u+1)，B进入LAST-ACK最后确认状态，等待A确认。第四次：A收到B的连接释放报文段后，对此发出确认报文段(ACK&#x3D;1，seq&#x3D;u+1，ack&#x3D;w+1)，A进入 TIME-WAIT（时间等待）状态。此时 TCP未释放掉，需要 经过时间 等待计时器设置的时间 2MSL后，A才进入CLOSED状态。 为什么 A 在 TIME-WAIT状态等待 2MSL的时间？MSL 最长报文段寿命 Maximum Segment Lifetime，MSL&#x3D;21.避免B 服务端无法 closed 关闭；确保有足够时间让 服务器 收到 对方的 ACK 包，一来一去就是2MSL； TCP 可靠的，服务器在 2MSL 时间后没收到ACK 会超时重传 ；ACK 报文段可能丢失，使得处于LAST-ACK状态的B 收不到对已发送的 FIN+ACK报文段的确认，B 超时重传FIN+ACK报文段，而 A 能在 2MSL时间内收到这个重传的 FIN+ACK报文段，接着 A重传一次确认，重新启动 2MSL计时器，最后A和B都进入到CLOSED状态；若A在TIME-WAIT状态不等待一段时间，而是 发送完 ACK报文段后立即释放连接，则 无法收到 B重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则 B无法正常进入到CLOSED状态。 2.避免 新旧连接混: 即 不会跟后面的 新连接混淆； 防止“ 已失效的连接请求 报文段”出现在本连接中；A 在发送完最后一个 ACK报文段后，再经过 2MSL，可以使 本连接持续时间内所产生的所有报文段 都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 为什么连接时三次握手，关闭时四次握手？当 Server 端收到 Client 端的 SYN连接请求报文后，可以直接 发送SYN+ACK报文。其中 ACK报文是用来应答的，SYN报文是用来同步的但是关闭连接时，当 Server端收到FIN报文时，可能不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉 Client端，你发的FIN报文我收到。只有等到我 Server端所有的报文都发送完，我才能发送FIN报文，因此不能一起发送, 故需要四步握手。 SYN泛洪（SYN flood）攻击：​ 如果大量的握手请求涌向TCP服务端，而它们只发出SYN报文而不以ACK响应结束握手，服务端就要为这每一个请求都维持约一分多钟的连接去等待ACK，也就形成所谓的“半连接”。维护这些半连接是需要消耗很多服务器的网络连接资源的。如果短时间内这些资源几乎都被半连接占满，那么正常的业务请求在这期间就得不到服务，处于等待状态。如果这些半连接的握手请求是恶意程序发出，并且持续不断，那么就会导致服务端较长时间内丧失服务功能——这就形成了DoS（Denial of Service拒绝服务）攻击。 Http的方法：Get, post 是客户端和服务器端进行请求-响应的常用方法GET 请求： 获取资源1.可被 缓存2.保留在 浏览器历史记录中3.有长度限制；URL 的最大长度是 2048 个字符4.可被 收藏为书签5.数据在 URL 中对所有人都是可见的6.传输的表单在 url中 POST 请求： 传输实体主体1.不会被缓存2.不会保留在浏览器历史记录中3.没有对数据长度的限制4.不能 被收藏为书签5.数据不会显示在 URL 中6.传输的表单在request请求的 body中 HEAD： 获取报文首部 和GET方法类似，但服务器在响应中 只返回首部，不返回实体的主体部分；允许客户端在未获取实际资源情况下，对资源首部进行检查优点：1.在 不获取资源的情况下 了解资源（比如：判断其类型）；2.通过查看 响应的状态码，看看某个对象是否存在；3.通过查看首部，测试资源是否被修改 PUT： 上传文件由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法 HTTP 和 HTTPs 区别：HTTP 的请求过程：1.TCP 建立连接后，客户端会发送报文给服务端；2.服务端接收报文并作出响应；3.客户端收到响应后解析给用户；HTTP协议 不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信,非常不安全 HTTPS 在 HTTP 的基础上加入 SSL 层，HTTPS 的安全基础是 SSL，HTTPS 存在 不同于 HTTP 的默认端口和 一个加密&#x2F;身份验证层(在HTTP与 TCP之间）这个系统提供了 身份验证与加密通讯方法; 它被广泛用于万维网上安全敏感的通讯，例如交易支付等方面。 HTTPS的请求过程：1.客户端 发送请求到 服务端；2.服务器返回 数字证书（公钥，明文数据，签名，服务器域名）3.客户端 根据数字证书来验证服务器是不是自己要访问的（有效性），有效则随机生成对称加密的密钥X，并使用公钥加密密钥X，然后发送到服务端；4.服务端使用 私钥解密，得到 对称密钥X ； 后续使用密钥 X 对报文加密传输 数字证书：验证访问的 服务器网站是有效的，合法的签名： 验证 数字证书是有效的CA 机构对数字证书中的 明文数据，做 hash ，然后使用 私钥加密得到 签名 S浏览器收到 数字证书后，通过 公钥对签名 S 解密得到 T， 然后对 明文数据进行 hash 得到 T’ ；通过验证T&#x3D;&#x3D;T’ 来保证数字证书没有被篡改Hash 作用：证书信息一般较长，而 hash后得到固定长度的信息(比如用 md5算法hash后得到固定的 128位的值),这样加密，解密会快很多数字证书公钥： 操作系统，浏览器本身会预装一些它们信任的根证书，其中会有 CA机构的根证书，这样就可以拿到它对应的 可信公钥，不是每次请求都经历一次密钥传输过程：服务器 会为每个浏览器维护一个 session ID，浏览器生成好 密钥X传给服务器，服务器把该 密钥X存到相应的 session ID，之后 浏览器每次请求都会携带 session ID，服务器根据 session ID 找到相应的密钥进行解密，加密操作。 服务器端有个session ID 表，客户端第一次带着账户信息请求时，服务端查库，并产生一个 sessionID 返回给客户端，客户端之后请求时，会把 sessionID 放到cookie 中，携带cookie 请求，服务端通过校验sessionID，如果在sessionID表中，直接通过避免查库。 HTTPS 缺点：1.https协议是 多次握手，导致页面 加载时间延长近50%;2.https 连接 缓存不如HTTP高效，会 增加数据开销和功耗;3.申请SSL 证书需要钱，功能越强大的证书费用越高;4.SSL涉及到的安全算法会 消耗 CPU 资源，对服务器资源消耗较大 http 和 https 区别：1.https 是 http 协议的安全版本2.http 协议的 数据传输是明文的，是不安全的; https使用 SSL&#x2F;TLS 非对称加密协议进行加密处理， 是安全的3.http 和https 使用连接方式不同，默认端口不一样，http是80，https是4434.https协议对传输的数据进行加密，内容传输上使用对称加密，证书验证上使用非对称加密 Https整体过程分为证书验证和数据传输阶段： ​ 非对称加密的 加解密效率是 非常低的，而 http 应用场景中通常 端与端之间存在大量的交互，非对称加密的效率是无法接受的。在 https场景中只有 服务端保存私钥，一对公钥，私钥只能实现单向的加密和解密，所以https 中内容传输加密是 对称加密，证书验证是非对称加密。 常见的状态码： 301 永久重定向； 302 暂时重定向； 网站调整； 网页移到新地址； 扩展名改变 Cookie：HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP&#x2F;1.1 引入 Cookie 来保存状态信息。Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。 用途： 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） Session：​ 除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。 Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有用户信息都存储到 Session 中。# RPC 与http 区别：RPC ： 远程调用其他计算机服务，底层使用 TCP 传输协议； 指定数据传输格式，序列化方式相同点： 底层都是基于 socket 编程，使用 TCP 协议，实现远程调用，服务调用 服务不同：RPC ： 提供方，消费方 都使用 统一的RPC 框架（ dubbo）, 跨操作系统，同一编程语言内使用； 调用快，处理快，实现复杂HTTP： 跨操作系统，跨编程语言； 通用性强， 实现简单 区分 MSS 与 MTU：最大传输单元（Maximum Transmission Unit, MTU）， 最大报文段长度（Maximum Segment Size ，MSS）协议用来定义最大长度的MTU 应用于 数据链接层，并无具体针对的协议。 MTU限制数据链接层上可以传输的数据包的大小，也因此限制了上层（网络层）的数据包大小。例如，如果已知 某局域网的 MTU为1500字节，则在网络层的因特网协议（ IP）里最大数据包大小为 1500字节（包含IP协议头）。MSS 应用于 传输层的TCP协议，因为 MSS应用的协议在数据链接层的上层，MSS会受到MTU的限制 参考：https://zhuanlan.zhihu.com/p/161560683","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"请求代理服务器--加密","slug":"E-网络/3.代理服务器-加密","date":"2022-04-09T13:55:19.000Z","updated":"2022-04-19T13:04:31.389Z","comments":true,"path":"2022/04/09/E-网络/3.代理服务器-加密/","link":"","permalink":"http://example.com/2022/04/09/E-%E7%BD%91%E7%BB%9C/3.%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8-%E5%8A%A0%E5%AF%86/","excerpt":"","text":"请求代理服务器–加密代理服务器： 提供代理服务的电脑系统或其它类型的网络终端,代替网络用户去取得网络信息。 使用代理的主要目的： 缓存：提高访问速度，由于目标主机返回的数据会存放在代理服务器的硬盘中，因此下一次客户再访问相同的站点数据时，会直接从代理服务器的硬盘中读取，起到缓存的作用，尤其对于热门网站能明显提高访问速度。 网络访问控制：防火墙作用，由于所有的客户机请求都必须通过代理服务器访问远程站点，因此可以在代理服务器上设限，过滤掉某些不安全信息。同时正向代理中上网者可以隐藏自己的IP,免受攻击。 突破访问限制：互联网上有许多开发的代理服务器，客户机在访问受限时，可通过不受限的代理服务器访问目标站点，通俗说，我们使用的翻墙浏览器就是利用了代理服务器，可以直接访问外网。 负载均衡，通过配置后台各个服务器的权重参数，实现多机负载 正向代理的应用 访问原来无法访问的资源 用作缓存，加速访问速度 对客户端访问授权，上网进行认证 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 反向代理的应用 保护内网安全 负载均衡 缓存，减少服务器的压力 正向代理：一个位于客户端和原始服务器之间的服务器，为了从 原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后 代理向原始服务器转发请求并将获得的内容返回给客户端，客户端才能使用正向代理。我们平时说的代理就是指正向代理。 反向代理：以 代理服务器来接受internet上的连接请求，然后 将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。 正向&#x2F;反向区别：1.位置不同 正向代理，架设在客户机和目标主机之间； 反向代理，架设在服务器端； 2.代理对象不同 正向代理，代理客户端，服务端不知道实际发起请求的客户端； 反向代理，代理服务端，客户端不知道实际提供服务的服务端； 3.安全性不同 正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此必须采取安全措施以确保仅为授权的客户端提供服务； 反向代理都对外都是透明的，访问者并不知道自己访问的是哪一个代理。 加密技术:是对信息进行编码和解码的技术，编码是把原来可读信息（明文）译成代码形式（密文），其逆过程就是解码（解密），加密技术要点是加密算法，加密算法可分为三类： 对称加密，如AES：​ 基本原理：将明文分成N个组，然后使用密钥对各个组进行加密，形成各自的密文，最后把所有的分组密文进行合并，形成最终的密文。​ 优势：算法公开、计算量小、加密速度快、加密效率高​ 缺陷：双方都使用 同样密钥，安全性得不到保证 非对称加密，如RSA：​ 基本原理：同时生成两把密钥：私钥和公钥，私钥隐秘保存，公钥可以下发给信任客户端​ 私钥加密，持有 私钥、公钥才可以解密​ 公钥加密，持有 私钥才可解密​ 优点：安全，难以破解​ 缺点：算法比较耗时 不可逆加密，如MD5，SHA：​ 基本原理：加密过程中不需要使用密钥，输入明文后由系统直接经过加密算法处理成密文，这种加密后的数据是无法被解密的，无法根据密文推算出明文。 1.在没有RSA加密时：在微服务架构中，可以把服务的鉴权操作放到网关中，将未通过鉴权的请求直接拦截，如图： 1.用户请求登录2.Zuul将请求转发到授权中心，请求授权3.授权中心校验完成，颁发JWT凭证4.客户端请求其它功能，携带JWT5.Zuul将jwt交给授权中心校验，通过后放行6.用户请求到达微服务7.微服务将jwt交给鉴权中心，鉴权同时解析用户信息8.鉴权中心返回用户数据给微服务9.微服务处理请求，返回响应问题： 每次鉴权都需要访问鉴权中心，系统间的网络请求频率过高，效率略差，鉴权中心的压力较大。 2.在结合RSA的鉴权： 1.利用RSA生成公钥和私钥，私钥保存在授权中心，公钥保存在Zuul和各个信任的微服务2.用户请求登录3.授权中心校验，通过后用私钥对JWT进行签名加密4.返回jwt给用户5.用户携带JWT访问6.Zuul直接通过 公钥解密 JWT，进行验证，验证通过则放行7.请求到达微服务，微服务直接用公钥解析JWT，获取用户信息，无需访问授权中心","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络概述","slug":"E-网络/1.计算机网络概述","date":"2022-04-08T13:55:19.000Z","updated":"2022-04-19T13:04:20.210Z","comments":true,"path":"2022/04/08/E-网络/1.计算机网络概述/","link":"","permalink":"http://example.com/2022/04/08/E-%E7%BD%91%E7%BB%9C/1.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/","excerpt":"","text":"计算机网络概述：网络是把主机连接起来，互连网（internet）是把多种不同的网络连接起来。 主机之间的通信方式1.客户-服务器(C&#x2F;S)：客户是服务的请求方，服务器是服务的提供方 2.对等(P2P): 不区分客户和服务器 分组交换每台计算机通信时把数据包进行分组打包，只要在头部附上本机的信息和组号就可以多台计算机共用一条通信线路，这样就提高了通信线路的利用率。分组交换过程中发送端计算机发送给路由器，路由器会缓存这部分数据然后再转发给目标计算机。路由器不一定按照队列先进先出然后再发出去，也有可能优先发出一些特殊的数据。每个分组都有首部和尾部，包含源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互不影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。 网络传输时延： 总时延 &#x3D; 排队时延 + 处理时延 + 传输时延 + 传播时延 排队时延：分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。 处理时延：主机或路由器收到分组时进行处理所需要的时间；例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。 传输时延：主机或路由器传输数据帧所需要的时间。 4.传播时延：电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。 七层协议： 应用层 ：为特定 应用程序提供数据传输服务；例如 HTTP、DNS 等协议。数据单位：报文 表示层 ：数据压缩、加密以及数据描述，使应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 传输层 ：为进程提供通用数据传输服务。应用层协议很多，定义通用的传输层协议可以支持不断增多的应用层协议。传输层包括：TCP，UDP 网络层 ：为主机提供数据传输服务。传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 协议的层次、模型：OSI 七层模型：应用层： 允许有访问OSI 环境的手段，HTTP，FTP,DNS, SMTP, Telnet表示层： 对数据进行翻译，加密、压缩 JPEG，MPEG会话层： 建立，管理和终止会话 SQL， RPC传输层： 提供不同端系统的进程间通信 TCP，UDP网络层： 提供主机间的通信， IP， ICMP， ARP，数据链路层： 提供网络中点到点之间数据帧的传递PPP，MAC（网桥，交换机）物理层： 提供在物理介质上每一比特的传输 CLOCK， IEEE802.3（中继器，集线器，网关） Internet 五层模型：应用层： 将应用程序的 报文交给传输层传输层： 将接收的报文分段，封装TCP&#x2F;UDP头部信息，将报文段传递给网络层网络层： 将接收的报文段封装 IP头部信息，将数据报交给数据链路层数据链路层： 将接收网络层的数据报，封装数据帧头部信息，将数据帧从一个节点通过链路传到另一个节点物理层： 数据链路层负责将一个个数据帧从一点传递到另一点，物理层负责一个个比特从一点传递到另一点 应用层：HTTP、DNS 、FTP等协议 传输层： 两种协议传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层：IP 协议：根据路由表实现IP数据报的路由转发 数据链路层：信道分类： 广播信道： 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA&#x2F;CD 协议。 点对点信道： 一对一通信： 因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。 信道复用技术： 频分复用；时分复用；统计时分复用；波分复用；码分复用 MAC 地址：链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 交换机：有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。 地址解析协议 ARP网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。ARP 实现由 IP 地址得到 MAC 地址。 物理层：根据信息在传输线上的传送方向，分为以下三种通信方式：单工通信：单向传输；半双工通信：双向交替传输；全双工通信：双向同时传输","categories":[{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"SQL实践案例","slug":"B-数据库/Mysql/B2-SQL实践案例","date":"2022-03-15T13:55:19.000Z","updated":"2022-04-19T13:05:35.845Z","comments":true,"path":"2022/03/15/B-数据库/Mysql/B2-SQL实践案例/","link":"","permalink":"http://example.com/2022/03/15/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/B2-SQL%E5%AE%9E%E8%B7%B5%E6%A1%88%E4%BE%8B/","excerpt":"","text":"SQL实践案例查寻每个省份中，金额排 前三的数据 12345678# a.province = b.province 表示分组，里外统一省份# b.amount &gt; a.amount 表示 内部金额 &gt; 外部金额的 条数# 先确定 外部金额，在从内部金额中找到满足条件的数量select * from city_order as a where 3 &gt; ( select count(*) from city_order as b where a.province=b.province and a.amount&lt; b.amount );ORDER BY amount desc; 使用group by 分组统计之后，select 后面只能跟： group by 的字段、聚合函数 select 中的非多行函数列，都必须出现在group by 中,在group by 中的列，可以出现或不出现在 select 字句中: 123select deptno, avg(sal)from empgroup by deptno; 12345678select province , max(amount) amountfrom city_ordergroup by province;select province , avg(amount) amountfrom city_ordergroup by provincehaving max(amount)&gt; 500; # amount&gt;500 报错， 在 having ,select 的字段中，只能写 group by 分组的字段 + 聚合函数（其他字段） 不适用 order by ， 实现在 salaries 表 中找 第二大 的员工信息： 123select b.emp_no, max(b.salary), a.last_name, a.first_namefrom employees a, salaries b on a.emp_no = b.emp_nowhere b.salary &lt; (select max(bb.salary) from salaries bb); 知识点：在 from 后边写 连接 left join, right join , inner join; 通过 on 连接2个表的相连字段。对所有员工的 薪水按照 salary降序进行 1-N的排名，要求相同 salary并列且按照 emp_no升序排列： 1234select emp_no, salary, (select count(distinct salary) from salaries s2 where s1.salary&lt;=s2.salary )from salaries s1order by salary Desc, emp_no Asc;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"SQL语法","slug":"B-数据库/Mysql/B1-SQL语法","date":"2022-03-14T13:55:19.000Z","updated":"2022-04-19T13:05:31.943Z","comments":true,"path":"2022/03/14/B-数据库/Mysql/B1-SQL语法/","link":"","permalink":"http://example.com/2022/03/14/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/B1-SQL%E8%AF%AD%E6%B3%95/","excerpt":"","text":"SQL语法本地启动： sudo &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server start –skip-grant-tables关闭： sudo pkill -9 mysql登陆 docker 中的 mysql: mysql -h 10.85.172.27 -P 4058 -u rootName -p passWord cashier忘记密码启动： 修改 mysql.user 表里面的password字段 12&gt;&gt; update mysql.user set password=‘***&#x27; where host=‘***&#x27;;&gt;&gt; flush privileges; 数据库：12345create database **if not exists dbName character set utf8;****show databases;****drop database if exists dbName;**use dbName;select database(); -- 显示当前打开的数据库 创建表：PRIMARY KEY: 主键约束 UNIQUE KEY: 唯一约束 NOT NULL: 非空约束 DEFAULT: 默认约束 FOREIGN KEY: 外键约束 主键可自动编号，则可加上 “AUTO_INCREMENT” 级联外键字段： CASCADE：父表的删除、更新操作会使得子表中匹配的行也自动进行删除或更新； SET NULL：父表的删除、更新操作会使得子表中的外键列为NULL，并且前提是外键列没有指定为NOT NULL； RESTRICT：拒绝对父表的删除或更新操作； 12345678910111213141516171819202122232425262728293031create table if not exists teacher( id **int primary key** unique key , name varchar(20) not null , score float(8,2) UNIQUE, age int not null);\\# 子表CREATE TABLE users( id SMALLINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, username VARCHAR(10) NOT NULL, pid SMALLINT UNSIGNED, FOREIGN KEY (pid) REFERENCES province (id) /* 外键列，外键列和参照列必须具有相似的数据类型 */);CREATE TABLE user3( id SMALLINT UNSIGNED PRIMARY KEY AUTO_INCREMENT, username VARCHAR(10) NOT NULL, pid SMALLINT UNSIGNED, FOREIGN KEY (pid) REFERENCES province (id) ON DELETE CASCADE);-- 外键create table province( id **SMALLINT UNSIGNED PRIMARY KEY AUTO_INCREMENT,** pname VARCHAR(20) NOT NULL);show tables;**show columns** from teacher; -- 查看数据表结构 修改表属性：123alter table user3 add age tinyint unsigned not null; -- 添加一列alter table teacher add (class varchar(20), address varchar(10) not null); —- 添加多列alter table teacher drop class; -- 删除一列 – 添加约束 12alter table teacher add unique(age);alter table user3 add foreign key(pid) references province(id); – 删除约束 1alter table user3 drop primary key; – 修改列定义 1alter table user3 modify id smallint unsigned not null first; – 修改列名 1alter table user3 change age userage tinyint unsigned; – 修改表名 1alter table user3 rename as user33; 删除表： 1drop table user; 增删改： 增-删-改:12345**insert into** teacher (id,name,score) values (0,&#x27;whq&#x27;,98.3241),(1,&#x27;wxb&#x27;,34.42);**delete from** teacher where id = 1;**update** teacher **set age=24** where name=&#x27;whq&#x27;; 查询：1234567891011121314151617181920212223242526272829303132SELECT select_expr1[,select_expr2,...][ FROM table_name [WHERE where_condition] [GROUP BY &#123;col_name | position&#125; [ASC | DESC],...] [HAVING where_condition] [ORDER BY &#123;col_name | expr | position&#125; [ASC | DESC],...] [LIMIT &#123;[offset,] row_count | row_count OFFSET offset&#125;]];select name, agefrom teachergroup by age asc;select name, agefrom teachergroup by age asc having age&gt;=10;/* 从查询结果中的第3行开始（从0开始计数），共返回4行 */SELECT name,age FROM teacher ORDER BY age ASC LIMIT 3,4;/* 子查询的结果作为上一层查询的条件。可使用IN()/NOT IN()、ANY()、SOME()、ALL()等操作符和比较运算符搭配使用。 */SELECT goods_id,goods_name,goods_price FROM tdb_goods WHERE goods_price &gt;= (SELECT AVG(goods_price) FROM tdb_goods);-- LEFT/RIGHT [OUTER] JOIN左外连接/右外连接SELECT goods_id, goods_name, cate_name FROM tdb_goods as tg **LEFT JOIN** tdb_goods_cates as tgc**ON tg.cate_id = tgc.cate_id;** – 多表删除12345678DELETE t1 FROM tdb_goods AS t1 LEFT JOIN (SELECT goods_id,goods_name FROM tdb_goods GROUP BY goods_name HAVING count(goods_name) &gt;= 2 ) AS t2 ON t1.goods_name = t2.goods_name WHERE t1.goods_id &gt; t2.goods_id; 聚合函数: AVG()：求平均值； COUNT()：计数； MAX()：求最大值； MIN()：求最小值； SUM()：求和 数值运算： ceil(x)：返回大于 x的最小整数值； div：整数除法，即结果中只保留整数部分； floor(x)：返回小于 x的最大整数值； mod：取余； power(x, y)：幂运算，即 x的y次方； round(x, y)：四舍五入，即将数值 x四舍五入为y位小数。 truncate(x, y)：数字截取，将数值 x保留y位小数（不进行四舍五入） 比较运算: [NOT] BETWEEN…AND…：【不】在范围之内； [NOT] IN()：【不】在列出值范围内； IS [NOT] NULL：【非】空 字符函数: CONCAT( str1, str2, …)： 字符连接； CONCAT_WS(separator, str1, str2, …)： 使用指定的分隔符进行字符连接； FORMAT(x, d)： x为某数字，d为小数位； LOWER(str)： 将字符串转化为小写字母； UPPER(str)： 将字符串转化为大写字母； LEFT(str, len)： 返回指定长度的字符串的左侧部分； RIGHT(str, len)： 返回指定长度的字符串的右侧部分； MID(str, pos[, len])： 返回str里从pos位置开始，长度为len的字符串部分； SUBSTRING(str, pos, len)： 返回str里从pos位置开始，长度为len的字符串部分； LENGTH(str)： 返回字符串str的长度，空格也会一起计算长度，以字节为单位； LTRIM(str)： 删除前导空格； RTRIM(str)： 删除后续空格； TRIM([{BOTH | LEADING | TRAILING} [removed_str]] FROM str)： 删除前后缀不需要的字符； [NOT]LIKE()： 与通配符一起使用选择数据。MySQL提供两个通配符（%和_），其中，“%”用于匹配任何字符串，“_”用于匹配任何单个字符。如果需要匹配的字符本身就是通配符，可使用ESCAPE； REPLACE(str, old_str, new_str)：将str字符串里的old_str字符串部分替换为new_str； LOCATE(substr,str)： 返回子符串substr在字符串str的第一个出现的位置； LOCATE(substr,str,pos)：返回子符串substr在字符串str，从pos处开始的第一次出现的位置。 12/* LIKE()举例 */SELECT * FROM test WHERE first_name LIKE &#x27;%1%%&#x27; ESCAPE &#x27;1’; -- 不将“1”后的“%”认为是通配符 日期时间函数: NOW()： 当前日期和时间； DATE(date)： 返回日期； CURDATE()： 当前日期； CURTIME()： 当前时间； YEAR(date)： 返回date中的年份； MONTH(date)： 返回date中的月份； DAY(date)： 返回date的中的日； DATE_ADD(date, INTERVAL expr type)：日期加减。type类型可以是DAY、WEEK、MONTH、YEAR等。例：SELECT DATE_ADD( ‘2017-11-20’, INTERVAL 2 DAY); DATEDIFF()：返回两个日期之间的天数； DATE_FORMAT( date, format)：日期时间格式化。例如%d、%m、%Y等 信息函数: CONNECTION_ID()：返回数据库的连接次数 DATABASE()： 当前数据库； LAST_INSERT_ID()： 最后插入记录的id； USER()： 当前用户； VERSION()： 版本信息 加密函数： MD5()：信息摘要算法； PASSWORD()：密码算法","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"MySQL扩展","slug":"B-数据库/Mysql/A4-Mysql扩展","date":"2022-03-12T13:55:36.000Z","updated":"2022-04-19T13:05:22.659Z","comments":true,"path":"2022/03/12/B-数据库/Mysql/A4-Mysql扩展/","link":"","permalink":"http://example.com/2022/03/12/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/A4-Mysql%E6%89%A9%E5%B1%95/","excerpt":"","text":"MySQL扩展Mysql 数据库连接池参数：userpasswordcharacterEncoding 编码方式autoReconnect： 当数据库连接异常中断时，是否自动重新连接？maxReconnects： autoReconnect设置为true时，重试连接的次数connectTimeout： 和数据库服务器建立 socket连接时的超时，单位：毫秒。 0表示永不超时allowMultiQueries： mysql驱动开启批量执行sql的开关 Mysql 的参数：max_connections&#x3D;3000: MySql的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量default-storage-engine: MySQL的 默认存储引擎 innodb_buffer_pool_size: (默认128M) 存储页面缓存数据innodb_change_buffer_max_size： changeBuffer缓存区,修改记录的read_rnd_buffer_size : 随机读缓冲区大小 MRR 做随机IO时使用，这里会对主键进行排序read_buffer_size : 读入缓冲区大小。对表进行 顺序扫描的请求将分配一个读入缓冲区innodb_log_buffer_size : 事务日志所使用的缓冲区； redo_log日志需要先缓存，再刷盘 wait_timeout&#x3D;1800: MySQL连接闲置 超过一定时间后将会被强行关闭back_log&#x3D;500 : 连接数据达到 max_connections时，新来请求将会被存在堆栈中，等待某一连接释放资源，该堆栈数量即back_logmax_user_connections ： 同一个账号能够同时连接到mysql服务的最大连接数。设置为0表示不限制 MySQL主机宕机后，如何恢复？主库宕机：1.确保所有从节点 relay log 全部更新完毕； 在每个从库上执行 show processlist 查看2.登录所有 从节点，查看 master.info文件， 找 最大的 pos 节点作为新主库，数据最全3.登录 pos 最大从节点，执行 stop slave; 删 relay-log.info 等从相关文件； 开启 bin-log 来记录sql 日志； 执行 reset master4.创建用于 同步的用户并授权slave5.登录其他从节点 ，执行 stop slave停止同步，再 执行 start slave ；6.测试 新master 和 slave 数据是 否同步 从库宕机：1)查看 从库上 mysql 的错误日志，里面有记录 主从挂掉时的binlog信息2)有了 binlog和postion信息后，只需要 重新在 从库上进行change master to配置； 配置后开启slave 状态，没有报错3)查看 slave状态，发现slave已经正常了，开始进行 延时数据恢复 MHA+多节点集群：MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master，整个故障转移过程对应用程序完全透明。1）service mysql stop (关闭主库)2）备库自动提升为主，IP地址同时漂移至备机3）从库自动同步备库修复原主库，将角色变为备，连接至现主库，三台主从又恢复了正常，重新建立MHA redo log 与 binlog 区别：1）作用不同：redo log是用于保证MySQL宕机也不会影响持久性；binlog是用于 保证服务器可以 基于时间点恢复数据，此外 binlog还用于主从复制。2）层次不同：redo log是 InnoDB存储引擎实现的；binlog 是MySQL的服务器层实现的，同时支持InnoDB和其他存储引擎。3）内容不同：redo log 是物理日志，内容基于磁盘的Page；binlog 内容是二进制的，根据binlog_format参数的不同，可能基于 sql语句，基于数据本身或者二者的混合。4）写入时机不同：binlog在事务提交时写入；redo log 写入时机相对多元：** 当事务提交时会调用 fsync对redo log进行刷盘；这是默认情况下的策略，修改innodb_flush_log_at_trx_commit参数可以改变该策略，但事务的持久性将无法保证。** 除事务提交时，还有其他刷盘时机：如master thread每秒刷盘一次redo log等，这样好处是不一定要等到commit时刷盘，commit速度加快。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"数据库隔离级别","slug":"B-数据库/Mysql/A3-数据库隔离级别","date":"2022-03-11T13:55:19.000Z","updated":"2022-04-19T13:05:18.904Z","comments":true,"path":"2022/03/11/B-数据库/Mysql/A3-数据库隔离级别/","link":"","permalink":"http://example.com/2022/03/11/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/A3-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","excerpt":"","text":"数据库隔离级别MVCC：MVCC（Multi-Version Concurrency Control）多版本的并发控制协议1.同一时刻，不同的事务读取到的数据可能是不同的 (即多版本)——在T5时刻，事务A和事务C可以读取到不同版本的数据。 ​ MVCC最大的优点： 读不加锁，因此 读写不冲突，并发性能好InnoDB 存储引擎中，SELECT 操作的不可重复读问题 通过 MVCC 得到解决，而 UPDATE、DELETE 的不可重复读问题通过 Record Lock 解决，INSERT 的不可重复读问题是通过 Next-Key Lock（Record Lock + Gap Lock）解决的。 InnoDB 实现 MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：1）隐藏列：InnoDB中 每行数据都有隐藏列，隐藏列中包含本行数据的事务id，指向 undo log的指针等。2）基于undo log的版本链：前面说到每行数据的隐藏列中包含了指向 undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。3）ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本；但具体要恢复到哪个版本，需要根据 ReadView来确定。 ReadView：指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行 读操作时，会将读取到的数据中的事务 id与 trx_sys快照比较，从而判断数据对该 ReadView是否可见，即对事务A是否可见。 trx_sys 中的主要内容，判断可见性的方法如下： low_limit_id：生成ReadView时系统中应该分配给下一个事务的id，如果数据的事务 id&gt;&#x3D;low_limit_id，则对该ReadView不可见。 up_limit_id：生成ReadView时当前系统中活跃的读写事务中最小的事务id，如果数据的事务 id&lt;up_limit_id，则对该ReadView可见。 rw_trx_ids：表示生成ReadView时当前系统中活跃的读写事务的事务 id列表。如果数据的事务 low_limit_id &lt; id &lt; up_limit_id ，则需要判断事务 id 是否在rw_trx_ids中：如果在，说明生成 ReadView时事务仍在活跃中，因此数据对ReadView不可见；如果不在，说明生成 ReadView时事务已经提交了，因此数据对ReadView可见。 RR隔离级别为例： ​ 当事务 A在T3时刻读取zhangsan的余额前，会生成ReadView，由于此时事务B没有提交仍然活跃，因此其事务id一定在ReadView的rw_trx_ids中，因此根据前面介绍的规则，事务B的修改对ReadView不可见。接下来，事务A根据指针指向的 undo log查询上一版本的数据，得到zhangsan的余额为100，这样事务A就避免了脏读。 当事务A在T2时刻读取zhangsan 的余额前，会生成 ReadView。此时事务 B 分两种情况讨论:一种是如图中所示，事务已经开始但没有提交，此时其事务id在ReadView的rw_trx_ids中；一种是事务B还没有开始，此时其事务id &gt;&#x3D; ReadView的 low_limit_id；无论是 哪种情况，根据前面介绍的规则，事务B的修改对ReadView都不可见。当事务A在 T5时刻再次读取zhangsan的余额时，会根据T2时刻生成的ReadView对数据的可见性进行判断，从而判断出事务B的修改不可见；因此事务A根据指针指向的undo log查询上一版本的数据，得到zhangsan的余额为100，从而避免了不可重复读。 MVCC避免幻读机制与避免不可重复读非常类似。当事务 A在 T2时刻读取 0&lt;id&lt;5的用户余额前，会生成ReadView。此时事务 B分两种情况讨论：一种是 如图中所示，事务已经开始但没有提交，此时其事务 id在ReadView的rw_trx_ids中；一种是 事务B还没有开始，此时其事务 id &gt;&#x3D; ReadView 的low_limit_id。无论是哪种情况，根据前面介绍的规则，事务B的修改对 ReadView都不可见。当事务A在 T5时刻再次读取0&lt;id&lt;5的用户余额时，会根据 T2时刻生成的ReadView对数据的可见性进行判断，从而判断出事务B的修改不可见。因此对于新插入的数据 lisi(id&#x3D;2)，事务A根据其指针指向的 undo log查询上一版本的数据，发现该数据并不存在，从而避免了幻读 可重复读隔离级别实现过程：​ 当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号。数据行快照的创建版本号是创建数据行快照时的系统版本号，系统版本号随着创建事务而递增，因此新创建一个事务时，这个事务的系统版本号比之前的系统版本号都大，也就是比所有数据行快照的创建版本号都大。 MVCC ：A 事务读取数据，记录此时刻的快照 id 值， 放在 ReadView 中保存，每次对数据修改都会改变快照 id 值，此id 值保持递增；当后来再次读取 数据时，会比较此时的数据版本 id 值，是否 &gt; 之前的 id 值，如果 &gt; , 说明已经被修改；通 undo log 日志，查询之前的记录数据的快照，访问那个版本时的数据 RR： 可避免 脏读，不可重复读，不能避免 幻读RC： 可避免 脏读， 不能避免 不可重复读，幻读因为 B 线程修改数据提交后，A线程在第二次 select 时，此时不再进行 id 值的比较，会重建ReadView, 使得数据丢失 MVCC是RR 隔离级别下“非加锁读”实现隔离性的方式1）读已提交（RC）隔离级别下的非加锁读RC与RR一样，都使用了 MVCC，其主要区别在于：RR 是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建；RR可以避免脏读，不可重复读和幻读。RC 每次执行select前都会重新建立一个新的ReadView，因此如果事务 A第一次select之后，事务B对数据进行了修改并提交，那么事务A第二次select 时会重新建立新的ReadView，因此事务 B的修改对事务 A是可见的；因此RC隔离级别可以避免脏读，但是无法避免不可重复读和幻读。 2）加锁读 与 next-key lock按照是否加锁，MySQL的读可以分为两种：1.非加锁读（快照读，一致性读），使用普通 select语句，这种情况下使用 MVCC避免了脏读，不可重复读，幻读，保证了隔离性。2.加锁读，在查询时会对查询的 数据加锁（共享锁或排它锁）；由于锁的特性，当某事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以 避免脏读和不可重复读。而避免幻读，则需要通过 next-key lock，它是一种行锁，相当于 record lock(记录锁) + gap lock(间隙锁)；其不仅会锁住 记录本身(record lock功能)，还会 锁定一个范围(gap lock功能)；因此，加锁读同样可以避免脏读，不可重复读和幻读，保证隔离性。#共享锁读取select…lock in share mode#排它锁读取select…for update 参考：https://www.cnblogs.com/kismetv/p/10331633.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"联合索引","slug":"B-数据库/Mysql/B3-联合索引","date":"2022-03-10T13:55:19.000Z","updated":"2022-04-19T13:05:40.789Z","comments":true,"path":"2022/03/10/B-数据库/Mysql/B3-联合索引/","link":"","permalink":"http://example.com/2022/03/10/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/B3-%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95/","excerpt":"","text":"联合索引联合索引使用：12345678select * from t where a=1 and b=1 and c =1; #利用到定义的索引（a,b,c）,用上a,b,cselect * from t where a=1 and b=1; #利用到定义的索引（a,b,c）,用上a,bselect * from t where b=1 and a=1; -- 利用到定义的索引（a,b,c）,用上a,b（mysql有查询优化器）select * from t where a=1; -- 可以利用到定义的索引（a,b,c）,用上aselect * from t where b=1 and c=1; -- 不可以利用到定义的索引（a,b,c）； 最左 a 不匹配select * from t where a=1 and c=1; -- 利用到定义的索引（a,b,c），但只用上a索引，b,c索引用不到 通过最左匹配原则你可以定义一个联合索引，但是使得多中查询条件都可以用到该索引。值得注意的是，当遇到范围查询( &gt;、&lt;、between、like )就会停止匹配 1select * from t where a=1 and b&gt;1 and c =1; -- 这样a,b可以用到（a,b,c），c索引用不到 但是如果是建立 (a,c,b)联合索引，则 a,b,c都可以使用索引，因为优化器会自动改写为最优查询语句 1select * from t where a=1 and b &gt;1 and c=1; -- 如果是建立(a,c,b)联合索引，则a,b,c都可以使用索引 优化器改写为：1select * from t where a=1 and c=1 and b &gt;1; 最左匹配原则，索引index1:(a,b,c)，只会走a、a,b、a,b,c 三种类型的查询； 注意：a,c也走，但是只走a字段索引，不会走c字段。特殊情况说明： 1select * from table where a = &#x27;1&#x27; and b &gt; ‘2’ and c=&#x27;3&#x27;; -- 这种类型只会有 a与b走索引，c不会走 以index （a,b,c）为例建立这样的索引相当于建立了索引a、ab、abc三个索引。 ​ 该图就是一个形如 (a,b,c) 联合索引的 b+ 树，其中的非叶子节点存储的是第一个关键字的索引 a，而叶子节点存储的是三个关键字的数据。这里可以看出 a 是有序的，而 b，c 都是无序的。但是当在 a 相同的时候，b 是有序的，b 相同的时候，c 又是有序的。最左匹配原则中如果遇到范围查询就会停止, 1select * from t where a=5 and b&gt;0 and c =1; -- 这样a,b可以用到（a,b,c），c不可以 例子: 当查询到 b 的值以后（这是一个范围值），c 是无序的, 所以就不能根据联合索引来确定应该取哪一行。 在 InnoDB 中联合索引只有先确定前一个（左侧的值）后，才能确定下一个值。如果有范围查询的话，那么联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。 值得注意的是，in 和 &#x3D; 都可以乱序，比如有索引（a,b,c），语句: 123select * from t where c =1 and a=1 and b=1，这样的语句也可以用到最左匹配，因为 MySQL 中有一个优化器，他会分析 SQL 语句，将其优化成索引可以匹配的形式，即：select * from t where a =1 and a=1 and c=1 为什么要使用联合索引:1.减少开销： 建一个联合索引(col1,col2,col3)，实际相当于建 (col1),(col1,col2),(col1,col2,col3)三个索引,每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！2.覆盖索引： 对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1&#x3D;1 and col2&#x3D;2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作，覆盖索引是主要的提升性能的优化手段之一。3.效率高： 索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1&#x3D;1 and col2&#x3D;2 and col3&#x3D;3, 假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%&#x3D;100w条数据，然后再回表从 100w条数据中找到符合col2&#x3D;2 and col3&#x3D; 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%&#x3D;1w，效率明显提升.","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"Mysql:原理-优化","slug":"B-数据库/Mysql/A2-原理-优化","date":"2022-03-09T13:55:28.000Z","updated":"2022-04-19T13:05:15.009Z","comments":true,"path":"2022/03/09/B-数据库/Mysql/A2-原理-优化/","link":"","permalink":"http://example.com/2022/03/09/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/A2-%E5%8E%9F%E7%90%86-%E4%BC%98%E5%8C%96/","excerpt":"","text":"工作原理-优化mysql 执行过程：客户端 —&gt;连接器 —&gt;缓存—&gt;分析器 —&gt;优化器—&gt;执行器 —&gt;引擎 —&gt; 查询结果客户端 —&gt;连接器 —&gt;缓存—&gt; 查询结果 调优是在执行器执行之前的分析器，优化器阶段完成 主从复制同步原理： 1.从库启动复制时，首先创建 I&#x2F;O 线程连接主库，主库随后创建 Binlog 线程将主库上的改变记录到二进制日志中2.从库通过 I&#x2F;O 线程，将主库的 二进制日志文件 copy 到 从库的中继日志 Relay Log3.从库上的 SQL线程 读取中继日志 Relay Log，重做 中继日志中的事件，将数据的改变更新到自己的数据库中 异步复制：主库执行完提交的事务后，会立即将结果返给给客户端，并不关心从库是否已经接收并处理，如果主 crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 全同步复制：指当主库执行 完一个事务，所有的从库都执行该事务后，主库才返回给客户端。需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 半同步复制：主库执行完客户端提交的事务后 不是立刻返回给客户端，而是等待 至少一个从库接收到并写到 relay log中才返回给客户端。半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP&#x2F;IP往返的时间。所以，半同步复制最好在低延时的网络中使用。 MySQL 数据一致性：1.半同步，从库 ack 确认机制2.缓存， 先写缓存再入主库，读从时先读缓存 读写分离主服务器：写 + 读 （实时性要求高）从服务器：读 读写 分离能提高性能的原因在于：1.主从服务器负责各自的读和写，极大程度缓解了锁的争用 2.从服务器可以使用 MyISAM，提升查询性能以及节约系统开销 3.增加冗余，提高可用性 读写分离常用代理方式来实现： 代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器 explain 分析 select查询语句的参数：select_type：常用的有 SIMPLE 简单查询，UNION 联合查询，SUBQUERY子查询等Table：要查询的表possible_keys：可选择的索引key： 实际使用的索引rows： 扫描的行数type：索引查询类型，经常用到的索引查询类型： **const：使用 主键或 唯一索引 进行查询的时候只有一行匹配 **ref： 使用 非唯一索引 **range：使用 主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询 **index： 和 all的区别是 只扫描索引树 1.查询字段是索引的一部分，覆盖索引; 2.使用主键进行排序 **all：扫描全表system：触发条件：表只有一行，这是一个 const type 的特殊情况 查询优化：1.只返回必要的列，行： 最好不要使用 SELECT*语句； 使用 LIMIT语句来限制返回的数据；只有一条数据 limit 12.多使用普通索引, 背景：写多读少，对唯一性要求不高，或业务代码来保证唯一性时 普通索引使用 change buffer ，可以把一些写操作缓存下来，在读取的时候进行，避免磁盘操作，提高效率3.注意：String字段，但 DB中是int ,用到隐式转换 cast(str) 函数转换，导致不走索引 碰到不走索引情况，可以考虑使用 force index，强制走索引；4.建立联合索引：出现频率较高，常在一起作为 where条件的字段，考虑建立联合索引，减少建立索引的数量；并借助索引下推减少回表； 减少服务器端扫描的行数, 使用索引来覆盖查询。对于业务中有一些不好的索引，考虑使用覆盖索引(最左匹配原则)，把设置错误的索引给覆盖掉 5.开启MRR（mult-range Read）：此操作可以在 回表之前，进行一个排序，把原来一个随机操作变成一个顺序操作原理：根据辅助索引的叶子结点，找到主键值的集合并存储到read_rnd_buffer中，在该buffer中对主键值进行排序，最后利用已经排序好的主键值的集合，去访问表中的数据，这样就由原来的 随机&#x2F;O变成为 顺序I&#x2F;O，降低查询过程中的I&#x2F;O消耗。 6.分解大连接查询：将一个大连接查询分解成 对每一个表进行一次单表查询，然后在 应用程序中进行关联，这样做的好处有：1.让缓存更高效；对于连接查询，如果一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用2.分解成多个单表查询；这些单表查询的缓存结果 更可能被其它查询使用到，从而减少冗余记录的查询。3.减少锁竞争；在应用层进行连接，更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。查询本身效率也可能会有所提升。 7.分页查询优化：1.控制返回的总页数；2.对超过特定 阈值的页数进行 SQL 改写，借助主键 id 的索引覆盖SELECT a.* FROM USER a INNER JOIN (SELECT id FROM USER WHERE age &#x3D; 10 LIMIT 100000,10) b ON a.id &#x3D; b.id; 结果0.53s需要对 where条件增加索引，id 因为是主键自带索引，select返回减少回表可以提升查询性能, 所以采用查询主键字段后进行关联大幅度提升了查询效率。3.使用Redis 来保存lastMaxtId, 下一次分页查询时直接拼接在 where 条件后边，直接跨过 offset 行数据。 8.很长的字段如何设置索引：索引选取越长，占用磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。1.短长度：把字段 hash为另外一个字段存起来，每次校验 hash就好了，hash的索引也不大，hash 后的数值要 区分度过高。2.高区分：通过函数处理倒序，删减字符串减少字段长度，并增加区分度； 如：身份证区域开头，同区域人很多，REVERSE() 函数翻转一下，提高区分度。 MySQL 工作原理： Buffer PoolMySQL 不会直接去修改磁盘的数据，因为这样做太慢了，MySQL 会先记录 redo log，再改内存 Buffer Pool ，等有空了再刷磁盘，如果内存 Buffer Pool里没有数据，就去磁盘 load ；Buffer Pool 是 一个以 页为元素的链表。持久化： 宕机时，Buffer Pool 丢失数据，重做 redo log； 先 redo log, 再 buffer poolBuffer Pool 链表结构：基于 LRU， 和缓存一样，需要淘汰算法来管理数据； ​ Change buffer:​ 查询数据时，如果内存里没有对应页的数据，MySQL 会从磁盘里 load ，如果每次需要的 页 都不同（或不是相邻的页），那每次都要去 load，很慢。如果 MySQL 发现你要修改的页不在内存里，就把要对页的修改，先记到一个叫 Change Buffer 的地方，同时记录 redo log，然后再慢慢把数据 load 到内存，load 过来后再把 Change Buffer 里记录的修改，应用到内存 Buffer Pool中，此操作： merge； 把内存数据刷到磁盘操作： purge ChangeBuffer 只在操作「二级索引」时才使用，原因是「聚簇索引」必须是「唯一」的，也就意味着每次插入&#x2F;更新，都需要检查 是否已经有相同的字段存在，也就没有必要使用 Change Buffer ；另外「聚簇索引」操作的随机性比较小，通常在相邻的「页」进行操作，比如使用自增主键的「聚簇索引」，那么 insert 时就是递增有&#x2F;序的，不像「二级索引」，访问非常随机。 ​ MySQL 以16KB「页」 为 读取和写入单位，一个「页」里面有多行数据，写入数据时，MySQL 会先写 内存中的页，然后再刷新到磁盘中的页。假设在某一次从 内存刷新到磁盘的过程中，一个「页」刷了一半，突然操作系统或 MySQL 进程 崩了，此时内存里的 页数据被清除了，而磁盘里的页数据，刷了一半，处于一个中间状态，可以说是一个「不完整」，甚至是「坏掉的」的页。redo log 在 磁盘中的页数据是正常、没有损坏情况下，才能把磁盘里页数据 load 到内存，如果磁盘中的页数据已经损坏，是无法应用 redo Log 的。 Doublewrite Buffer：在 刷数据到 磁盘之前，先把数据写到另外一个地方 DoubleWrite Buffer， 写完后再开始写磁盘；Doublewrite Buffer 是一个备份，当发生 crash时，就可以利用 它来 修复磁盘里的数据 1.刷数据之前宕机：内存—&gt; 磁盘，重做 redo log 日志2.刷数据时宕机： 利用 Doublewrite Buffer 修复磁盘数据 ​ 要更新一个数据页时，如果数据页在 内存中就直接更新；但如果这个数据页还没有在内存中，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在 change buffer中，这样就不需要 从磁盘中读入这个数据页。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作，通过这种方式就能保证这个数据逻辑的正确性。Change buffer 是可以持久化的数据，在内存中有拷贝，也会被写入到磁盘上，将change buffer中的操作应用到原数据页，得到最新结果的过程称为 merge。 Merge触发条件： 1.访问这个数据页2.系统后台线程定期 merge3.在数据库正常关闭（shutdown）的过程中，也会执行merge将更新操作先记录在 change buffer，可以减少读磁盘，语句的执行速度会得到明显的提升, 数据读入 内存是需要占用 buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率 使用 change buffer 的条件？普通索引可以使用 change buffer ,唯一索引（主键，聚簇索引）的更新就不能使用 change buffer唯一索引更新操作都要先判断这个操作 是否违反唯一性约束, 要判断表中是否存在这个数据，就必须要将数据页读入内存才能判断，都已经读入到内存，那直接更新内存会更快，就没必要使用change buffer change buffer 是 buffer pool里的内存，不能无限增大；change buffer大小可以通过参数 innodb_change_buffer_max_size来动态设置，设置为50 表示change buffer大小最多只能占用buffer pool的50% change buffer 使用场景：适合：写多读少业务，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好，业务模型常见：账单类,日志类的系统不适合：读多写少（写入后马上会做查询 ）将更新先记录在change buffer，但由于马上要访问这个数据页，会立即触发merge过程，访问IO次数不会减少，反而增加 change buffer的维护代价 数据库进行 Merge 时，是真正进行 数据更新的时刻，而 change buffer 主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer 记录的变更越多（页面上要更新的数据越多），收益就越大 flush 操作： redo log 会找个时间去更新到磁盘，这个操作就是flush脏页：在更新之前，当内存数据页跟磁盘数据页内容不一致的时候干净页：内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致 flush 操作条件： InnoDB的 redo log写满了 系统内存不足，需要淘汰一些数据页，空出内存给别的数据页使用。 如果淘汰“脏页”，就要先将脏页写到磁盘。 MySQL认为系统 “空闲”的时候，只要有机会就刷一点 “脏页” MySQL正常关闭，会把内存的脏页都flush到磁盘上，这样下次启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 ​ MySQL 中数据的存储：各个 数据页 组成一个 双向链表；每个 数据页中的记录又组成一个 单向链表每个 数据页都会为存储的记录 生成页目录，一个数据页内： 主键查找，二分法快速定位 ； 其他非主键列查找，从最小记录开始一次遍历单链表 数据库连接池设置：如果你有 10000个并发用户，设置一个10000的连接池基本等于失了智, 即是100也太多了。你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"Mysql:索引-事务","slug":"B-数据库/Mysql/A1-索引-事务","date":"2022-03-08T13:55:19.000Z","updated":"2022-04-19T13:05:09.525Z","comments":true,"path":"2022/03/08/B-数据库/Mysql/A1-索引-事务/","link":"","permalink":"http://example.com/2022/03/08/B-%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/A1-%E7%B4%A2%E5%BC%95-%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"索引-事务搜索引擎：InnoDB : 支持事务，外键，行锁（用MVCC支持高并发）；聚簇索引，叶子节点data域存行记录；跨平台copy 容易复制；Delete 表时一行一行删除MyIsAM: 不支持 事务，外键，行锁； 非聚簇索引，叶子节点data域中存引用地址； 跨平台难 copy 不易复制； Delete表时先Drop 再Create； InooDB:InnoDB 采用 MVCC 来支持高并发，并且实现了四个标准隔离级别(未提交读、提交读、可重复读、可串行化)。默认级别时可重复读（REPEATABLE READ），在可串行化级别下，通过 MVCC + Next-Key Lock防止幻读。 MyIsam索引： 索引优点：1.提高数据检索的效率，降低数据库的 IO成本，类似于书的目录 2.索引列对 数据进行排序，降低数据排序的成本，降低CPU消耗 **被索引的列会 自动进行排序，包括【单列索引】和【组合索引】，只是组合索引的排序要复杂一些。如果按照 索引列的顺序进行排序，对应 order by语句来说，效率就会提高很多。 索引缺点：1.索引会占据磁盘空间 2.索引虽然会 提高查询效率，但是会降低更新表的效率。每次对表增删改，不仅要保存数据，还保存或更新对应的索引文件。 为什么索引结构使用B+树？Hash : 不适合范围查找；无法用于排序与分组；二叉树：根节点的取值，容易导致 二叉树不分叉平衡二叉树： 不支持 范围查询快速查找； 范围查询时需要从根节点多次遍历，查询效率不高。 B树：1.B树 不支持范围查询 的快速查找（节点保存记录）；2.每个节点的 data域存储 行记录，行的大小随着列数的增多，所占空间会变大。 这时一个 页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。 B+ 树： 可以保证等值，范围查询的快速查找范围查询时，因为主键具备唯一性（后面不会有 &lt;&#x3D; max_val 数据），不需再向后查找，终止。InnoDB存储引擎一次 IO读取一页（默认16K）的数据量，MySQL的数据存储在磁盘文件中，查询处理数据时，需先把 磁盘中数据加载到内存中，磁盘IO操作很耗时，所以优化重点就是 尽量减少磁盘 IO 操作。 自适应Hash: InnoDB 存储引擎中，当某个 索引值被频繁使用时，会在 B+Tree 索引之上 再创建一个哈希索引，让 B+Tree 索引可以根据哈希值来快速查找。MySQL 会自动评估使用自适应索引是否值得，如果观察到建立哈希索引可以提升速度，则建立。一般情况下 聚簇索引 &#x3D;&#x3D; 主键索引，当一个表没有创建主键索引时，InnoDB会 自动构建聚簇索引，规则如下： 1.在表上定义 主键 PRIMARY KEY，InnoDB 将主键索引用作聚簇索引2.如果表没有定义主键，InnoDB会选择 第一个不为NULL的 唯一索引列 用作聚簇索引 3.如果以上两个都没有，InnoDB 使用一个 6 字节长整型的字段 ROWID字段构建聚簇索引，该 ROWID字段会在 插入新行时自动递增 辅助索引： 聚簇索引之外的所有其他索引。 联合索引查询： 前缀索引：​ MySQL 支持前缀索引，可以定义字符串的一部分作为索引，如果创建索引的语句不指定前缀长度，索引默认包含整个字符串优点：使用前缀索引，定义好长度，就可以做到既节省空间，又不用 额外增加太多的查询成本。有前缀索引的联合索引 一定要回表： 联合索引已包涵相关信息，还是会回表，因为有前缀索引，不确定到底是不是一个完整的信息。就算是 www.aobing@mogu.com 一个完整的邮箱去查询，但无法判断后续是否有数据，不知道是否是完整的数据，所以需要回表去判断 最左匹配原则： 在条件允许的情况下 使用组合索引替代多个单列索引使用。组合索引最左匹配：组合索引查询时，mysql 一直向右匹配直至遇到范围查询 ( &gt;、&lt;、between、like ) 停止匹配**最左前缀匹配原则：** MySQL会一直向右匹配直到遇到范围查询 （&gt;,&lt;,BETWEEN,LIKE）就停止匹配。覆盖索引： 使用辅助索引的时候，只可以拿到主键值，获取数据还需要再根据主键查询主键索引取到数据。在上面abc_innodb 表中的组合索引查询时，如果只需要 abc字段，则查询到组合索引的叶子节点就可以直接返回，不需要回表。like 模糊匹配支持索引，支持最左匹配原则； Like 要使索引生效，like后不能以%开头， like %字段名%、like %字段名 这类语句会使索引失效 索引列不能参与计算，尽量保持列“干净”： 1FROM_UNIXTIME(create_time) = &#x27;2016-06-06’ 不能使用索引，原因：B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较 1优化： create_time = UNIX_TIMESTAMP(&#x27;2016-06-06&#x27;)。 复合（联合）索引设计原则1.把频繁使用的列、区分度高的列放在前面2.将范围查询的列放在复合索引的最后面，例如 idx_status_create_time3.在常需要作为 查询返回的字段上增加到联合索引中，在联合索引上增加一个字段而使用到覆盖索引，此时建议这种情况下使用联合索引 索引下推：在使用联合索引时 12select * from table where name like &#x27;敖%&#x27; and size=22 and age = 20; 语句在搜索索引树时只能用 “敖”，找到第一个满足条件的记录ID1，然后判断其他条件是否满足，比如 size等后续条件；在 MySQL 5.6之前，只能从 ID1开始 一个个回表，到主键索引上找出数据行，再对比字段值。 索引下推优化： 可以在索引遍历过程中对 联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数 唯一索引、普通索引区别：（核心 change buffer）普通索引使用 change buffer, 唯一索引不适用 change buffer 索引字段选取：1.主键，外键2.尽量保持自增，差异性大的字段3.出现频率高，常在where子句中出现的字段4.小的字段（减少所占用的空间） 破坏使用索引的场景：1.索引列 有函数运算&#x2F; 运算2.索引列有 !&#x3D; &lt;&gt; not in not exist3.like %刘 百分号在前的索引4.字符型索引列5.隐式类型转换select * from t where id &#x3D; 1如果 id 是字符类型的，1是数字类型的，explain会发现走全表扫描，根本用不上索引；因为MySQL底层会对 比较进行转换，相当于加了 cast( id AS signed int ) 这样的一个函数，上面说过函数会导致走不上索引。 MySQL 联接方式：1、内联接（ 使用 &#x3D; ， &lt; ，&gt; 比较运算符）： 包括相等联接、自然联接内联接使用比较运算符根据 每个表 共有的列的值 匹配两个表中的行。例如，检索 students和courses表中 学生标识号相同的所有行 2、外联接：左向外联接、右向外联接、完整外部联接在 FROM子句中指定外联接时，可以由下列几组关键字中的一组指定：1）LEFT JOIN或 LEFT OUTER JOIN左向外联接的结果集包括 LEFT OUTER 子句中指定的左表的所有行，而不仅仅是 联接列所匹配的行。如果左表的某行在右表中没有匹配行，则在相关联的 结果集行中右表的所有选择列表列均为空值 null2）RIGHT JOIN 或 RIGHT OUTER JOIN右向外联接是 左向外联接的反向联接, 将返回右表的所有行, 如果右表的某行在左表中没有匹配行，则将为左表返回空值 null3）FULL JOIN 或 FULL OUTER JOIN完整 外部联接返回 左表和右表中的所有行。当某行在 另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。 3、自然连接(笛卡尔积) 返回左表中的所有行，左表中的每一行与右表中的所有行组合 事务四大特性： 原子性，一致性，隔离性，持久性1.持久性：保证事务 提交后不会因为宕机等原因导致数据丢失； redo log2.原子性：语句要么 全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；undo log （回滚找到前版本数据）3.隔离性：保证 事务执行尽可能不受其他事务影响；undo log4.一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障InnoDB默认的隔离级别是RR，RR的实现主要基于 锁机制（包含next-key lock），MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView） Redo log 保证事务 持久性； undo log 保证事务原子性、隔离性 持久性： redo log（重做日志）InnoDB 作为存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会 定期刷新到磁盘中（这一过程称为刷脏）。Buffer Pool 的使用提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。Redo log 解决这个问题：当数据修改时，除了修改 Buffer Pool中的数据，还会在 redo log记录这次操作；当事务提交时，会调用 fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是 预写日志，（WAL Write-ahead logging），所有 修改先写入日志，再更新到Buffer Pool，保证数据不会因MySQL宕机而丢失，从而满足持久性要求。redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快？主要有以下两方面的原因：（1）刷脏是随机IO，因为每次修改的数据位置随机，但写 redo log是追加操作，属于顺序IO（2）刷脏是以 数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而 redo log中只包含真正需要写入的部分，无效IO 减少。 原子性：undo log （回滚日志）undo log: 当 事务回滚时能够撤销所有已经成功执行的sql语句，当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行 失败或调用了rollback，导致事务需要回滚，可以利用undo log中的信息将数据回滚到修改之前的样子。undo log属于逻辑日志： 记录的是 sql执行相关的信息，当发生回滚时，InnoDB 会根据undo log的内容 做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。 隔离性：undo log并发情形下事务之间互不干扰， 隔离性主要可以分为两个方面（读、写操作）：1.锁： (一个事务) 写操作对(另一个事务)写操作； MVCC： (一个事务) 写操作对 (另一个事务)读操作 未提交读： 事务可以读取 其他未提交事务的执行结果已提交读： 事务可以读取 已经提交事务所做的改变可重复读： 同一事务在 多次读取数据时，可以读取到相同的结果可串行化： 各个事务间串行执行， 在每个读数据行上加上共享锁。在这个级别，导致大量的超时现象和锁竞争。 脏读： 不同事务下，当前事务可以读取到 另外事务未提交的数据不可重复读： 同一事务内 多次读取同一数据，读取到的数据是不一样的幻读： 一个事务读取 某一范围的数据行时，另一个事务在该范围内 插入新行，当此事务再次读取范围内的数据行时，返回之前不存在的行。 幻读是一种特殊的不可重复读问题。 InnoDB 锁类型 :行锁：行锁则只锁定需要操作的数据，并发性能好 共享锁（S Lock）： 共享锁可以和其他锁共存；多个事务可以同时访问 同一数据，但 只能读不能修改排他锁（X Lock）： 排他锁和其他锁不能共存；一个事务获取一个数据行的排他锁，其他事务就不能再获取该行的 共享锁和排他锁，获取排他锁的事务可以对数据进行读取和修改。有排他锁的数据行，其他事务不能修改此数据行，也不能通过 for update和 lock in share mode 锁的方式查询数据，但可以直接通过 select …from…查询数据，因为 普通查询没有任何锁机制读时加共享锁，其他事务可以并发读，但不能写； 写时加排它锁，其他事务不能并发写，也不能并发读 Record Lock：行记录锁；Gap Lock：间隙锁，在索引记录间隙上的锁，在第一条索引记录之前，最后一条索引记录之后上的间隙锁；Next-key lock：下键锁，上面2个锁的组合锁； 间隙锁（Gap锁） 在使用范围条件检索数据，请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；对于 键值在条件范围内但并不存在的记录，叫做 “间隙(GAP)”，InnoDB 也会对这个“间隙”加锁，这种锁机制就是 间隙锁（GAP锁） 123SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; 字面上意思是锁住 10-15的数据，如果id&#x3D;10的数据已存在，那么别的用户 不可以修改该条数据，但是如果 id&#x3D;15的数据并不存在，也是不可以插入的，因为无论该列中是否已有这样的值，因为该范围中 id 在 （10，15）所有 现有值之间的间隙也是锁定的。 间隙锁的目的：1.防止幻读，满足相关隔离级别的要求，要是不使用间隙锁，其他事务插入(10,20)闭区间的任何记录，本事务再次执行上述语句，就会发生幻读2.为满足其恢复和复制的需要，有关其恢复和复制机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。 Record Lock： 锁定一个 记录上的索引，而不是记录本身；Gap Lock：锁定索引之间的间隙，但不包含索引本身。 当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15： 123SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Lock： Record Locks + Gap Locks 结合，不仅锁定 一个记录上的索引，也锁定索引之间的间隙。 一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： 12345(-∞, 10](10, 11](11, 13](13, 20](20, +∞) 间隙锁作用：​ 当事务A执行 update user set name&#x3D;’风筝2号’ where age &#x3D; 10 时，由于条件 where age &#x3D; 10 ，数据库不仅在 age &#x3D;10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷, 10]， (10,30] 这两个区间加了间隙锁，从而导致事务 B插入操作无法完成，只能等待事务A提交。不仅插入 age &#x3D; 10 的记录需要等待事务A提交，age&lt;10， 10&lt;age&lt;30 记录页无法完成，而 &gt;&#x3D; 30的记录不受影响，这足以解决幻读问题了.这是有索引的情况，如果 age 不是索引列，那数据库会为整个表加上间隙锁，不管 age 是否 &gt;&#x3D; 30，都要等待事务 A提交才可以成功插入.​ 表锁：表锁在操作数据时会锁定整张表，并发性能较差；意向共享锁（IS Lock）：事务对 一张表中 某几行的数据加上共享锁； 意向排他锁： 事务对一张表中 某几行的数据加上 排他锁；一个事务想要给一张表加上表锁，前提是 没有其他任何事务已经锁定这张表的任意一行数据，需要去全表扫描，确认是否有哪一行数据被其他事务锁定，但这非常低效。因此引入意向锁，意向锁相当于一个标识，表示 是否有其他事务 锁定该表中的某几行数据。 未提交读 ： 总是 读取最新的数据行，没有任何加锁，更新数据就会被读取到可串行化： MVCC + Next-Key Lock（Record Lock + Gap Lock）所有 读取的行都加锁 已提交读：根据 MVCC 实现，事务每次查询开始时 都会生成一个独立的 ReadView在数据库表中看到的一行记录可能有多个版本，每个版本记录除了有数据本身外，还有一个 表示版本的字段（row trx_id），它在事务开始的时候向事务系统申请，按时间先后顺序递增已提交读是 每次执行语句时都重新生成一次快照，可重复读在事务开始的时候生成一个当前事务全局性的快照 一个快照能够读到那些版本数据，要遵循以下规则：1.当前事务内的更新，可以读到；2.版本 未提交，不能读到；3.版本 已提交，但是却在快照创建后提交的，不能读到；4.版本 已提交，且是在快照创建前提交的，可以读到； 已提交读-可重复读：主要区别是在快照的创建上，可重复读仅在事务开始时创建一次， 已提交读每次执行语句时都重新创建一次 对于已提交读-—-可重复读区别：它们生成 ReadView的策略不同，已提交读每次查询时都会生成一个新的 ReadView，而可重复读每次查询都复用第一次生成的ReadView，ReadView中保存数据版本号。 可重复读：InnoDB 存储引擎中，1.SELECT 操作的不可重复读问题 通过 MVCC 得到了解决；2.UPDATE，DELETE 的不可重复读问题通过 Record Lock 解决3.INSERT 的不可重复读问题是通过 Next-Key Lock（Record Lock + Gap Lock）解决根据 MVCC实现，只会根据事务中第一次查询时生成的 ReadView MVCC： 多版本并发控制（Multi-Version Concurrency Control）InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现 已提交读、可重复读 这两种隔离级别。 版本号：**系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增 **事务版本号：事务开始时的系统版本号 隐藏的列： MVCC 在每行记录后面都保存着 两个隐藏的列，用来存储两个版本号 创建版本号：指示 创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的 删除版本号 &gt; 当前事务版本号 表示该快照有效，否则表示该快照已经被删除 MVCC 使用 快照存储在 Undo 日志中，该日志通过 回滚指针把一个数据行（Record）的所有快照连接起来 快照读、当前读：问题：在可重复读级别中，通过 MVCC机制让数据变得可重复读，但读到的数据可能是历史数据，不是数据库当前的数据！这在一些对于数据的 时效特别敏感 的业务中，可能出问题。快照读： 读取历史数据； MVCC 的 select 操作是快照中的数据，不需要进行加锁操作。当前读： 读取数据库当前版本数据； MVCC 对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行 加锁操作，从而读取最新的数据。 MVCC 也使用加锁，但是 避免了 SELECT 的加锁 , MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得 select不用加锁。而 update，insert ，delete 这些 “当前读”的隔离性，就需要通过加锁来实现 未提交读隔离级别：直接返回记录上的最新值，没有视图概念，也就是图中丙丙那一栏，脏读，幻读，不可重复读都有可能发生。 串行化隔离级别： 直接用 加锁的方式来避免并行访问。 已提交读、可重复读这两种隔离级别使用了MVCC： 事务在 执行普通的 SELECT操作， 访问记录版本链过程中，可以使不同事务的读-写，写-读操作并发执行，从而提升系统性能 RC，RR 隔离级别不同： RC 在每一次进行 普通 SELECT操作前都会生成一个ReadView； RR 只在第一次进行普通 SELECT操作前生成一个ReadView，数据的可重复读其实就是 ReadView的重复使用","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"段/页式存储","slug":"D-操作系统/2.段页式存储","date":"2022-02-27T13:55:19.000Z","updated":"2022-04-19T13:03:10.226Z","comments":true,"path":"2022/02/27/D-操作系统/2.段页式存储/","link":"","permalink":"http://example.com/2022/02/27/D-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%AD%98%E5%82%A8/","excerpt":"","text":"段&#x2F;页式存储背景：​ 在多进程环境下，为使进程之间的内存地址不受影响，相互隔离，操作系统为 每个进程独立分配一套 虚拟地址空间，每个程序只关心自己的虚拟地址，多进程通过 虚拟地址 映射到不同的物理地址内存。 ​ 作为程序，也不用关心物理地址的事情。每个进程都有自己的虚拟空间，而物理内存只有一个；当启用大量的进程，物理内存必然会很紧张，于是操作系统会通过 内存交换技术，把不常使用的内存暂时存放到硬盘 （换出），在需要时再装载回物理内存（换入）。 ​ 有了虚拟地址空间，必然要把 虚拟地址「映射」到 物理地址，这个事情通常由操作系统来维护，对于虚拟地址与物理地址的映射关系，可以有 分段，分页，段页的方式。访问虚拟地址时，由操作系统转换成不同的 物理地址，这样不同进程运行的时候，写入不同的物理地址，就不会冲突。 程序所使用的内存地址： 虚拟内存地址实际存硬件里面的空间地址：物理内存地址 内存分段（Segmentation）​ 程序由若干个逻辑分段组成： 代码分段、数据分段、栈段、堆段；不同段 有不同的属性，用分段形式把这些段分离出来。 内存分段-寻址方式段选择因子：保存在段寄存器里； 段号：段表的索引，段表里面保存 段的基地址、段的界限和 特权等级等； 段内偏移量：位于（0~段界限）； 物理内存地址 &#x3D; 段基地址 + 段内偏移量； 虚拟地址：通过 段表与 物理地址映射，分段机制把程序的虚拟地址分成 4 个段，每个段在 段表中有一个项，在这一项找到段的基地址，再加上偏移量，就能找到物理内存中的地址。 段式存储问题： 1.内存碎片；2.内存交换的效率低1.内存锁片：外部内存碎片：在物理内存中产生多个 不连续的小物理内存，导致 新的程序无法被装载；内部内存碎片：程序所有的内存都被装载到物理内存，但程序 有部分的内存 可能并不是很常使用，这也会导致内存的浪费； 内存交换：解决–外部内存碎片问题 把一个程序占用的 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回时，不装载回原来位置，而是紧紧跟在已经被占用的 512MB 内存后面。这样就 就使得空间利用连续，避免内存碎片产生。 2.内存交换的效率低：​ 内存交换空间在 Linux 系统里就是 Swap 空间，这块 空间是从硬盘划分出来，用于内存与硬盘的空间交换对于多进程系统，内存碎片很容易产生，需要经常进行 内存交换操作，但Swap空间是硬盘，有性能瓶颈；硬盘访问速度比内存慢很多，每次内存交换都需要把 一大段连续的内存数据写到硬盘上。如果内存交换时，交换占内存空间很大的程序，整个机器都会卡顿。 内存分页：解决 内存碎片，内存交换效率低；把整个 虚拟，物理内存空间切成一段段 固定尺寸的大小-页（Page）：一个连续并尺寸固定的内存空间，Linux 一页大小 4KB。 虚拟地址分为： 页号，页内偏移页号： 页表的索引，页表包含 物理页每页所在 物理内存的基地址，物理内存地址 &#x3D; 基地址 与 页内偏移的组合内存分页寻址过程：1.把虚拟内存地址，切分成 页号，偏移量2.根据页号，从 页表里查询对应的物理页号3.直接拿 物理页号 + 偏移量，得到 物理内存地址 **内存空间： **预先划分好，不像分段那样产生 间隙非常小的内存，这正是分段会产生内存碎片的原因。释放的内存都是以页为单位释放的，也不会产生无法给进程使用的小内存。**页表： **存储在 CPU 内存管理单元 （MMU） 中； CPU 可以直接 通过 MMU 找出实际要访问的 物理内存地址。当 进程访问的虚拟地址在页表中查不到时，系统会产生：缺页异常解决： 进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 ​ 如果内存空间不够，操作系统会把 其他正在运行的进程中的「最近没被使用LRU」的 内存页面换出（Swap Out）， 暂时写在硬盘上；需要时再加载进来，称为换入（Swap In）。一次性写入磁盘只有少数一个页或几个页，不会花太多时间，内存交换效率相对比较高。​ 分页方式在加载程序时，不需要一次性把程序加载到物理内存中。在虚拟内存 和物理内存的页映射之后，并不真的把页加载到物理内存里，而 只有在 程序运行中，需要用到对应虚拟内存页里面的 指令和数据时，再加载到 物理内存里面去。 页式存储空间上的缺陷：操作系统可以同时运行非常多的进程，意味着页表会非常的庞大。在 32 位的环境下，虚拟地址空间共有 4GB，一个页大小 4KB，就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，整个 4GB 空间的映射就需要有 4MB 内存来存储页表。每个进程都是有自己的虚拟地址空间，如果有 100 个进程的话，就需要 400MB 内存来存储页表，这是非常大的内存，而 64 位环境则会更大。 多级页表 解决：多进程页表占用空间过大问题使用 二级分页，一级页表 就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表，即可以在需要时才创建二级页表。例如：假设只有 20% 一级页表项被用到，那么页表占用内存空间就只有 4KB（一级页表）+ 20% * 4 MB（二级页表）&#x3D; 0.804MB 局部性原理​ 每个进程有 4GB 虚拟地址空间，对于大多数程序来说，其使用的空间远未达到4GB，因为会有部分对应的页表项都是空的，没有分配，对于已分配的页表项，如果是最近一段时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，不会占用物理内存。 程序的局部性​ 把常访问的 几个页表项存储到访问速度更快的硬件，在 CPU 芯片中加入一个专门存放 程序最常访问的 页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为：页表缓存、转址旁路缓存、快表等。 地址转换：在 CPU 芯片里封装了 内存管理单元（Memory Management Unit）芯片，它用来完成 地址转换和 TLB 的访问与交互。CPU 在寻址时，会先查 TLB，如果没找到，才继续查常规的页表。TLB 命中率其实是很高的，因为程序最常访问的页就那几个 。 段页式内存管理内存分段和内存分页并不是对立的，它们可以组合起来在同一个系统中使用，组合后称为：段页式内存管理段页式内存管理：1.先将程序划分为 多个有逻辑意义的段2.再把 每个段划分为 多个页，对分段划分出来的连续空间，再划分 固定大小的页这样地址结构就由 段号、段内页号，页内位移 三部分组成。用于 段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址 是 页表的起始地址，而 页表中的地址是 某页的物理页号 段页式地址–&gt;物理地址过程：1.访问段表，得到页表起始地址2.访问页表，得到物理页号3.将物理页号 + 页内位移 组合，得到物理地址 Linux 虚拟地址和物理地址映射方式：Linux 系统中，每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位），所有段的起始地址都是一样的。Linux 系统中的代码，包括操作系统本身的代码和 应用程序代码，所面对的 地址空间都是线性地址空间（虚拟地址），相当于屏蔽处理器中的 逻辑地址概念，段只被用于 访问控制和内存保护。Linux 本身采用的实际是段式和页式都有，但不叫段页式； linux的段和页式顺序的两个过程，只不过 段式相当于啥也不干，目的是为了保证兼容性，所以 Linux内存管理的方式实际上相当于 只有页式管理，但查询过程 经过一层段式查询。 总结：内存分段：根据程序逻辑角度，分成 栈段、堆段、数据段、代码段 等，分离出不同属性的段，同时是一块连续的空间。每个段的 大小都不是统一的，这会导致 内存碎片，内存交换效率低 的问题。于是出现：内存分页把 虚拟空间和 物理空间分成 大小固定的页，在 Linux 系统中每一页大小为 4KB。1.分页后就不会 产生细小的内存碎片。2.在内存交换时，写入硬盘是 一个页或几个页，提高内存交换的效率。多级页表：为解决 简单分页产生页表过大 问题，但会导致 CPU 在寻址过程中，需要 有很多层表参与，加大时间上的开销。根据程序局部性原理，在 CPU 芯片中加入了 Cache 就是TLB（Translation Lookaside Buffer），负责 缓存最近常被访问的页表项，来提高 地址的转换速度。Linux 系统主要采用 分页管理，但由于 Intel 处理器的发展史，Linux 系统无法避免 分段管理。于是 Linux 把所有 段的基地址设为 0，所有程序的地址空间都是 线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。另外，Linxu 系统中 虚拟空间分布可分为用户态和内核态两部分，用户态：代码段、全局变量、BSS、函数栈、堆内存、映射区。 参考： Linux 段页存储： https://blog.csdn.net/jinking01/article/details/107098437","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"操作系统-基础","slug":"D-操作系统/1.操作系统-基础","date":"2022-02-25T13:55:19.000Z","updated":"2022-04-19T13:03:04.844Z","comments":true,"path":"2022/02/25/D-操作系统/1.操作系统-基础/","link":"","permalink":"http://example.com/2022/02/25/D-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"操作系统基本知识点进程的五大状态： Sleep, wait 区别：sleep() 休眠：让调用线程进入睡眠，让出执行机会给其他线程，等到休眠时间结束，线程进入就绪状态和其他线程一起竞争cpu执行时间。Thread的静态方法，不能改变对象的机锁，当一个synchronized块中调用了sleep() 方法，线程虽然进入休眠，但是对象的锁没有被释放，其他线程依然无法访问这个对象。wait() 挂起：是Object类的方法，当一个线程执行到wait方法时，它就进入到一个和该对象相关的等待池，同时释放对象的锁，使得其他线程能够访问，可以通过notify，notifyAll方法来唤醒等待的线程。 总结：1.sleep不释放对象锁，只是让出CPU； wait释放对象锁，也让出CPU2.sleep 是Thread 的静态方法； wait 是Object 类的私有方法3.sleep可以指定休眠时间，无法唤醒；wait 可指定时间，也可通过notify&#x2F;notifyAll唤醒，实现多线程间通信 CPU 执行程序的过程:CPU 根据 程序计数器里的内存地址，从内存里面把需要执行的 指令序列读取到 指令寄存器 里面执行，然后根据 指令长度自增，开始顺序读取下一条指令。CPU 的指令周期： CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束。 操作系统中的死锁：一组进程中，每个进程都 无限等待被该组进程中另一进程所占有的资源，而永远无法得到资源，这种现象称为进程死锁，这一组 进程称为死锁进程。如果死锁发生，会浪费大量系统资源，甚至导致系统崩溃。 产生死锁必要的四个条件：(1)互斥使用 (资源独占)： 一个资源 每次只能给一个进程使用(2)请求和保持(部分分配)：进程在 申请新的资源的同时 保持对原有资源的占有(3)不可抢占 (不可剥夺)：资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放(4)循环等待：存在一个进程等待队列 {P1 , P2 , … , Pn}，其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路。 解除死锁： 资源剥夺法、 进程撤销法、进程回退法、 系统重启法破坏环路等待：给资源统一编号，进程只能按编号顺序来请求资源。死锁避免：在程序运行时避免发生死锁 同步&#x2F;异步&#x2F;阻塞&#x2F;非阻塞IO：等待过程： 数据从网络 到 网卡, 再到 内核空间读写(copy)过程： 内核空间，和 用户空间 相互拷贝IO： 读入&#x2F;写出 数据的过程，和等待 读入&#x2F;写出数据的过程同步&#x2F;异步： 是否 等待数据到 内核空间（网络—&gt;网卡—&gt;内核）阻塞&#x2F;非阻塞： 是否 等待 copy数据 （ 内核—&gt; 用户） 阻塞IO：用户线程被阻塞在等待数据上和拷贝数据上。应用程序都运行在 用户空间，能操作的 数据也都在用户空间；如果此时用户线程已经参与，那它一定 会被阻塞在IO上，这就是常说的阻塞IO，用户线程被阻塞在等待数据，拷贝数据。非阻塞IO：数据已经拷贝到用户空间后，才去通知用户线程，一上来就可以直接操作数据，用户线程没有因为IO的事情出现阻塞。 同步IO&#x2F;同步阻塞IO：同步IO: 发起 IO请求后，必须拿到 IO数据才继续执行，在 等待和拷贝数据过程中，线程都在阻塞，因为后续操作依赖IO数据非阻塞IO：发起IO请求后，可以继续往下执行，后续执行不依赖于IO数据，所以它肯定不是同步的。同步IO 一定是 阻塞IO，也就是同步阻塞IO。 异步： 等待数据继续执行， 阻塞：copy 数据时阻塞异步IO：IO请求后，不用拿到IO的数据就可继续执行，用户线程继续执行，和操作系统准备IO数据的过程是同时进行。异步阻塞 IO： 在等待数据过程中，用户线程继续执行，在拷贝数据过程中，用户线程在阻塞；用户线程没有参与数据等待的过程，所以是异步的。但用户线程参与数据拷贝的过程，所以是阻塞的,合起来异步阻塞IO。异步非阻塞IO： 等待数据， copy 数据时 用户线程都在继续执行；在 等待数据的过程中，和拷贝数据的过程中，用户线程都在继续执行；用户线程 没有参与等待过程也没有参与拷贝过程，当接到通知时数据已经准备好了，没有因为IO数据而阻塞，是非阻塞的。 I&#x2F;O多路复用通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（读就绪或写就绪），能通知程序进行相应的读写操作select，poll，epoll 本质上都是 同步I&#x2F;O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I&#x2F;O 则无需自己负责进行读写，异步 I&#x2F;O的实现会负责把数据从 内核拷贝到用户空间。 Select 原理：1.从 用户空间 拷贝 fd_set 到 内核空间，fds 文件描述符（ 3类，分别是writefds，readfds，和exceptfds ）2.注册回调函数 __pollwait ，然后将 current（当前进程）挂到 设备的等待队列中，不同的设备有不同的等待队列。（有数据 可读、可写、或超时timeout等待时间）3.有描述符 就绪后，通过回调函数进行通知，select 会对 fd_set 进行遍历，来找到就绪的描述符。遍历完 所有的 fd，还没有返回一个 可读写的 mask掩码，调用 schedule_timeout 是 调用select的进程（current）进入睡眠缺点：1）支持的文件描述符数量太小，默认是 10242）每次 调用 select，需要把 fds 集合从 用户态拷贝 到内核态，在 fds 很大时, 开销较大3）每次调用 select 需要在 内核遍历传递进来的 所有 fds，找到处于 就绪的描述符，开销较大 poll ：实现和 select 相似，只是 描述 fd集合 不同，poll使用 poll fd结构而不是select的fd_set结构，链表存储的。优：没有最大连接数的限制，原因：基于链表来存储的缺：1.poll, select 大量的 fds 的数组被整体 复制于 用户态和内核地址空间之间2.select, poll 都要通过 遍历文件描述符来获取已经就绪的socket，如果同时连接大量客户端，但只有很少的处于就绪状态，这会导致随着监视的 描述符数量的增长，效率下降。 epoll:提供三个函数：epoll_create创建一个epoll句柄； epoll_ctl 注册要监听的事件类型； epoll_wait 是等待事件的产生 。 1.解决反复 copy fds 问题：epoll更加灵活，没有描述符限制。epoll 使用一个 文件描述符管理多个描述符， 将 用户关系的文件描述符的事件 存放到 内核的一个事件表 中，这样在 用户空间和内核空间的 copy只需一次。2.epoll 使用 “事件”就绪通知方式，通过 epoll_ctl时把 current 遍历一遍，并 为每个 fd 指定一个回调函数，当设备就绪，唤醒 等待队列上的等待者时，会调用这个回调函数，而这个 回调函数会把就绪的 fd 加入一个就绪链表；epoll_wait 工作实际上就是在这个 就绪链表中查看有没有就绪的fd 。 总结：select，poll 每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把 current往设备等待队列中挂一次，而 epoll只要一次拷贝，而且把 current 往等待队列上挂也只挂一次。只有活跃可用的 FD才会调用 callback函数；即 epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。 内存拷贝：利用 mmap()文件 映射内存加速 与 内核空间的消息传递；即 epoll使用mmap减少复制开销参考：https://blog.csdn.net/weixin_34067102/article/details/91532307?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-10.essearch_pc_relevant&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-10.essearch_pc_relevant 用户态 &lt;—&gt; 内核态：所有程序都在 用户空间运行（用户态），但很多操作 可能涉及内核运行，就需要进入内核态 用户态把一些 数据放到寄存器，或创建对应的堆栈，表明需要操作系统提供的服务 用户态 执行 系统调用（系统调用是操作系统的最小功能单位） CPU 切换到内核态，跳到对应的内存指定的位置执行指令 系统调用 处理器 去读取先前放到 内存的数据参数，执行程序的请求 调用完成，操作系统重置 CPU为用户态返回结果，并执行下个指令 内核 &lt;—&gt;用户 1.系统调用：本身就是中断，但是软件中断，跟硬中断不同 2.异常：如果当前进程运行在用户态，如果此时发生异常事件，就会触发切换， 例如：缺页异常 3.外设中断：当外设完成用户的请求时，会向CPU发送中断信号用户态进程通过 系统调用申请使用 操作系统提供的服务程序完成工作，比如 fork() 实际上就是执行了一个 创建新进程的系统调用；CPU 在执行 用户态下的程序时，发生不可知的异常，这时会触发当前运行进程切换到处理此异常的内核相关程序中，转到内核态，比如缺页异常。用户态: 上层应用程序的活动空间，应用程序的执行必须依托于 内核提供的资源，包括CPU资源、存储资源、I&#x2F;O资源等。为了使上层应用能够访问到这些资源，内核 必须为上层应用提供访问的接口：即系统调用。 系统调用：操作系统的最小功能单位Shell (命令行) 是一个特殊的应用程序，下通系统调用，上通各种应用，让不同程序能够以一个清晰的接口协同工作，从而增强各个程序的功能。同时 Shell是可编程的，可以执行符合 Shell语法的文本(Shell脚本)。为方便用户和系统交互，一个Shell对应一个终端，可以通过终端窗口输入或输出文本，这个文本直接传递给shell 进行分析解释，然后执行。 进程、线程区别：进程： 操作系统 资源分配的基本单位线程： 任务调度、执行的基本单位， cpu调度和分派的基本单位。 开销：每个进程都有独立的 代码 和 数据 空间（程序上下文），程序之间的切换会有较大的开销；线程就像轻量级的进程，同一类 线程 共享代码和数据空间，每个线程都有自己独立的 运行栈和程序计数器（PC），线程之间切换的开销小 环境：操作系统中能 同时运行多个进程（程序）；在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行） 内存分配：系统在运行的时候会为 每个进程分配不同的内存空间对线程而言，除了CPU外，系统不会为线程分配内存， 线程所使用的资源来自其所属进程的资源，线程组之间只能共享资源 进程间通信方式：1.P、V信号量（Semaphore）：操作系统提供一种进程间的通信方式，主要用来协调并发程序对共享资源的访问，操作系统可以保证对信号量操作的原子性信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。特点 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。 2.管程：原理：所有进程对某一种临界资源的同步操作都集中起来，构成一个秘书进程。凡要访问该临界资源的进程，都需要先报告秘书进程，由秘书来实现进程对同一临界资源的互斥使用。 管程可以理解为一个对象监视器，任何线程想要访问共享资源，需要排队进入监控范围，接受检查，不符合条件，则要等待直到被通知，然后再进入监视器. 它是 半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。注意：信号量和管程两者是等价的，信号量可以实现管程，管程也可以实现信号量，两者的表现形式不同，管程对开发者更加友好。 管程为了解决信号量在临界区的 PV 操作上的配对的麻烦，把配对的 PV 操作集中在一起，并且加入了条件变量的概念，使得在多条件下线程间的同步实现变得更加简单。 3.消息队列：容量受系统限制消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。特点： 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 4.共享内存：速度快，各个进程间共享同一个内存区域，实现共享变量的访问共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区。特点 共享内存是 最快的一种 IPC，因为进程是直接对内存进行存取。 因为 多个进程可以同时操作，所以需要进行同步。 信号量+共享内存: 通常结合在一起使用，信号量用来同步对共享内存的访问。 5.套接字用于不同设备间的进程通信 线程间通信方式：1.互斥锁： 以排他的方式防止数据结构并发修改2.条件变量：阻塞进程，知道某个条件满足3.读写锁： 多线程同时读，互斥写4.信号量： 类似进程间信号量通信，主同步 进程调度算法；1.先来先服务2.最短作业优先3.响应比最高者优先4.优先级调度算法5.时间片轮转调度算法 参考：文件系统：https://mp.weixin.qq.com/s/UT2JrfpkA5OUC9fJJ_MirQ","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"集群一致性hash算法","slug":"C-中间件/Redis/A4-Redis集群一致性Hash算法","date":"2021-07-09T13:55:19.000Z","updated":"2022-04-19T13:06:22.992Z","comments":true,"path":"2021/07/09/C-中间件/Redis/A4-Redis集群一致性Hash算法/","link":"","permalink":"http://example.com/2021/07/09/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/A4-Redis%E9%9B%86%E7%BE%A4%E4%B8%80%E8%87%B4%E6%80%A7Hash%E7%AE%97%E6%B3%95/","excerpt":"","text":"Redis集群一致性Hash算法​ 类似于数据库，当单表数据 &gt;500W 时，需要对其进行分库分表，当数据量很大时，同样需要对 Redis进行分库分表的操作。在做缓存集群时，为缓解服务器压力，会部署多台缓存服务器，把数据资源均匀的分配到每个服务器上，分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。 ​ 使用上述 Hash算法进行缓存时，会出现一些缺陷，在服务器数量变动时，所有缓存的位置都要发生改变！那原本 hash(a.png) % 4 &#x3D; 2 的公式就变成了 hash(a.png) % 5 &#x3D; ？， 这个结果不是2的，此时所有缓存位置都要发生改变！也就是当服务器数量发生改变时，所有缓存在一定时间内是失效的。​ 假设 4 台缓存中突然有一台缓存服务器出现故障，需要将故障机器移除，但如果移除一台缓存服务器，缓存服务器数量从4台变为3台，也会出现上述问题！ 一致性Hash算法就是解决这个问题!​ 刚才描述的取模法是对服务器的数量进行取模，而 一致性Hash算法是对 2^32 取模，简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，假设某哈希函数H 的值空间为： 0 ~ 2^14​ 0点右侧的第一个点代表1，以此类推，2,3,4,5,6……直到 2^14，也就是说 0点左侧的第一个点代表 2^14， 0和2^14 在零点中方向重合，我们把这个由2^14 个点组成的圆环称为 Hash环。下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下： ​ 接下来使用如下算法定位数据访问到相应服务器：将数据 key使用相同的函数 Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！ 例如: 有 Object A,Object B,Object C,Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： ​ 根据一致性 Hash算法，数据A会被定为到Node A 上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 一致性Hash算法 容错性和可扩展性:​ 现假设Node C 不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如果在系统中增加一台服务器Node X，如下图所示： ​ 此时对象Object A，B，D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 Hash环的数据倾斜问题：​ 一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： ​ 此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。 ​ 例如:上面的情况，可以为每台服务器计算 三个虚拟节点，于是可以分别计算 “Node A#1”，“Node A#2”，“Node A#3”，“Node B#1”，“Node B#2”，“Node B#3” 哈希值，于是形成六个虚拟节点： ​ 通过虚拟节点做为中间变量，再从虚拟节点—&gt;实际节点，实现数据映射。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”，“Node A#2”，“Node A#3” 三个虚拟节点的数据均定位到Node A上。 这样就解决了服务节点少时数据倾斜的问题，在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"中间件/Redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Redis性能优化","slug":"C-中间件/Redis/A3-Redis 优化","date":"2021-07-08T13:55:19.000Z","updated":"2022-04-19T13:06:08.829Z","comments":true,"path":"2021/07/08/C-中间件/Redis/A3-Redis 优化/","link":"","permalink":"http://example.com/2021/07/08/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/A3-Redis%20%E4%BC%98%E5%8C%96/","excerpt":"","text":"Redis性能优化布隆过滤器：应用场景： 缓存穿透，海量数据去重 K 个哈希函数，每个字符串跟 k个bit对应，降低冲突概率当一个元素被加入集合时，通过 K个散列函数 将这个元素映射成一个 位数组中的K个点，把它们置为 1, 检索时只要看这些点 是不是为 1 就知道集合中有没有它了。如果 这些点有任何一个 0，则被检元素一定不在； 如果都是1，则被检元素很可能在Bloom Filter 和单哈希函数 Bit-Map不同：Bloom Filter使用了 k个哈希函数，每个 字符串跟 k个bit对应。降低冲突概率 存在的问题：存在误判：hash之后得到的 k个位置上值都是1，但可能此值不存在；解决：可以通过建立一个 白名单来存储可能会误判的元素删除困难： 一个放入容器的元素映射到 bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断；解决： 可以采用Counting Bloom Filter 分布式锁： 常规锁只能适用于单机，对于分布式架构无法保证避免不同节点重复相同的工作： 比如用户执行某个操作有可能不同节点会发送多封邮件；避免破坏数据的正确性：如果两个节点在同一条数据上同时进行操作，可能会造成数据错误或不一致的情况出现； Redis 分布式锁的问题： 锁超时有两台平行的服务 A B，其中 A 服务在 获取锁之后 由于某种原因突然 挂了，那么 B 服务就永远无法获取到锁； 需要额外设置一个超时时间，来保证服务的可用性。如果 加锁，释放锁 之间的逻辑执行得太长，以至于 超出了锁的超时限制，也会出现问题。因为这时第一个线程持有锁过期了，而临界区逻辑还没执行完，与此同时第二个线程就提前拥有了这把锁，导致临界区的代码不能得到严格的串行执行。为避免这个问题，Redis 分布式锁 不要用于较长时间的任务。 解决：标记版本号 将锁 value 值设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key， 确保当前线程占有的锁不会被其他线程释放，除非这个锁是因为过期而被服务器自动释放的，但匹配 value 和 删除 key 在 Redis 中并不是一个原子性的操作，需要使用像 Lua 脚本来处理，因为 Lua 脚本可以 保证多个指令的原子性执行 分布式锁：setnx是 SET if Not exists设置过期时间： EXPIRE name 5 # 5s 后过期EXPIRE 命令依赖于 SETNX 的执行结果，而事务中没有 if-else 的分支逻辑，如果 SETNX 没有抢到锁，EXPIRE 就不应该执行。加入 SET 指令扩展参数，使 SETNX 和 EXPIRE 指令一起执行： SET key value [EX seconds | PX milliseconds] [NX | XX] [KEEPTTL]设置一个过期时间，就算线程 1挂了，也会在失效时间到了，自动释放计数： 使用 INCR 命令进行 原子性 的自增操作，多个 客户端对同一个 key 进行操作，也决不会导致竞争的情况 Setnx 加锁， expire 过期时间； 不是原子性操作；Redis:: set( “my:lock”, $token, “nx”, “ex”, 10);直接使用 set进行锁，参数配置，让 加锁+过期时间 成原子操作；传统的 del 解锁方式，存在问题； 如果 expire time 释放锁后， 其他线程重新获取，直接 del 解锁，会删除别人建立的锁了。通过 lua脚本（保证一系列操作的原子性），先进行 get，再进行 del； 外加 token 字段，一个随机数，当 lock的时候，往redis的 my:lock中存的是这个token，unlock的时候，先 get一下lock中的token，如果 和要删除的 token是一致的，说明这个锁是之前我 set的，否则说明这个锁已经过期，是别人set的，就不应该对它进行任何操作。 场景题：假如 Redis里面有1亿个 key，有10w key 是以某个固定前缀开头，如何全部找出？使用 keys 指令可以扫出 指定模式的 key列表；如果 redis正在给 线上的业务提供服务，那使用 keys指令会有什么问题？Redis单线程的，keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。可以使用 scan指令，无阻塞的提取出指定模式的key列表，但会有一定的重复概率，需要在客户端做一次去重，整体所花费的时间会比直接用keys指令长。分布式场景下，多个微服务间协同调用，调用链使用 UUID 唯一 redis常见性能问题和解决方案：1.Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master最好不要写内存快照。2.Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响 Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化, 如果数据比较关键，某个 Slave开启AOF备份数据，策略为每秒同步一次。3.Master 调用bgrewrite AOF 重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。4.Redis主从复制的性能问题，为主从复制速度和连接的稳定性，Slave和 Master最好在同一个局域网内。 Redis 事务特征：1.在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端请求提供任何服务，从而保证s事务中的所有命令被原子的执行。2.和关系型数据库中的事务相比，在 Redis事务中，如果 某一条命令执行失败，其后的命令仍然会被继续执行。3.通过 multi 命令开启一个事务，在该语句之后执行的命令都将被视为事务之内的操作，最后通过执行 exec&#x2F;discard 命令来提交&#x2F; 回滚 该事务内的所有操作。 这两个Redis命令可被视为等同于关系型数据库中的 commit&#x2F;rollback 语句。4.在事务开启之前，如果 客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。如果网络中断事件是发生在客户端执行exec 命令之后，那么该事务中的所有命令都会被服务器执行。5.当使用 Append-Only模式时，Redis会通过调用系统函数write 将该事务内的所有写操作在本次调用中全部写入磁盘。如果在写入过程中出现系统崩溃，如电源故障导致宕机，此时也许只有部分数据被写入到磁盘，而另一部分数据却已经丢失。Redis服务器会在重启时执行一系列必要的一致性检测，一旦发现类似问题，会立即退出并给出相应的错误提示。 此时需要充分利用Redis 工具包中提供的 redis-check-aof工具来定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复后就可以再次重新启动 Redis服务器了。 Redis做异步队列：使用 list结构作为队列，rpush生产消息， lpop消费消息当lpop没有消息的时候，要适当sleep一会再重试。不使用 sleep: list还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。 使用 pub&#x2F;sub主题订阅者模式，可以实现 1:N 的消息队列。pub&#x2F;sub缺点： 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等 使用Redis 实现可靠的消息队列 ack 机制？消费者用 rpop 取出元素，若消费者在 取出元素之后崩溃了，此时消息 已被取出且没有正确处理，会造成该消息的丢失队列的备份：消费者程序在 从主消息队列中取出消息后，再将其插入到备份队列中，直到消费者程序完成正常的处理逻辑后再将该消息从备份队列中删除。当备份队列中消息过期时，重新将其 再放回到主消息队列中，以便其它的消费者程序继续处理。RPOPLPUSH命令执行过程示意图如下： Redis 如何实现延时队列？使用 sortedset，拿时间戳作为 score，消息内容作为 key调用 zadd来生产消息，消费者用 zrangebyscore指令获取N秒之前的数据轮询进行处理。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"中间件/Redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"持久化-哨兵/集群","slug":"C-中间件/Redis/A2-Redis-持久化-哨兵:集群","date":"2021-07-07T13:55:19.000Z","updated":"2022-04-19T13:06:05.091Z","comments":true,"path":"2021/07/07/C-中间件/Redis/A2-Redis-持久化-哨兵:集群/","link":"","permalink":"http://example.com/2021/07/07/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/A2-Redis-%E6%8C%81%E4%B9%85%E5%8C%96-%E5%93%A8%E5%85%B5:%E9%9B%86%E7%BE%A4/","excerpt":"","text":"Redis-持久化-哨兵&#x2F;集群Redis 简介：1.非常快2.支持丰富的数据类型3.操作具有 原子性，单线程 为什么快？1.数据结构简单，操作的时间复杂度低2.单线程，没有多线程相互切换的开销，避免不必要的上下文切换和锁竞争条件3.所有操作都是基于内存的4.多路I&#x2F;O复用模型，非阻塞IO RDB：快照持久化，根据指定时间内改变的key数量来做持久化（冷备）快照持久化 完全交给 子进程处理，父进程 继续 处理客户端请求。父进程调用 fork函数产生一个子进程 做数据持久化，不会修改现有的内存数据结构，只是对数据结构进行遍历读取，然后序列化写到磁盘中。但父进程继续响应客户端请求，然后对内存数据结构进行不间断的修改。这个时候就会使用 操作系统的 COW 机制来进行 数据段页面 的分离。父进程对其中一个页面的数据进行修改时，将被共享的页面复制一份，并分离出来，然后对这个复制的页面进行修改。这时 子进程 相应的页面是 没有变化的，是一个快照的数据，然后子进程就可以遍历数据进行序列化写磁盘了。 优点：1.性能影响小，网络传输快2.数据恢复速度快3.文件小 缺点：1.无法实时同步，停机时会导致大量丢失数据2.兼容性差（文件需要满足指定格式） AOF (Append Only File-仅追加文件)将每条 写入命令作为日志，以 append-only 的模式写入一个日志文件中，这个模式是 只追加的，没有任何磁盘寻址的开销，速度快；先执行指令再将日志存盘。每次执行 修改内存 中数据集的写操作时，都会 记录 该操作，在持久化恢复时 「重放」 所有的 修改性指令序列，来恢复 Redis 当前实例的内存数据结构的状态。AOF 是 先执行指令再将日志存盘，如果先写日志再操作的话，AOF日志中会出现 很多无效&#x2F;错误的命令记录（一些错误的操作也会记录）对本来就庞大的AOF文件来说就是雪上加霜；这一点不同于 MySQL 等存储引擎，如果先存储日志再做逻辑处理，这样就可以保证即使宕机了，仍然可以通过之前保存的日志恢复到之前的数据状态；AOF 文件采用追加写的方式，避免IO 的随机寻址，优化磁盘写入性能 优点：1.实时持久化，可以做到秒级更新（一秒一次去通过线程 fsync操作，最多丢一秒数据）；2.文件兼容性好，无需满足指定格式；3.文件写入性能快，文件不容易破损； 缺点：1.AOF 文件大；2.恢复数据时对系统性能影响大；3.恢复速度慢； 重写AOF 日志：Redis 在长期运行的过程中，AOF 日志会越变越长，如果宕机重启，重放整个AOF日志会非常耗时，导致长时间Redis 无法对外提供服务，所以需要对AOF日志 “瘦身” 。Redis 提供 bg rewrite aof 指令用于对 AOF 日志进行瘦身；原理：父进程开辟一个子进程，由子进程对内存中的 redis数据库进行遍历 转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件 中，序列化完毕后再将 操作期间发生的 增量AOF日志追加到这个新的 AOF日志文件中，追加完毕后就立即替代旧的AOF 日志文件 AOF 日志是以文件的形式存在的，当程序对AOF 日志文件进行写操作时，实际上是将内容写到 内核为文件描述符分配的一个内存缓存中，内核会异步将脏数据刷回到磁盘。 出现事故时，第一时间用 RDB恢复，然后AOF做数据补全，冷备热备一起上。 突然机器掉电会怎样？取决于AOF日志sync属性的配置，如果不要求性能，在 每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync是不现实的，一般都使用定时sync，比如1s 1次，这个时候最多丢失1s数据 主从复制模型： 主从同步，从从同步主从之间数据同步：1.第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到 内存buffer2.完成后将 RDB快照文件 全量同步到复制节点，然后复制节点将RDB镜像加载到内存3.加载完成后，再通知主节点将 期间修改的操作记录发送过来，复制节点重放这些操作记录4.后续的 增量数据通过 AOF日志同步主从复制模型： 同时使用 RDB 、 AOF 持久化操作 重点：RDB快照数据生成时，缓存区也同时开始接受新请求，来保存同步期间的增量数据传输过程中有什么网络问题，会自动重连，把缺少的数据补上优点：高可用，提高数据读的负载能力缺点：master 主节点故障，无法实现自动故障恢复 哨兵模型： 每个哨兵节点（Sentinal）每隔1秒向master、slave、其他哨兵节点发送 ping命令，如果对方能在指定时间内响应，说明节点健康存活。如果未在规定时间内（可配置）响应，那么该哨兵节点认为此节点 主观下线。 故障恢复过程：1.每个 Sentinal 节点 1次&#x2F;s 向 它所关联的 主, 从 , 其他Sentinal 节点发送 ping命令，心跳检测2.如果一个 节点没有回复 ping 命令，或超时， 将被Sentinal 节点标记为 主观下线3.如果主节点被标记主观下线，与主节点相连的其他Sentinal 节点也监测主节点，当达到一定数量的Sentinal 节点都认为主节点下线了，主节点被标记为客观下线4.选举领导哨兵节点： 当主节点被判断客观下线以后，各个Sentinal 节点会进行协商，选举一个领导哨兵节点，并由该领导节点对其进行故障转移操作监听该主节点的所有哨兵，都有可能被选为领导者，选举算法是 先到先得：即在一轮选举中，哨兵 A 向 B 发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。5.故障转移：选举出的 领导者哨兵，开始进行故障转移操作，分 3个步骤： 在从节点中选择新的主节点，原则:1.首先 过滤掉不健康的从节点； （下线或断线），没有回复过哨兵ping响应的从节点2.然后 根据指定的优先级选择，默认情况下所有的从节点priority值为100，如果倾向于选择同机房的另一台salve节点替代现有的master节点，则可以把同机房的 从节点的 priority值设置的低一些3.如果 优先级无法区分，则选择 复制偏移量最大的从节点；数据更新程度选择4.如果仍无法区分，则选择 runid最小的从节点；每个节点启动的时候都会有一个唯一的runId更新主从状态：通过 slaveof no one命令，让新选出来的从节点成为主节点；并通过 slaveof命令让其他节点成为其从节点，将已经下线的 主节点也设置为从节点。 每个哨兵都设置一个随机休眠时间，苏醒后向其他哨兵发送申请成为领导者的请求；其他哨兵只能对收到的第一个请求进行回复确认 ；首先达到多数确认选票的哨兵节点，成为领导者 Sentinal 节点数量是基数个，通过投票机制来 选出 leader 哨兵，如果当前 选不出来则重新进行投票。 每个Sentinal 节点会把 票投给第一个请求他的 Sentinal 节点 Redis Sentinal 高可用，提高读负载，在 master宕机时会自动将slave提升为master，继续提供服务。Redis Cluster 扩展性，提高写负载，在单个redis内存不足时，使用Cluster进行分片存储。优点： 在复制的基础上，实现自动故障恢复缺点：写操作无法实现负载，存储能力受单机限制 （集群可解决） 集群模型： 16384 &#x3D; 2^14一致性hash ： 2^32 -1想扩展 并发读就添加Slaver，想扩展 并发写就添加Master，想扩容也就是添加Master，任何一个 Slaver或几个Master挂了都不会是灾难性的故障。1.Redis集群是一个由 多个节点组成的分布式服务集群，具有复制、高可用和分片特性2.集群没有中心节点，并且带有 复制和故障转移特性，不会因某个节点下线而影响整个集群3.集群中的 主节点负责处理 槽（储存数据），而从节点则是主节点的 复制品4.主节点只会执行自己槽有关的命令，当节点接收到不属于自己处理的槽的命令时，将会处理指定槽节点的地址返回给客户端，而 客户端会向正确的节点重新发送 各个哨兵模型下 slaver 间相互监听，若有故障随时替换，故障恢复各个 master节点间均分数据分片，当 添加节点，删除节点时，由一致性Hash算法维护现在 服务器都是多核的，如何高效使用 Redis? 通过在单机开多个Redis实例集群中，各个master 节点保存 其他master 的数据槽范围，当出现 数据请求不在当前范围时，返回给 客户端并告诉其应该访问的具体master的 ip 信息。 解决单机 Redis 的瓶颈？集群部署方式： Redis cluster； 主从同步读写分离，类似Mysql的主从同步，Redis cluster 支撑 N 个 Redis master node，对数据分片，每个master node都可以挂载多个slave node。整个Redis 可以横向扩容，如果要支撑更大数据量的缓存，那就横向扩容更多的master 节点，每个master 节点能存放更多数据。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"中间件/Redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Redis数据结构","slug":"C-中间件/Redis/A1-Redis基本数据结构","date":"2021-07-06T13:55:19.000Z","updated":"2022-04-19T13:05:47.032Z","comments":true,"path":"2021/07/06/C-中间件/Redis/A1-Redis基本数据结构/","link":"","permalink":"http://example.com/2021/07/06/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/A1-Redis%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"Redis基本数据结构基本数据结构： String、List、Hash、Set、SortedSet、 bitMap，HyperLogLogString :动态字符串，类似于 Java 中的 ArrayList，一个字符数组； 应用：缓存; 使用 SDS 结构 SDS 与 C 字符串的区别： C 语言使用一个长度 N+1 的字符数组来表示长度为 N 的字符串，字符数组最后一个元素是 ‘\\0’ 1.计数方式不同： C 不保存数组长度，每次都需要遍历一遍整个数组，获取字符串长度 O(N) ； redis 自己本身就保存 长度信息2.避免缓冲区溢出：执行 拼接 or 缩短字符串的操作时，可能出现 缓冲区溢出&#x2F;内存泄漏 的问题现在需要在后面拼接，但是没计算好内存，结果可能因 内存不足，被意外的修改；SDS 结构存储 当前长度+ free未使用长度，在做拼接操作时，会判断是否可以放得下，如果长度够直接执行，如果 不够那就进行扩容 3.减少 修改字符串时带来的内存重分配次数： Redis是个高速缓存数据库，如果需要对字符串进行 频繁的拼接和截断操作，在写代码时忘记了重新分配内存，就可能造成缓冲区溢出，以及内存泄露。Redis为避免 C字符串这样的缺陷，就分别采用了两种解决方案，去达到性能最大化，空间利用最大化：***空间预分配：对SDS进行扩展操作的时候，Redis会为 SDS分配好内存，并且根据特定的公式，分配多余的 free空间，还有多余的 1byte空间（这1byte也是为了存空字符），这样就可以避免连续执行 字符串添加所带来的内存分配消耗。*** 算法动态计算调整free值：字符串变长了，Redis还会根据算法计算出一个 free值给他备用；再继续拼接会发现，备用的 free用上了，省去这次的内存重分配 4.惰性空间释放： 当执行完一个字符串缩减的操作，为了预防继续添加的操作，redis并不会马上收回空间，这样来减少分配空间带来的消耗；当再次操作还没用到多余空间的时候，Redis就会收回多余的空间，防止内存的浪费。调用删减函数，并不会马上释放掉 free空间；如果需要继续添加，则这个空间就能用上，减少内存的重分配，如果空间不需要，调用函数删掉 5.二进制安全： 因为 C 语言中的字符串必须符合某种编码（如 ASCII），中间出现 ‘\\0’ 可能会被判定为提前结束的字符串而识别不了；因此 C的字符串 只能保存文本数据；Redis 保存字符串的长度，不判断空字符而是判断长度； 所以redis 可以保存 各种二进制数据，更加安全； List：双向链表，类似于 Java 中的 LinkedList，插入、删除 性能好，时间复杂度为 O(1)，但索引定位慢，查询 O(n)； 应用：消息队列； 结构： 1234567891011121314typedef struct list&#123; //表 头结点 listNode *head; //表 尾节点 listNode *tail; //链表 长度 unsigned long len; //节点值复制函数 void *(*dup) (viod *ptr); //节点值释放函数 void (*free) (viod *ptr); //节点值对比函数 int (*match) (void *ptr,void *key);&#125;list 特性：1.无环双向链表2.获取表头指针，表尾指针，链表节点长度的 时间复杂度均为O(1)3.链表使用 void *指针来保存节点值，可以保存各种不同类型的值 Hash:数组 + 链表， 类似于 Java 中的 HashMap ，链地址法来解决部分 哈希冲突， 2倍扩容， 初始容量 16. 结构： ht[0]： 用于存放真实的key-vlaue数据； ht[1]：用于扩容(rehash)Redis中哈希算法和哈希冲突跟Java实现的差不多，它俩差异: Redis哈希冲突，链表头插法；JDK1.8后，Java哈希冲突，链表尾插法。 渐进式 rehash：Hash 扩容是比较耗时间的，需重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新数组下面，这是一个 O(n) 的操作，作为 单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 渐进式 rehash 来实现小步搬迁。 在 rehash时，保留新旧两个 hash结构，查询时先查新hash, 没有再查旧hash，并搬迁至新hash; 增加直接加到新hash; 修改先改hash, 没有改旧hash, 然后删除搬迁至新hash; 删除先删新hash, 没有再删旧hash。 扩容条件：当 hash表中 元素个数 &#x3D;&#x3D; 数组.size() 扩容 原数组大小 2 倍。 如果 Redis 正在做 bgsave(持久化命令)，为减少内存，尽量不去扩容，但如果 hash 表非常满，达到一维数组长度 5 倍，这时就会 强制扩容。缩容条件：当 hash 表中 元素个数 &lt; 数组.size() * 10% ，缩容不会考虑 是否在做 bgsave 在对哈希表进行 扩展或者收缩操作时，reash过程并不是一次性地完成的，而是 渐进式地完成的。Redis在 rehash时采取渐进式的原因：数据量如果过大的话，一次性rehash会有庞大的计算量，这很可能导致服务器一段时间内停止服务。Redis具体是rehash时这么干的：1: 在字典中维持一个 索引计数器变量 rehashidx，并将设置为0，表示rehash开始。2:在 rehash期间每次对字典进行 增加、查询、删除和更新操作时，除了执行指定命令外；还会将ht[0]中rehashidx 索引上的值 rehash到ht[1]，操作完成后 rehashidx+1。3:字典操作不断执行，最终在某个时间点，所有的键值对完成rehash，这时将rehashidx设置为-1，表示rehash完成4:在渐进式rehash过程中，字典会 同时使用两个哈希表ht[0]和ht[1]，所有的更新、删除、查找操作也会在两个哈希表进行。例如要查找一个键的话，服务器会优先查找ht[0]，如果不存在，再查找ht[1]，诸如此类。此外当执行新增操作时，新的键值对一律保存到ht[1]，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。 Set ： 键值对 无序、唯一，类似于 Java 语言中的 HashSet， 在 HashMap 的基础上对所有的 value &#x3D; NULL SortedSet（zset）:ziplist + 跳表（ skiplist）； 应用：排行榜 ； 参考： http://blog.jobbole.com/111731/zset 可以按照 用户指定的 排序规则对输入字段进行排序， 支持随机插入、删除同时满足如下条件时, 使用的是 ziplist, 其他时候使用 skiplist1.有序集合保存的元素 数量小于128个2.有序集合保存的所有元素的 长度小于64字节ziplist 为存储结构时,每个集合元素使用 两个紧挨在一起的 压缩列表结点 来保存, 第一个 节点保存元素的成员, 第二个元素保存元素的分值score 。 为什么不考虑平衡树，红黑树？1.性能考虑： 在高并发情况下，树形结构需要执行一些 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化 只涉及局部 ；2.实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单； 在新产生的链表上，每两个相邻的节点增加一个指针，从而产生第三层链表： skiplist 为每个节点随机出一个层数(level)，比如：一个节点随机出的层数 3，就把它链入到 第 1 层到第 3 层这三层链表中 每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此 插入操作只需要 修改节点前后的指针，而不需要对多个节点都进行调整，这就降低插入操作的复杂度。 从刚才创建的这个结构中查找 23 这个不存在的数，查找路径： 跳跃表 重要过程：随机层数：对于每一个新插入的节点，都需要调用 一个随机算法给它分配一个合理的层数；直观上期望的目标是 50% 的概率被分配到 Level 1； 25% 的概率被分配到 Level 2； 12.5% 的概率被分配到 Level 3，以此类推…有 2^(-63) 的概率被分配到最顶层，因为这里每一层的晋升率都是 50%默认允许 最大的层数是 32，当 Level[0] 有 264 个元素时，才能达到 32 层，所以定义 32 完全够用了插入节点：找到当前需要插入的位置 （其中包括相同 score 时的处理）； 创建新节点，调整前后的指针指向，完成插入节点删除: 和插入过程类似，先把 “搜索路径” 找出来，然后对于 每个层的相关节点重排一下 前向后向指针，同时更新一下最高层数 maxLevel 节点更新:当调用 ZADD 方法时，如果对应的 value 不存在，那就是插入过程，如果这个 value 已经存在，只是调整一下 score 的值，那就需要走一个 更新流程如果这个新的 score 值 并不会带来排序上的变化，那就不需要调整位置，直接修改元素的 score 值如果 排序位置改变，那就需要调整位置，把这个元素 删除再插入，需要经过两次路径搜索； 需调整顺序，先删再插 元素排名：跳跃表是有序的， 在 skiplist 的 forward 指针上，为每一个 forward 指针都增加 span 属性，表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点 中间会跳过多少个节点在 插入、删除操作时，都会更新 span 值的大小，所以沿着 “搜索路径”把所有经过节点的 跨度 span 值累加 就可以算出当前元素的最终 rank 值。极端情况, 跳跃表中所有 score 值都是一样，zset 的查找性能会退化为 O(n) BitMap: 位图应用场景：对于统计浏览某个网页的 独立访客数量 UV（Unique visitor）的业务场景，考虑使用 BitMap、 布隆过滤器（缓存穿透） Redis 位图是一个 二进制位组成的数组，数组的每个单元只能存储 0和1。 将数组中的每个 二进制位与用户 ID 一一对应， 使用位图去记录每个用户当日是否访问，存储的 1的个数就是UV数量。以 当天的日期加固定的前缀作为key，建立一个Bitmap，每一位二进制的 offset做为一个用户 ID的标识，当今天用户访问时就将Bitmap中标识此用户的二进制（value）从0置为1。最后统计所有bitmap 中 1 的个数，即为独立访客数量。 HyperLogLog：基数统计 通常是用来 统计一个集合中不重复的元素个数 ；某个网页的 独立访客数量 UV（Unique visitor）的业务场景Bitmap 已经节约了内存，但如果页面访问量非常大（例如用户规模达到1亿），那么用于统计单个页面的UV内存占用需要 100000000&#x2F;8&#x2F;1024&#x2F;1024 ≈ 12M；若分别统计多个页面，则内存占用会线性增加。如果只需要 每天的UV大致统计数量，使用HyperLogLog 比较合适。HyperLogLog 是用来做 基数估计的算法，HyperLogLog 用12K字节的内存占用，可以计算接近 264 个不同元素的基数（UV） 2.比特串的基数估计在UV统计中需要统计一组集合中 不重复元素的个数。利用哈希算法将集合中的数据转换成 0和1构成的二进制数串，那么一个二进制串可以类比为一次抛硬币实验，1是抛到正面，0是反面。使用 MurmurHash2 算法来计算 集合数据的哈希值，该算法有很好的均匀性，即使输入集合数据按规律排列，哈希之后仍能保证数据随机分布，因此可以保证每 bit出现 0或1的概率均为1&#x2F;2，Redis中采用的是MurmurHash2固定64比特版本，另外该算法的计算速度也较快。 HLL算法思想的核心就在于通过 保留少量的比特信息，来 估计或观察消息流。二进制串中从低位开始第一个 1出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数k，那么基于上面的结论，可以 通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，通过第一个1出现位置的最大值 kmax来预估总共有多少个不同数字 分桶平均如果直接应用上面的HLL方法进行基数估计会由于偶然性带来较大的误差，因此 HLL算法采用分桶平均的方法来消减偶然性的误差、提高估计的准确度。1.先把数据 分成若干个分组（桶bucket），估计每个分组的基数2.然后用所有 分组基数的平均数来估计总的基数。Redis 中桶的个数是16384，对于每个哈希值（64bit），14 位作为 桶编号用来定位数据分布的桶位置，剩余的50bit 即伯努利过程，每个桶对应 6 bit大小，记录kmax。举例说明，若 UV值通过Hash 算法得到比特串: 10110000 00000000 01101100 00000100 00101001 11000000 00 000100 00011101后面 14位确定桶编号，即bucket&#x3D;1053; 前面的50 bit 伯努利过程，该例中 kmax&#x3D; 9，那么UV基数估计为29多个桶用平均数计算，HLL采用的是 调和平均方法，然后再基于 因子修正公式计算得出，调和平均较比 几何平均有更高的精度Redis中规定 分桶个数16384，每个桶的kmax用 6bit空间来存放，6*16384&#x2F;8 字节，再加上结构头等数据，加起来一共12304个字节；用12K字节的内存占用，即可 计算接近 264 个不同元素的基数。这和基数越大占用内存越大的其它计算基数的方式形成鲜明对比。但Redis对应内存的节约还不止于此，12K字节内存是 encoding&#x3D;HLL_DENSE(密集)模式下的内存占用；对于基数值比较少，大多数桶的计数值kmax为0的情况，Redis采用HLL_SPARSE稀疏模式的存储，稀疏存储的空间占用远小于12K字节。对密集存储和稀疏存储方式，本文做简单介绍：密集存储的结构很简单，就是连续的 16384个6比特连起来的位图。 稀疏存储 针对的就是很多的桶计数值为 0的情况，因此会有大量连续0的情况出现 使用 set 集合问题： 存储空间巨大： 如果数量庞大，则需要用来存储的 set 集合就会非常大，去重功能将耗费较高的时间复杂度 ，影响性能 统计复杂： 每个场景都需要一个set，对于多个 set 集合，如果要聚合统计一下，也是一个复杂的事情 Redis 过期策略： 定期删除+ 惰性删除定期删除：默认100ms 就随机抽一些 设置了过期时间的key，去检查是否过期，过期了就删如果一直没随机到很多key，里面不就存在大量的无效key了？惰性删除：不主动删，等你来查询我，看看过期没，过期就删了 定期没删，也没查询，那可咋整？ 内存淘汰策略：1.noeviction: 永不删除2.allkeys-random: 无过期时间的数据，随机删除一部分3.allkeys-lru: 无过期时间的数据，删除 最近最少使用的（LRU）4.volatile-random: 设置过期时间的数据，随机删除一部分5.volatile-lru: 有过期时间的数据，删除最近最少使用的（LRU）6.volatile-ttl: 有过期时间的数据，删除 剩余时间最短的（TTL） 缓存穿透：缓存和数据库 中都没有的数据，而用户不断发起请求，导致请求不走缓存，直接访问到数据库，数据库压力过大通常是 请求参数非法导致，(例如 id&#x3D;-1) 解决：1.接口层 增加校验，比如 用户鉴权校验，参数做校验2.在缓存中取不到，数据库中也没有取到，此时将对应Key的 Value 改写：{ null、位置错误、稍后重试 }，参照具体的场景3.布隆过滤器（Bloom Filter）利用bitMap结构和hash算法，判断出这个Key是否在数据库中存在，不存在 return，存在就去查 DB刷新KV 再return 缓存击穿：一个热点 Key，扛着高并发，当这个Key在失效瞬间，持续的高并发击穿缓存，直接请求到数据库解决：1.设置 热点数据永远不过期2.加上互斥锁，保证 同一进程中对同一数据，不会并发请求到DB 缓存雪崩：同一时间多个热点 Key值， 大面积失效，导致大量请求访问到DB解决：1.把每个 Key的失效时间都加个随机值，保证 数据不会在同一时间大面积失效2.设置 热点数据永远不过期3.将 多个热点数据 均匀分布在不同的Redis库中4.使用主从、集群模型，提高缓存服务的高可用缓存雪崩需要做 熔断等策略 事前： Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃 事中： 本地 ehcache 缓存 + Hystrix 限流+降级，避免MySQL被打死 事后： Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"中间件/Redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"多线程-AQS详解","slug":"A-Java语言/多线程/5.AQS详解","date":"2021-06-09T13:55:19.000Z","updated":"2022-04-19T13:04:10.128Z","comments":true,"path":"2021/06/09/A-Java语言/多线程/5.AQS详解/","link":"","permalink":"http://example.com/2021/06/09/A-Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/5.AQS%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"AQS 详解三个线程(线程1，2，3)同时来加锁&#x2F;释放锁：目录1.线程一加锁成功时 AQS内部实现2.线程二&#x2F;三加锁失败时 AQS中等待队列的数据模型3.线程一释放锁，及线程二获取锁实现原理4.通过线程场景来讲解Condition中await()和signal()实现原理 1.线程一加锁成功：如果同时有三个线程并发抢占锁，此时线程一抢占锁成功，线程二和线程三抢占锁失败，具体执行流程如下： 此时AQS内部数据为： 2.线程二、线程三加锁失败： 有图可以看出，等待队列中的节点Node是一个 双向链表线程二抢占锁失败,按照真实场景来分析，线程一抢占锁成功后，state变为1，线程二通过 CAS修改state变量必然会失败，此时AQS中FIFO队列中数据如图: 线程一将state修改为1，所以线程二通过 CAS修改state的值不会成功，加锁失败。线程二执行 tryAcquire()后会返回false，接着执行addWaiter(Node.EXCLUSIVE)逻辑，将自己加入到一个FIFO等待队列中。 3.线程一释放锁线程一释放锁，释放锁后会 唤醒head节点的后置节点，就是线程二。线程二设置为head节点，然后空置之前的head节点数据，被空置的节点数据等着被垃圾回收。 线程二 释放锁 &#x2F; 线程三加锁：当线程二释放锁时，会唤醒被挂起的线程三，流程和上面大致相同，被唤醒的线程三会再次尝试加锁 4.Contition实现原理： await()方法中首先调用 addConditionWaiter()将当前线程加入到Condition队列中，执行完可以看到 Condition队列中的数据： ​ 这里会用当前线程创建一个 Node节点，waitStatus为CONDITION。 接着会释放该节点的锁，调用之前解析过的release()方法，释放锁之后，会唤醒被挂起的线程二，线程二会继续尝试获取锁。接着调用 isOnSyncQueue()方法判断当前节点是否为 Condition队列中的头部节点，如果是则调用LockSupport.park(this)挂起 Condition中当前线程。此时线程一被挂起，线程二获取锁成功。 ​ 线程二执行 signal()方法：首先我们考虑下线程二已经获取到锁，此时AQS等待队列中已经没有数据。这里先从transferForSignal()方法来看，Condition队列中只有线程一创建的一个Node节点，且waitStatue为CONDITION，先通过CAS修改当前节点waitStatus为0，然后执行enq()方法将当前线程加入到等待队列中，并返回当前线程的前置节点。加入等待队列的代码在上面也已经分析过，此时等待队列中数据如下图： 接着开始通过CAS修改当前节点的前置节点waitStatus为SIGNAL，并且唤醒当前线程。等线程二释放锁后，线程一会继续重试获取锁，结束。 参考：https://mp.weixin.qq.com/s/trsjgUFRrz40Simq2VKxTA ​ https://mp.weixin.qq.com/s/iNz6sTen2CSOdLE0j7qu9A","categories":[{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程-详解知识点","slug":"A-Java语言/多线程/4.多线程-详解知识点","date":"2021-06-08T13:55:19.000Z","updated":"2022-04-19T13:03:57.717Z","comments":true,"path":"2021/06/08/A-Java语言/多线程/4.多线程-详解知识点/","link":"","permalink":"http://example.com/2021/06/08/A-Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/4.%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E8%AF%A6%E8%A7%A3%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"多线程-详解知识点1. 线程:是 CPU 进行 运算调度的最⼩基本单位，包含在进程之中，没有 独立的资源，共享其进程中的资源，每个线程都有 自己独立的 运行栈和程序计数器（PC），线程之间切换的开销小，系统不会为线程分配内存. 2. 线程安全和线程不安全？线程安全: 多线程访问时，采用加锁机制，当一个线程访问 该类的某个数据时，进行保护，其他线程不能进⾏访问，直到该线程读取完，其他线程才可使用, 不会出现数据不一致问题。 线程不安全：不提供数据访问保护，有可能出现 多个线程先后更改数据 造成所得到的数据是脏数据； 线程安全问题 都是由 全局变量，静态变量引起的，若有多个线程同时执行写操作，一般需要考虑线程同步，否则可能影响线程安全。 多线程：是指从 软件或硬件上实现多个线程的并发技术。 多线程的好处：i. 使用 多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视屏的下载 ii. 发挥 多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好 多线程的缺点：1.大量的 线程降低代码的可读性； 2.更多的 线程需要更多的内存空间 3.当 多个线程对同一个资源出现争夺时候要注意 线程安全的问题。 3. ⾃旋锁1.当线程 A 想要获取一把自旋锁⽽该锁又被其它线程锁持有时，线程 A会在⼀个循环中自旋以检测锁是不是已经可用。 2.自旋锁需要注意： 由于 自旋时不释放CPU，持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直自旋，浪费CPU时间。 持有自旋锁的线程在 sleep 之前应该释放自旋锁，以便其它线程可以获得自旋锁。 3.目前的 JVM实现自旋会 消耗CPU，如果⻓时间不调用 doNotify方法，doWait方法会一直自旋，CPU会消耗太大 4.自旋锁比较适用于 锁使用者 ，保持锁时间比较短 的情况，这种情况自旋锁的效率比较高 5.自旋锁是一种对 多处理器相当有效的机制，⽽在单处理器非抢占式的系统中基本上没有作⽤ 4. 乐观锁和悲观锁悲观锁： 每次都加重锁，认为其他线程会访问共享变量 乐观锁： 轻量级的锁，认为其他线程不会访问共享变量，修改时进行判断，通过 cas 乐观锁技术 保证数据⼀致性。 5. 原⼦操作在 Java Concurrency API中有些原⼦类(atomic classes) 原子操作：一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的⼿段。 int++： 并不不是一个原子操作，所以当⼀个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。 解决问题：java.util.concurrent. atomic 包提供了int和long类型，它们可以自动的保证操作是原子的并且不需要使用同步。 6. Executors框架Java通过 Executors 提供四种线程池，分别为： 1.newSingleThreadExecutor 创建一个单线程线程池，只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 2.newFixedThreadPool 创建一个固定数量线程池，可控制线程最大并发数，超出的线程会在队列中等待。 3.newCachedThreadPool 创建一个可缓存线程池，如果 线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 4.newScheduledThreadPool 创建一个定⻓线程池，支持 定时及周期性任务执行。 7. 阻塞队列 JDK7 提供了 7个阻塞队列（也属于并发容器） ArrayBlockingQueue ：一个由 数组结构组成的 有界阻塞队列 LinkedBlockingQueue ：一个由 链表结构组成的 有界阻塞队列 PriorityBlockingQueue ：一个 支持优先级排序的 无界阻塞队列。 DelayQueue：一个使用 优先级队列实现的 无界阻塞队列。 SynchronousQueue：一个不存储元素的 阻塞队列。 LinkedTransferQueue：一个由链表结构组成的 无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的 双向阻塞队列。 概念： 阻塞队列 是一个在队列基础上又支持 两个附加操作的队列。 附加操作： 支持阻塞的 插入方法：队列满时，队列会阻塞插入元素的线程，直到队列不满。 支持阻塞的 移除方法：队列空时，获取元素的线程会等待队列变为非空。 8. Callable和Future获取线程的执行结果时使用，Callable 用于产生结果，Future用于获取结果； Callable 接口使用 泛型去定义它的返回类型，Executors 类提供一些有用的方法在线程池中执⾏Callable内的任务。由于Callable任务是并行的，必须等待它返回的结果。java.util.concurrent.Future对象解决了这个问题。 在线程池提交Callable任务后返回一个Future对象，使用它可以知道 Callable任务的状态和得到Callable返回的执⾏结果。Future提供了get()方法，等待Callable结束并获取它的执行结果。 9. FutureTaskFutureTask 可用于 异步获取执行结果或取消执行任务的场景。 通过传入Runnable或 Callable的任务给 FutureTask，直接调用其 run方法或放入线程池执行，之后可以在外部通过 FutureTask的 get方法异步获取执行结果，因此 FutureTask 非常适合⽤于耗时的计算，主线程可以在完成⾃己的任务后，再去获取结果。另外，FutureTask还可以确保 即使调用多次 run方法，它都只会执行一次 Runnable或 Callable任务，或通过 cancel 取消 FutureTask的执行等。 FutureTask 可用于执行 多任务、以 避免高并发情况下多次创建数据锁的出现。 10. 同步容器 和 并发容器同步容器： 主要代表有 Vector和 Hashtable，以及 Collections.synchronizedXxx等； 锁的 粒度为当前对象整体； 迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛ConcurrentModificationException。 并发容器： 主要代表有 ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。 锁的粒度是分散的、细粒度的，即读和写是使⽤不同的锁。 迭代器具有弱一致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。 11. 多线程的上下文切换CPU 通过 时间片分配算法来循环执行任务，当前一个任务执行一个时间片后，会切换到下一个任务。但在切换前会保存上一个任务的状态，以便下次 切换回这个任务时，可以再次加载这个任务的状态。 12.ThreadLocal的作用​ ThreadLocal 类允许 创建 只能被同一个线程读写的变量。因此，如果⼀段代码含有一个 ThreadLocal变量的引用，即使 两个线程同时执行这段代码，它们也 无法访问到对方的ThreadLocal变量量。 线程局部变量: 在并发编程的时候，成员变量如果不做任何处理, 线程是不安全的，各个线程都在操作同⼀个变量，显然是不行的，volatile这个关键字也是不能保证线程安全的。那么在有一种情况之下，需要满足这样⼀个条件：变量是同一个，但每个线程都使用同一个初始值，也就是使用同一个变量的一个新的副本。这种情况之下 ThreadLocal就⾮常适用，比如说 DAO的数据库连接，DAO是单例的，它的属性 Connection 就不是一个线程安全的变量。每个线程都需要使用他，并且各自使用各自的。这种情况，ThreadLocal 就比较好的解决了这个问题。 ​ 每个线程都维护了一个map，而这个map的 key就是 threadLocal，而值就是我们set的那个值，每次线程在 get的时候，都从⾃己的变量中取值，既然从⾃己的变量中取值，那肯定就不存在线程安全问题。ThreadLocal这个变量的状态根本没有发生变化，他仅是充当一个 key的⻆色，另外提供给每一个线程一个初始值。 13. ThreadPool（线程池）用法与优势优点： 1.减少 创建和销毁线程的次数，每个工作线程都可以被重复利用，可执⾏多个任务 2.可以根据系统的承受能力，调整 线程池中工作线程的数目，防⽌因为消耗过多的内存，而把服务器累趴下 (每个线程需要⼤约 1MB内存，线程开的越多，消耗的内存也就越大，最后死机)；减少在 创建和销毁线程上所花的时间以及系统资源的开销 如不使⽤用线程池，有可能造成系统创建⼤量线程⽽导致消耗完系统内存 Java⾥⾯线程池的顶级接口： Executor，但严格意义上讲 Executor并不是⼀个线程池，⽽只是⼀个执⾏线程的⼯具，真正的线程池接⼜是 ExecutorService。 当线程数 &lt; corePoolSize时，创建线程执⾏行行任务。 当线程数 &gt;&#x3D; corePoolSize并且 workQueue没有满时，放入workQueue中 线程数 &gt;&#x3D;corePoolSize并且 workQueue满时，新任务新建线程运行，线程总数要 &lt; maximumPoolSize 当线程总数 &#x3D;maximumPoolSize并且 workQueue满了的时候，执行 handler的rejectedExecution 拒绝策略 14.CAS 产生的ABA 问题原节点 A ，改变头节点 2次， 先改为 B， 改变B 指针的指向（插入链表的表头，成为新头节点），最后再改回节点 A ，对于节点，其实际的 值没有改变，但此时 指针的指向 已经发生了改变 解决： 加入版本号，在内部维护一个状态戳（时间戳），每次修改对象值的同时，也改变状态戳， 在校验 CAS 时，同时校验 对象值+ 状态戳 的期望值（类似于MVCC 中记录数据的版本号操作） 15. volatile关键字作用*从主内存中加载 最新的数据 *对共享变量修改后，立刻重写回主内存，即时刷新重写 *为了获取更好的性能 JVM可能会对指令进行重排序，volatile则会对 禁⽌语义重排序 1. 如何获取 线程 dump(堆栈)⽂件线程 dump 堆栈； 死循环、死锁、阻塞、⻚面 打开慢等问题，查看线程 dump是最好的解决问题的途径。 获取到线程堆栈有两步： 1.获取到线程的 pid，通过 ps命令， ps -ef | grep java 2.打印线程堆栈，通过 jstack pid 命令，在 Linux环境下还可以使⽤用 kill -3 pid 3.Thread类提供了一个 getStackTrace()方法， 可以获取线程堆栈。此方法和具体线程实例绑定，每次获取到的是某个线程当前运行的堆栈。 2. 创建 线程的方式 继承 Thread类，重写 run方法 实现 Runnable接口并重写 run方法，实现Runnable接口实现类的实例对象，作为Thread构造函数的target 实现 Callable接口，通过 FutureTask包装器来创建Thread线程 通过 线程池创建线程 3.多线程线程数量设置A. 高并发、任务执行时间短的业务： 线程池线程数可以设置为 CPU核数+1，减少线程上下⽂的切换。 B. 并发不高、任务执行时间长的业务： *假如是业务时间长集中在 IO操作上，也就是 IO密集型的任务，因为IO操作并不占⽤用CPU，所以不要让所有的CPU 闲下来，可以加⼤线程池中的线程数目，让CPU处理更多的业务 *假如是业务时间长集中在计算操作上，也就是 计算密集型任务，这个就没办法了，和 (1)一样，线程池中的 线程数设置得少一些，减少线程上下文的切换 C. 并发高、业务执行时间长：解决这种类型任务的关键不在于线程池⽽在于整体架构的设计， 第一步：看这些业务⾥面 某些数据是否能做缓存 第二步：增加服务器 第三步：使用 中间件 对任务进行 拆分和解耦 4. 锁的等级：方法锁、对象锁、类锁1.方法锁，synchronized修饰方法时 a. 通过在 方法声明中加入 synchronized 关键字来声明 synchronized 方法。 b. synchronized 方法控制对 类成员变量的访问： c. 每个 类实例对应一把锁，每个 synchronized 方法都必须获得 调用该方法的 类实例的锁 方能执行，否则所属线程阻塞，⽅法一旦执行，就独占该锁，直到 从该方法返回时才将锁释放，此后被 阻塞的线程方能获得该锁，重新进⼊可执行状态。 这种机制确保了同一时刻对于每一个类实例，其所有声明为 synchronized 的成员函数中至多只有一个处于可执行状态，从⽽有效避免了类成员变量的访问冲突。 2.对象锁，synchronized修饰方法或代码块 a. 当一个对象中有synchronized method或synchronized block的时候调用此对象的同步方法或进入其同步区域时，必须先获得对象锁。如果对象锁已被其他调用者占用，则需要等待此锁被释放。（⽅法锁也是对象锁） b. java的所有对象都含有 1个互斥锁，这个锁由 JVM自动获取和释放。线程进入 synchronized⽅法的时候获取该对象的锁，当然如果已经有线程获取了这个对象的锁，那么当前线程会等待；synchronized方法正常返回或者抛异常而终止，JVM会⾃动释放对象锁。这里也体现了用 synchronized来加锁的1个好处，⽅法抛异常的时候，锁仍然可以由JVM来自动释放。 3.类锁(synchronized 修饰静态的方法或代码块) a. 由于一个class不论被实例化多少次，其中的静态⽅法和静态变量在内存中都只有一份。所以，一旦一个静态的⽅法被申明为synchronized。此类所有的实例化对象在调用此方法，共用同一把锁，我们称之为 类锁。 4.对象锁 是用来控制实例方法之间的同步，类锁 是用来 控制静态方法（或静态变量互斥体）之间的同步 总结： 在某个对象的所有synchronized方法中,在某个时刻只能有一个唯一的一个线程去访问这些synchronized方法 如果一个方法是synchronized方法,那么该synchronized关键字表示给当前对象上锁(即this)相当于 synchronized(this){} 如果⼀个synchronized方法是static的,那么该synchronized表示给当前对象所对应的class对象上锁(每个类不管生成多少对象,其对应的class对象只有⼀个) 5.并行、并发的区别 并行指两个或多个事件在同一时刻发生； 并发指两个或多个事件在 同一时间间隔发生。 并行 是在不同实体上的多个事件，并发是在 同一实体上的多个事件。 并行是在多台处理器上同时处理多个任务；并发是在一台处理器上“同时”处理多个任务。 并发编程的⽬标是充分的利⽤处理器的每⼀个核，以达到最⾼的处理性能 6.唤醒一个阻塞的线程wait与notify：wait与notify 配合synchronized使用，调用之前持有锁，wait会立即释放锁，notify同步块执行完才释放。 await与singal：Condition类提供，由 new ReentLock().newCondition() 获得Condition对象，与 wait和 notify相同，因为在使用 Lock锁后无法使用wait方法。 park与 unpark：LockSupport 是一个线程阻塞工具，可以在 线程任意位置让线程阻塞。和 Thread.suspenf()相比，它弥补了由于 resume() 在前发生，导致线程⽆法继续执行的情况。和Object.wait()相⽐，它 不需要先获得某个对象的锁，也不会抛出 IException异常。可以唤醒指定线程。 7. 如何检测死锁，预防死锁死锁：两个或两个以上的进程在执行过程中，因 争夺资源而造成一种互相等待 的现象，若无外力作用，它们都将⽆法推进下去。 产生死锁必要条件： 互斥条件：进程对所 分配到的资源 不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至释放该资源 请求和保持：进程获得资源后，对其他资源发请求，但该资源可能被其他进程占有，此时请求阻塞，但它对已获得资源保持不放 不可剥夺：进程 已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放 循环等待：进程发⽣ 死锁后，若干进程之间形成⼀种 头尾相接的 循环等待资源关系 死锁产生原因： 1.竞争资源发⽣死锁：多个进程共享的资源数目不足以满⾜全部进程的需要，引起对资源的竞争 2.进程 推进顺序不当发⽣死锁 8. 守护线程守护线程（daemon thread），是个服务线程，用于服务其他的线程 Java中线程分2种： 1.守护线程，⽐如 垃圾回收线程，最典型的守护线程 2.用户线程，应用程序里的自定义线程 9. synchronized和ReentrantLock 区别可重入锁：同一个线程可以多次获取同一把锁，ReentrantLock和synchronized都是可重入锁。 可中断锁：线程尝试获取锁的过程中，是否可以响应中断。synchronized 不可中断，ReentrantLock可中断 公平锁： 多个线程 同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序， 非公****平锁：允许线程“插队”, synchronized：非公平锁， ReentrantLock的默认：非公平锁，但可以设置为公平锁 Synchronized Synchronized是 java内置的关键字，它提供了一种独占的加锁方式；Synchronized 的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。 局限性： 当线程尝试获取锁的时候，如果 获取不到锁会一直阻塞。 如果 获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。 ReentrantLock: ReentrantLock它是JDK 1.5之后提供的 API层面的互斥锁，需要 lock() 和 unlock()方法配合 try&#x2F;finally语句块来完成。 等待可中断避免，出现死锁的情况 （如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回 true，如果等待超时，返回false） 公平锁与非公平锁 多个线程等待同一个锁时，必须按照 申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock 默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁 选择性通知： Synchronized只能通过notify, notifyAll 随机唤醒一个或多个等待的线程； ReentrantLock可以和Contition实例配合，指定的线程注册到指定的Contition实例中，实现选择性唤醒。 10. Lock接⼝(Lock interface)Lock 接⼝比同步方法和同步块提供更具扩展性的锁操作，他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持 多个相关类的条件对象。 优势： 可以使 锁更公平 可以使 线程在等待锁的时候响应中断 可以让 线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 可以在 不同的范围，以不同的顺序获取和释放锁 11. ConcurrentHashMap 并发度1、工作机制（分片思想）：它引入了一个 “分段锁”的概念，具体可以理解为把一个大的Map拆分成N个小的segment， 根据 key.hashCode()来决定把 key放到哪个HashTable中。可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。 2、应用：当读 &gt; 写时使用，适合做缓存，在程序启动时初始化，之后可以被多个线程访问； hash冲突：HashMap中调用 hashCode()方法计算hashCode。由于在Java中两个不同的对象可能有一样的 hashCode, 所以不同的键可能有一样hashCode，从而导致冲突的产生。 hash冲突解决：使用平衡树来代替链表，当同一hash中的元素数量超过 8 时会由链表切换到平衡树 无锁读：ConcurrentHashMap 有较好的并发性，因为 ConcurrentHashMap是 无锁读和加锁写，并且利用分段锁（不是在所有的entry上加锁，而是在一部分entry上加锁）； ConcurrentHashMap的并发度就是 segment的⼤小，默认为16，这意味着最多同时可以有16条线程操作 ConcurrentHashMap，这也是 ConcurrentHashMap对Hashtable的最⼤优势。 JDK 1.7 后，ConcurrentHashMap 升级为 数组首节点加锁 12. CyclicBarrier 和 CountDownLatch 区别CyclicBarrier 和 CountDownLatch 都位于 java.util.concurrent 这个包下 CountDownLatch: 减计数； 计算&#x3D;0时释放所有等待线程； 计数为0后无法重置，不可重复利用； 调用countDown() 方法计数-1，调用await() 方法只进行阻塞，对技术没有任何影响。 CyclicBarrier: 加计数； 计数&#x3D;指定值时，释放所有等待线程； 计数&#x3D;指定值，计数置为0重新开始，可重复利用； 调用await() 方法计数+1， +1后&lt; 指定值时，线程阻塞； 13. Fork&#x2F;Join作用1.Fork ： 把一个 大任务切分为若⼲子任务并行的执行。 2.Join ： 合并这些子任务的执行结果，最后得到这个⼤任务的结果。 14. wait()和sleep() 区别sleep()方法： 线程类（Thread）的静态方法，让调用 线程进入睡眠状态，让出执行机会给其他线程，等到休眠时间结束后，线程进入 就绪状态和 其他线程一起竞争cpu的执⾏时间。 因为 sleep() 是 static静态的方法，它不能改变对象的锁，当一个 synchronized 块中调⽤ sleep()方法，线程虽然进入休眠，但是对象的锁没有被释放，其他线程依然无法访问这个对象。 wait()方法： Object类的方法，当一个线程执行到 wait方法时，它就进入到一个和 该对象相关的等待池，同时释放对象的锁，使得其他线程能够访问，可以通过notify，notifyAll⽅法来唤醒等待的线程 15. 线程的五个状态（创建、就绪、运⾏、阻塞、死亡） 创建状态：生成线程对象，并 没有调用该对象的 start方法，这是线程处于创建状态。 就绪状态：调用线程对象的 start方法之后，进入就绪状态，没有获得时间片则不会执行，从等待或睡眠中醒来，也会处于就绪状态 运行状态： 线程调度程序将 就绪线程设置为当前线程，此时进入运行状态，开始运行 run()函数当中的代码。 阻塞状态： 线程正在运行时被暂停，为等待某个事件的发生(资源就绪)之后再继续运行，sleep, suspend,wait等方法可以导致线程阻塞。 死亡状态： 一个线程 run()方法执行结束或调用stop()方法后，该线程就会死亡，对于死亡的线程，无法再使用 start⽅法使其进入就绪。 16. start()和 run()方法区别1.start()方法来 启动一个线程，真正实现多线程运行。 2.如果直接调用 run(), 其实就相当于是调用一个普通函数而已，直接调用 run()方法必须等待run()方法执行完毕才能执行下面的代码，所以执行路径还是只有一条，根本没有线程的特征，所以在多线程执行时要使用 start()方法而不是run()方法。","categories":[{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程-编程实战","slug":"A-Java语言/多线程/3.多线程-编程实战","date":"2021-06-07T13:55:19.000Z","updated":"2022-04-19T13:03:53.325Z","comments":true,"path":"2021/06/07/A-Java语言/多线程/3.多线程-编程实战/","link":"","permalink":"http://example.com/2021/06/07/A-Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/3.%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/","excerpt":"","text":"多线程-编程实战奇偶数循环打印，交替执行实例：ReantrantLock() 使用： 12345678910111213141516171819202122232425262728293031323334353637383940public static int state = 0;public static Lock mylock = new ReentrantLock();static class RunnableA implements Runnable&#123; @Override public void run() &#123; for(int i=0; i&lt;10; )&#123; try &#123; mylock.lock(); if(state % 2==0)&#123; System.out.println(&quot;Thread A: &quot; + String.valueOf(i)); state++; i++; &#125; &#125;finally &#123; mylock.unlock(); &#125; &#125; &#125;&#125;static class RunnableB implements Runnable&#123; @Override public void run() &#123; for(int i=0; i&lt;10; )&#123; try&#123; mylock.lock(); if(state % 2==1)&#123; System.out.println(&quot;Thread B: &quot; + String.valueOf(i)); state++; i++; &#125; &#125;finally&#123; mylock.unlock();; &#125; &#125; &#125;&#125; 使用 Synchronized：1234567891011121314151617181920212223242526272829303132333435363738394041424344public static int state = 0;static class RunnableA implements Runnable&#123; @Override public void run() &#123; for(int i=0; i&lt;10; )&#123; synchronized(this)&#123; if(state % 2==0)&#123; System.out.println(&quot;Thread A: &quot; + String.valueOf(i)); state++; i++; &#125; &#125; &#125; &#125;&#125;static class RunnableB implements Runnable&#123; @Override public void run() &#123; for(int i=0; i&lt;10; )&#123; synchronized(this)&#123; if(state % 2==1)&#123; System.out.println(&quot;Thread B: &quot; + String.valueOf(i)); state++; i++; &#125; &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; Thread t1 = new Thread(new RunnableA()); Thread t2 = new Thread(new RunnableB()); t1.start(); t2.start();&#125;","categories":[{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程-高级","slug":"A-Java语言/多线程/2.多线程-高级","date":"2021-06-06T13:55:19.000Z","updated":"2022-04-19T13:03:49.461Z","comments":true,"path":"2021/06/06/A-Java语言/多线程/2.多线程-高级/","link":"","permalink":"http://example.com/2021/06/06/A-Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/2.%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E9%AB%98%E7%BA%A7/","excerpt":"","text":"多线程-高级CAS（Compare And Swap 比较并且替换）是乐观锁的一种实现方式，线程在读取数据时不进行加锁，先保存原值，在实际修改数据的瞬间，比较此时的值，是否和原值相等。若相等则回写；若不相等，则重新执行读取流程。 CAS产生的问题：一、CAS可能有 ABA问题： （破坏了事务的原子性） 线程1 读取数据A 线程2 读取数据A，把数据A改成数据B 线程3 读取数据B，把数据 B 又改回数据A 线程1 通过CAS比较，发现数据还是 A没变，就写成了自己要改的值 解决：加标志位（类似版本号），设置 自增字段，操作一次自增+1；或搞个时间戳，比较时间戳的值；每次修改： 数据+版本号；版本号递增，校验时同时校验： 数据 + 版本号例如：操作数据库，根据CAS原则本来只要查询原本的值，现在需要一同查出他的标志位版本字段 vision 二、长时间循环等待：CAS 长时间不成功的话，会导致一直自旋（死循环），CPU开销较大。三、只保证 一个共享变量的原子操作：CAS操作单个共享变量赋值时 可以保证原子操作，但多个变量就不行； Atomic 相关类：AtomicInteger，AtomicBoolean 等 java.util.concurrent包下面的类，只能并发修改一个属性AtomicInteger 类利用 CAS + volatile 和 native 方法 来保证原子操作，避免 synchronized 的高开销，执行效率大为提升。内部使用 UnSafe 类 objectFieldOffset() 一个本地方法，可以得到 “原来的值”的内存地址，返回值 valueOffset； value 是一个volatile变量，在内存中可见，JVM 可以保证 任何时刻，任何线程 总能拿到该变量的最新值。 AtomicReference：AtomicReference 可以保证 对象操作的原子性；不单单仅限于 Integer, Boolean, Long等类型和 AtomicInteger 类似，AtomicInteger是 对整数的封装，而 AtomicReference 则是对普通对象的引用，它可以保证在修改对象引用时的线程安全性。 AtomicReference原子性的作用是对 ”对象”进行原子操作；提供一种 读 和 写都是原子性的对象引用变量。 原理： 通过 “volatile” 和 “Unsafe 提供的 CAS函数实现”原子操作 value是 volatile类型，保证当某个线程修改 value值时，其他线程看到的 value值都是最新的，即修改之后的volatile的值 通过 CAS设置value，保证当某个线程池通过CAS函数(如compareAndSet)设置value时，操作是原子的，即线程在操作value时不会被中断需要借用Unsafe类的原子操作使用场景：当涉及到 比较，设置等，多于一个操作时，使用AtomicReference ； 升级： AtomicStampedReference类通过引入 时间戳作为数据的版本号，来解决ABA 问题。 悲观锁：访问共享资源前，先要上锁，认为多线程同时修改共享资源的概率高，容易出现冲突互斥锁：一个线程获得锁，其他线程无法再次获得，挂起等待锁的释放；加锁失败时，会做「线程切换」，当加锁失败的线程再次加锁成功，这一过程会有两次线程上下文切换的成本，性能损耗大。自旋锁：加锁失败时不会主动产生线程切换，忙等待直到获得锁；如果被锁代码执行时间短，那忙等待的时间相对应也短。 读写锁：原理：当「写锁」没有被线程持有时，多个线程能够并发的持有读锁，提高共享资源访问效率；因为「读锁」是用于读取共享资源，多个线程同时持有读锁不会破坏共享资源。一旦「写锁」被线程持有，读线程获取读锁的操作会被阻塞，其他写线程获取写锁的操作也会被阻塞。写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁；读锁是共享锁，因为读锁可以被多个线程同时持有。应用场景：在读多写少 读写锁可以分为「读优先锁」和「写优先锁」读优先锁 ：期望读锁能被更多的线程持有，提高读线程的并发性。方式：当读线程A 持有读锁，写线程B 在获取写锁时会被阻塞，在阻塞过程中，后续来的读线程C 仍可以成功获取读锁，直到读线程A 和C 释放读锁后，写线程B 才可以成功获取读锁。写优先锁：优先服务写线程；方式：读线程A 先持有读锁，写线程B 在获取写锁时会被阻塞，阻塞过程中，后续读线程C 获取读锁时会失败，被阻塞在获取读锁的操作上，这样只要读线程A 释放读锁，写线程B 就可以成功获取读锁。 总结：读优先锁：对于读线程并发性更好，但可能出现 写线程「饥饿」的现象。写优先锁：保证写线程不会饿死，但如果一直有写线程获取写锁，读线程也会被「饿死」。解决：公平读写锁，用队列把获取锁的线程排队，读，写线程都按照先进先出原则加锁，这样就不会出现「饥饿」现象。 乐观锁：乐观锁：假定冲突的概率很低，先修改共享资源，再验证这段时间 内有没有发生冲突。没有其他线程修改，则操作成功；发现有其他线程修改，则放弃本次操作。使用场景：在冲突概率低，加锁成本高冲突概率上升，不适合乐观锁，因为解决冲突的重试成本非常高。注意：加锁代码的范围尽可能的小，加锁的粒度要小，这样执行速度会比较快。 ThreadLocal :数据隔离，填充的数据只属于当前线程，变量数据对别的线程而言是相对隔离的，多线程环境下，防止自己的变量被其它线程修改。 存储结构：​ value 实际上存储在ThreadLocalMap中，ThreadLocalMap 是ThreadLocal的一个 静态内部类，它的 key是 ThreadLocal实例对象，value是任意Object对象。每个线程实例都对应一个 TheadLocalMap实例，在同一个线程里实例化很多 ThreadLocal来存储很多种类型的值，这些ThreadLocal实例分别作为key，对应各自的value，存储在 Entry table 数组中。set获取当前线程的ThreadLocalMap，然后往map里添加 KV，K是当前ThreadLocal实例，V是我们传入的valueget获取当前线程对应的私有变量，是之前set或通过 initialValue的值 ​ ThreadLocal 能做到线程间的数据隔离，别的线程使用get() 方法没办法拿到其他线程的值. 每个线程 Thread 都维护自己的threadLocals变量，在每个线程创建 ThreadLocal 时，实际上数据是存在 线程Thread的 threadLocals中的 ThreadLocalMap 里，别人没办法拿到，从而实现隔离。 ThreadLocal内存模型原理： 线程的一些局部变量和引用：Stack（栈）区； 普通对象：Heap（堆）区1.线程运行时，定义的 TheadLocal对象被初始化，存储在Heap，同时线程运行的栈区保存指向该实例的引用，也就是图中的ThreadLocalRef。2.当 ThreadLocal的 set &#x2F; get 被调用时，虚拟机会根据当前线程引用，查看对应的TheadLocalMap实例是否被创建，如果没有则创建并初始化3.虚线，表示 key对应的 ThreadLocal实例的引用是个弱引用。 建议：1.需要 存储 线程私有变量的时2.需要实现 线程安全的变量时3.需要 减少线程资源竞争的时 ThreadLocalMap底层使用数组，如何解决Hash冲突？一个线程可以有多个 TreadLocal 来存放不同类型的对象，他们都放到当前线程的 ThreadLocalMap里，一个线程一个数组来存。ThreadLocalMap存储时，给每一个ThreadLocal对象一个 threadLocalHashCode，插入过程中根据 ThreadLocal对象的hash值，定位到 table中的位置id ，然后判断当前位置 是否为空，为空就初始化一个Entry对象放在位置id上； 如果位置id 不空，这个Entry对象的 key &#x3D; 计算出来的hash值，则更新 Entry中的value；如果位置id 不空，且 Entry 对象的 key !&#x3D;计算出来的hash值， 则找下一个空位置。set和get如果冲突严重的话，效率会降低。 ThreadLocal 实例及其值存放在哪？ ThreadLocal实例实际上被其创建的类持有，而ThreadLocal的值是被线程实例持有，位于堆上，只是通过一些技巧将 可见性修改成了线程可见。 如何共享 一个线程的ThreadLocal数据？ 使用 Inheritable ThreadLocal可以实现多个线程访问ThreadLocal的值。例：在主线程中创建一个InheritableThreadLocal实例，在 子线程中得到这个Inheritable ThreadLocal实例设置的值。 ThreadLocal 内存泄漏：ThreadLocalMap 使用的 key 为 ThreadLocal 的弱引用, 而 value 是强引用。如果ThreadLocal 没有被外部强引用，在垃圾回收时 key 会被清理掉，而 value 不会被清理掉。这样 ThreadLocalMap 中会出现 key为null的Entry。假如不做任何措施，value 永远无法被GC 回收，导致内存泄露。解决：每次使用完 ThreadLocal，调用 remove()方法，清除数据。 ThreadLocalMap的key 为什么设计成弱引用？ 如果 key不设置成 弱引用，会造成 entry中 value一样内存泄漏的场景。 CountDownLatch:允许一个或 多个线程一直等待，直到 count&#x3D;0，唤醒所有线程。一个线程调用await() 时，阻塞当前线程。有线程调用一次 countDown() 时，计数 -1。当 count &#x3D; 0 时，被阻塞线程全部唤醒。 CyclicBarrier (barrier 障碍, cyclic 循环）一组线程互相等待，直到所有线程都到达一个同步点。例：一组运动员比赛 100米，当所有人都准备完成之后，才可以一起开跑。 CountDownLatch 和CyclicBarrier 区别： 1.CountDownLatch 是一个线程等待其他线程， CyclicBarrier 多个线程互相等待。2.CountDownLatch 计数 -1 直到 0，CyclicBarrier 计算 +1，直到指定值。3.CountDownLatch 是一次性的， CyclicBarrier 可以循环利用。 AbstractQueuedSynchronizer（AQS）ReentrantLock、ReentrantReadWriteLock、CountDownLatch 都是基于AQS实现的 AQS实现原理：AQS中维护一个 volatile int state（共享资源）和 一个 FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。state 初始化 0，多线程条件下线程要执行 临界区的代码，首先获取 state。 某个线程获取成功后， state +1，其他线程再获取的话，由于共享资源已被占用，将阻塞线程放到 FIFO 等待队列 中，等占有 state 的线程执行完，释放资源( state -1)后，会唤醒 FIFO 中下一个等待线程去获取 state。 state 由于是多线程共享变量，所以定义成 volatile，保证 state 可见性, 并通过 CAS 来保证其并发修改的安全性。FIFO 等待队列是一个双向链表，head 结点代表当前占用的线程，其他节点由于暂时获取不到锁，依次 排队等待锁的释放 AQS定义两种资源共享方式1.Exclusive（独占）：只有一个线程执行； 如ReentrantLock，可分为公平锁和非公平锁： **公平锁：按照线程在队列中的排队顺序，先到者先得锁 **非公平锁：获取锁时，无视队列顺序直接抢锁，谁抢到是谁的 2.Share（共享）：多线程同时执行，如CountDownLatch ​ 获取独占式锁过程对做个总结: AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后-&gt;将线程构造成Node节点(addWaiter)-&gt;将Node节点添加到同步队列对尾(addWaiter)-&gt;节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点单获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。 AQS 内部维护一个线程的队列。队列由内部的节点组成。队列的节点为Node,节点分为SHARED和EXCLUSIVE分别时共享模式的节点和独占模式的节点。节点的等待状态为waitStatus CANCELLED(1):取消状态，当线程不再希望获取锁时，设置为取消状态 SIGNAL(-1):当前节点的后继者处于等待状态，当前节点的线程如果释放或取消了同步状态，通知后继节点 CONDITION(-2):等待队列的等待状态，当调用signal()时，进入同步队列 PROPAGATE(-3): 共享模式，同步状态的获取的可传播状态 0：初始状态 AQS共享模式和 独占模式的实现上最大的差别就在于共享模式获取锁后的传播。其他的区别主要还是表现在实现类实现的区别上。通过ReentrantLock和ReentrantReadWriteLock可以了解AQS的独占模式和共享模式，但是要注意将AQS和锁的实现剥离开，弄明白哪些逻辑是AQS实现的，哪些逻辑是锁实现的，同时也思考怎么使用AQS实现其他的特定的线程同步问题。 公平锁和非公平锁：非公平锁和公平锁的区别：非公平锁性能高于公平锁性能。非公平锁可以减少 CPU唤醒线程的开销，整体的吞吐效率会高点，CPU不必 唤醒所有线程，减少唤起线程的数量问题：非公平锁存在线程饥饿的情况，可能某个线程一直获取不到锁. AQS 组件：1.Semaphore(信号量)-允许多线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源2.CountDownLatch ： 一个同步工具类，协调多线程之间的同步。用来控制线程等待，让某一个线程等待直到倒计时结束，再开始执行。3.CyclicBarrier ： CyclicBarrier 和 CountDownLatch 类似，可以实现线程间的等待，但功能比 CountDownLatch 更复杂和强大。主要应用场景和 CountDownLatch 类似，CyclicBarrier 可以让 一组线程到达一个屏障（同步点）时被阻塞，直到 最后一个线程到达屏障时，屏障才会打开，所有被屏障拦截的线程才会继续执行。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，参数表示 屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。 排他锁：只有一个线程可以访问共享变量；共享锁：允许多个线程同时访问重入锁是排他的；信号量是共享的 AQS内部结构：AQS中有一个同步等待队列，保存等待在这个锁上的线程。为了维护等待在 条件变量上的等待线程，AQS维护一个条件变量等待队列，就是由 Condition.await() 引起阻塞的线程。一个重入锁可以生成 多个条件变量对象，因此一个重入锁 可能有多个条件变量等待队列。每个条件变量对象内部都维护一个等待列表。 同步等待队列，条件变量等待队列，都使用 同一个 Node类作为链表的节点Node 中包括链表的上一个元素 prev，下一个元素next 和线程对象thread，对于条件变量等待队列，还使用nextWaiter表示下一个等待在条件变量队列中的节点。 Condition ：Condition是用来替代Object的 wait()，notify() 方法的，使用Condition中await()，signal()可以更加安全，高效的实现线程间协作。 Condition 和 wait&#x2F;notify 比较：1.Condition 可以精准的 对多个不同条件进行控制，wait&#x2F;notify 只能和 synchronized关键字一起使用，只能唤醒一个或全部的等待队列；2.Condition 使用 Lock进行控制，使用后要 unlock()，Condition 有类似于 await 的机制，不会因为加锁而产生死锁问题，底层实现park&#x2F; unpark 机制，不会产生死锁，但wait&#x2F;notify 可能会产生先唤醒再挂起的死锁。 对系统资源占用不同：虽然都释放了CPU，但阻塞的进程仍处于内存中，而挂起的进程通过“对换”技术被换出到外存（磁盘）中。 发生时机不同：阻塞一般在进程等待资源（IO资源、信号量等）时发生；而挂起是由于用户和系统的需要，例如，终端用户需要暂停程序研究其执行情况或对其进行修改、OS为了提高内存利用率需要将暂时不能运行的进程（处于就绪或阻塞队列的进程）调出到磁盘 恢复时机不同：阻塞要在等待的资源得到满足（例如获得了锁）后，才会进入就绪状态，等待被调度而执行；被挂起的进程由将其挂起的对象（如用户、系统）在时机符合时（调试结束、被调度进程选中需要重新执行）将其主动激活 一般线程中的阻塞： A、线程执行了Thread.sleep(int millsecond);方法，当前线程放弃CPU，睡眠一段时间，然后再恢复执行B、线程执行一段同步代码，但是尚且无法获得相关的同步锁，只能进入阻塞状态，等到获取了同步锁，才能回复执行。C、线程执行了一个对象的wait()方法，直接进入阻塞状态，等待其他线程执行notify()或者notifyAll()方法。D、线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。比如说监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。 非公平锁和公平锁的区别：非公平锁性能高于公平锁性能。非公平锁可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量非公平锁性能虽然优于公平锁，但是会存在导致线程饥饿的情况。在最坏的情况下，可能存在某个线程一直获取不到锁。不过相比性能而言，饥饿问题可以暂时忽略，这可能就是ReentrantLock默认创建非公平锁的原因之一了 多线程编程详解： https://blog.csdn.net/mu_wind/article/details/113806680","categories":[{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程-基础","slug":"A-Java语言/多线程/1.多线程编程-基础","date":"2021-06-05T13:55:19.000Z","updated":"2022-04-19T13:03:38.177Z","comments":true,"path":"2021/06/05/A-Java语言/多线程/1.多线程编程-基础/","link":"","permalink":"http://example.com/2021/06/05/A-Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1.%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"多线程编程-基础Java 中创建线程方式主要有三种：1.继承 Thread 类，重写run() 方法，在run() 方法里实现内部逻辑2.实现 Runnable 接口， 重写 Runnable 接口中的 run 方法，在 thread 类中传入 Runnable对象3.实现 Callable 接口，重写 call() 方法，和 Future 来创建线程 Callable 和 Runnable 接口区别：1.Runnable 不会产生任何返回值, Callable 有返回值2.Callable重写 call 方法，而 Runnable 重写 run 方法。3.使用 Callable 中的 call方法可以抛出异常，而 Runnable 方法不能抛出异常 使用：执行 Callable方式，需要 FutureTask 实现类的支持，用于接收运算结果 1234ThreadDemo td = new ThreadDemo();FutureTask&lt;Integer&gt; result = new FutureTask&lt;&gt;(td);Integer sum = result.get();class ThreadDemo implements Callable&lt;Integer&gt; &#123;..其中实现call() 方法..&#125; 可重入锁： 同一个线程可以反复获得同一把锁，但申请和释放锁的次数必须一致。 重入锁是非公平的，公平的重入锁性能差 重入锁内部基于CAS实现的 对于重入锁，可以使用 Condition类提供的await()，singal()功能，实现线程间通信可重入锁优势：可以避免一些死锁的情况，更好的封装可重入性：Synchronized 锁对象时，对象头关联的monitor中有个计数器，会记录下线程获取锁的次数，获得锁+1，释放锁-1，当计数器清零时就释放锁。 不可中断性：一个线程获取锁后，另一个线程处于阻塞或等待状态，前一个不释放，后一个则会一直阻塞或等待，不可以被中断。 对象在 JVM 的内存中分为三块区域：1.对象头 * Mark Word（标记字段）：锁标志位信息…随着锁标志位的变化而变化。 * Klass Point（类型指针）：指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例。 2.实例数据：存放类的数据信息，父类的信息。 3.对其填充：虚拟机要求对象起始地址必须是 8字节的整数倍，为了字节对齐。 问题：一个空对象占多少个字节？ 8个字节，因为对齐填充的关系，不到8个字节对其填充会自动补齐。 对象头关联一个monitor对象，当进入一个方法的时候，会获取当前对象的所有权，monitor进入数 +1，当前线程拥有 monitor的所有权。 Synchronized锁：​ 在 JDK1.6之前，Synchronized 属于重量级锁，效率低。 JDK1.6之后，Synchronized 锁升级的过程：无锁、偏向锁、轻量级锁、重量级锁。随着竞争的激烈而逐渐升级，注意：锁可以升级不可降级，为了提高获得锁和释放锁的效率。从无锁状态，首先进入的线程获得偏向锁，当前释放后，此时如果同一个线程再次获得锁，锁不升级，偏向于同一线程；此时如果其他线程获得锁，并产生锁的竞争，则将锁升级为轻量级锁。偏向锁: 采用CAS操作，每次同一线程进入，虚拟机就不进行任何同步操作，对标志位+1，不同线程过来，CAS操作失败。CAS操作：jvm会存储 锁对象Mark Word 拷贝，然后利用 CAS比较当前的Mark Word和保存的Mark Word，相同就说明加锁成功，改变锁标志位轻量级锁（自旋锁）：升级到轻量级锁后，同样也使用CAS操作判断。如果同一线程，CAS成功修改monitor中计算器+1。如果CAS操作失败，则自旋，一旦可以获取资源，就直接尝试成功，直到超出自旋阈值（10）。则自旋失败，升级为重量级锁，像1.5一样，等待唤醒。轻量级锁通过不断自旋，来防止线程被挂起；线程等待唤醒 是 用户态和内核态 的切换，此过程很耗资源，可通过自旋减少这种消耗(短时间) synchronized三种使用方式：1.修饰实例方法: 在当前对象实例上加锁，进入同步代码前要获得当前对象实例的锁2.修饰静态方法: 给当前类加锁，会作用于类的所有对象实例。3.修饰代码块: 指定加锁对象，对给定的对象进行加锁，进入同步代码库前，先要获得 给定对象的锁。 总结：synchronized关键字加到 static 静态方法和 synchronized(class) 代码块上都是给 Class 类上锁synchronized 关键字加到 实例方法上是给 对象实例上锁尽量不要 synchronized(String a) ，因为JVM中字符串常量池具有缓存功能！ synchronized和 ReentrantLock 的区别 （都是可重入锁）：1.层次：synchronized是 JVM层面，ReentrantLock是 API层面。synchronized由jvm负责加锁，释放锁等操作，不需要我们维护；RentrantLock 是需要 lock() 和 unlock() 方法配合 try&#x2F;finally 语句块来完成2.中断: synchronized是不可中断的，ReentrantLock 是可中断的，通过 lock.lockInterruptibly() 实现，可以使正在等待的线程选择放弃等待3.指定公平锁，非公平锁：synchronized只有非公平锁；ReentrantLock 可以通过参数设置公平，非公平锁。4.选择性通知（锁可以绑定多个条件）：synchronized关键字与 wait()和 notify()&#x2F;notifyAll()方法相结合可以实现 等待&#x2F;通知机制，但被通知的线程是由 JVM 选择无法控制，如果执行 notifyAll()方法会通知所有处于等待状态的线程； 用 ReentrantLock类结合 Condition实例可以实现“选择性通知” ，Condition 可以为不同线程 注册不同的 Condition实例，执行 Condition实例的 signalAll()方法时 只会唤醒注册在该Condition实例中的所有等待线程。 Synchronized 不可逆问题：例：我现在是滴滴，早上有打车高峰，代码使用了大量的synchronized，锁升级过程是不可逆的，过了高峰我们还是重量级的锁，那效率降低。根据具体场景进行选择 Volatile : 可见性、有序性​ 所有共享变量都存储于主内存，线程对变量的操作(读，取)是在 工作内存中完成的，而不是直接读写主内存中的变量。不同线程之间不能直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存中转来完成。 工作内存和主内存的关系： ​ 多个处理器运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，那同步回到主内存时以谁的缓存数据为准呢？为解决一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI等。 MESI（缓存一致性协议）：当 CPU写数据时，如果发现操作的变量是共享变量，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中该变量的缓存行是无效的，就会从内存重新读取。加锁可以解决可见性问题：某一个线程进入 synchronized代码块，线程获得锁，会清空工作内存，从主内存拷贝共享变量最新的值到工作内存成为副本，执行代码后，将修改后的 副本值刷新回主内存中，线程释放锁。而获取不到锁的线程会阻塞等待，所以变量的值肯定一直都是最新的。 Volatile修饰的共享变量：volatile使用缓存一致性协议，当一个线程修改了volatile修饰的变量，立即修改写回主内存，同时发信号通知其他线程将该变量的 缓存行置为无效状态，当其他线程需要读取这个变量时，发现自己缓存中该变量的缓存行是无效的，就会从内存重新读取，得到最新数据。 怎么发现数据是否失效呢？ 嗅探： 每个处理器通过 嗅探在总线上传播的数据来检查自己缓存的值是不是过期，当处理器发现自己缓存行对应的内存地址被修改，就会将当前自己的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 总线风暴：由于Volatile的 MESI缓存一致性协议，需要不断的从主内存嗅探和 cas 不断循环，无效交互会导致总线带宽达到峰值。 所以不要大量使用Volatile。有序性：禁止指令重排序什么是重排序? 为了提高处理速度，JVM会对代码进行编译优化，也就是指令重排序优化，并发编程下指令重排序会带来一些安全隐患：如 指令重排序导致的多个线程操作之间的不可见性 如何保证不会被重排序呢？内存屏障 Volatile借助Java编译器，在 生成指令系列时的适当位置插入 内存屏障 指令，来 禁止特定类型的处理器重排序。Volatile 写：在前面和后面分别插入内存屏障； 而volatile读：在后面插入两个内存屏障。 Volatile 无法保证原子性要实现原子性操作，可以考虑加锁、原子类，比如 AtomicInteger； volatile与synchronized的区别:1.volatile只能修饰 变量（实例变量、类变量），而 synchronized可以修饰 方法，以及代码块。2.volatile保证数据的可见性，但不保证原子性(多线程同时进行写操作，不保证线程安全); synchronized 两者都能保证。3.volatile 主要解决变量在多个线程之间的可见性，而 synchronized主要解决多线程之间访问资源的同步性。4.多线程访问 volatile不会发生阻塞，而synchronized 可能会发生阻塞。 volatile可以看做是轻量版的synchronized，volatile不保证原子性。如果一个共享变量进行多个线程的赋值，没有其他操作，那可以用volatile来代替synchronized，因为赋值本身是原子性的，而volatile又保证可见性，所以可以保证线程安全。 使用场景： 某个属性被多个线程共享，其中一个线程修改后，其 他线程可以立即得到修改后的值 volatile提供可见性，任何一个线程对其的修改将立马对其他线程可见，volatile属性不会被线程缓存，始终从主存中读取。 volatile可以使得 long和double的赋值是原子的。 Volatile可以在 单例双重检查中实现可见性和 禁止指令重排序，从而保证安全性。 Volatile 禁止指令重排序好处: 创建对象需要几个步骤： 1.分配内存空间; 2.调用构造器，初始化实例 ; 3.返回地址给引用 ​ 在执行时可能发生指令重排序，有可能 构造函数在对象初始化完成前就赋值完成，在内存里开辟一片存储区域后直接返回内存的引用，这个时候还没真正的初始化完对象。但是别的线程去判断 instance!&#x3D;null，直接拿去用了，其实这个对象是个半成品，那就有空指针异常了。 常见的线程池种类：SingleThreadPool 单个线程：若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。FixedThreadPool 固定线程数量：线程数量始终不变。当一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，新任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。CachedThreadPool 动态分配线程数量：根据具体的任务数量来调整线程数量的线程池，若有空闲线程可以复用，会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 线程池的构建方法：1.构造方法实现： ThreadPoolExecutor(6个参数)2.使用 Executor 框架的工具类 Executors来实现 线程池的参数，ThreadPoolExecutor 构造函数重要参数：1.corePoolSize : 核心线程数，定义最小可以同时运行的线程数量。核心线程数，默认情况下，核心线程会一直存活，但是当将allowCoreThreadTimeout 设置为true时，核心线程也会超时回收。2.maximumPoolSize : 当队列中存放的任务达到队列容量的时候，可以同时运行的线程数量变为最大线程数。3.workQueue: 缓存队列当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务会被存放在队列中。4.keepAliveTime: 当线程池中的线程数量大于 corePoolSize 时，此时如果没有新任务提交，核心线程外的线程 不会立即销毁，而是等待直到时间超过 keepAliveTime才会被回收销毁；5.unit : keepAliveTime 参数的时间单位。6.handler : 饱和策略；当线程数量达到maximumPoolSize，并且workQueue中任务满时，执行饱和操作。 ThreadPoolExecutor 饱和策略：1.ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。2.ThreadPoolExecutor.DiscardOldestPolicy： 此策略将 丢弃最早的未处理的任务请求。3.ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException 异常，拒绝新任务的处理。4.ThreadPoolExecutor.CallerRunsPolicy：增加队列容量，调用执行自己的线程运行任务。如果应用程序可以承受此延迟并且不允许丢弃任何一个任务请求，可以选择。这种策略会降低对于新任务提交速度，影响程序的整体性能。 阻塞队列：阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。非阻塞队列：入队和出队操作均利用CAS（compare and set）更新，这样允许多个线程并发执行，并且不会因为加锁而阻塞线程，使得并发性能更好。2.LinkedBlockingQueue可以高效的处理并发数据，这是因为生产者和消费者端分别采用了独立的锁来控制数据同步，所以在高并发的情况下生产者和消费者可以并行地操作队列中的数据，从而提高整个队列的并发性能。 3.如果没有给 LinkedBlockingQueue 指定其容量大小，则默认为 Integer.MAX_VALUE，这样的话，如果生产者的速度大于消费者的速度，则可能还没等到队列阻塞，系统内存就被消耗完了，从而导致内存溢出 线程池中线程数量的设置：CPU密集型的任务：较小线程数IO密集型的任务：较多线程数由于 IO操作不占用CPU，不能让CPU闲。但如果线程数目太多，线程切换所带来的开销也会对系统的响应时间带来影响。 线程等待时间所占比例越高，需要越多线程。线程CPU时间 所占比例越高，需要越少线程。 123CPU 的使用率 50% （ 线程CPU时间/(线程等待时间+线程CPU时间）），那么这段时间可以运行 2 个IO任务最佳线程数目 = （（ 线程等待时间+线程CPU时间）/ 线程CPU时间 ）* CPU数目 Atomic 原子类 （一个操作是不可中断的）：AtomicInteger 类主要利用 CAS + volatile 来保证原子操作，避免 synchronized 的高开销，提升执行效率。 JUC 包中的4种 原子类：基本类型：AtomicInteger：整形原子类 等；数组类型：AtomicIntegerArray：整形数组原子类； 引用类型：AtomicReference：引用类型原子类； 线程中常用的方法： .join() 方法（类似中断）： 导致当前运行的线程停止执行，直到它加入的线程完成其任务，调用 join 时带上一个超时参数，来设置到期时间，时间到期 join方法自动返回。类似于中断，先执行其他线程，再返回来执行原来这个。 execute() 和 submit() 的区别： execute() 无返回值，无法判断任务 是否被线程池执行成功。 submit() 有返回值， 线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以 判断任务是否执行成功，并且通过 Future 的 get() 方法来获取返回值，get() 方法会阻塞当前线程直到任务完成。 start(), run() 区别：1.调用 Thread.start( ) 方法启动一个线程，此线程是处于 就绪状态，并没有运行2.然后通过此 Thread类来调用 run() 方法，完成其运行操作，run() 称为线程体，它包含这个线程要执行的内容，run()方法运行结束，此线程终止，之后CPU再运行其它线程。run()方法当作普通方法的方式调用，程序还是要顺序执行，还是要等待run方法体执行完毕后才可继续执行后续代码。如果直接用Run方法，这只是调用一个方法而已，程序中依然只有主线程–这一个线程，其程序执行路径还是只有一条，这样就没有达到多线程目的。run() 只是在当前线程中执行任务，而 start才是 真正生成thread，并放在cpu中调度。 参考：https://blog.csdn.net/xyy1028/article/details/107801358","categories":[{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Kafka-高级","slug":"C-中间件/消息队列/3.Kafka 性能优化-高级","date":"2021-05-09T13:55:19.000Z","updated":"2022-04-19T13:04:53.063Z","comments":true,"path":"2021/05/09/C-中间件/消息队列/3.Kafka 性能优化-高级/","link":"","permalink":"http://example.com/2021/05/09/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/3.Kafka%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E9%AB%98%E7%BA%A7/","excerpt":"","text":"Kafka 性能优化-高级性能问题主要是三个方面：网络、磁盘、复杂度；对于 Kafka 分布式队列，网络、磁盘 是优化的重点解决方案：并发、压缩、批量、缓存 Kafka 为什么快？ 顺序读写磁盘 零拷贝网络和磁盘 数据批量压缩，传输，减少网络 IO 损耗 Partition 并行和可扩展 高效的文件数据结构设计 优秀的网络模型（基于 Java NIO） 1.顺序读写磁盘完成一次磁盘IO，经过 寻道、旋转、数据传输三个步骤，如果写磁盘时 省去寻道、旋转可以极大地提高磁盘读写的性能。虽然使用硬盘存储，但仍然速度很快。Kafka 采用 顺序写文件的方式来提高磁盘写入性能，基本减少了 磁盘寻道和旋转的次数。Kafka 中 每个分区是一个有序的，不可变的消息序列，新消息不断追加到 Partition 的末尾，在 Kafka 中 Partition 只是一个逻辑概念，将 Partition 划分为多个 Segment，每个 Segment 对应一个物理文件，Kafka 对 segment 文件追加写，这就是顺序写文件。 2.零拷贝网络和磁盘 传统的 IO流程，先读取 网络IO，再写入磁盘IO，实际需要将数据 Copy 四次 第一次：读取 磁盘文件 到 操作系统 内核缓冲区；DMA搬运的 第二次：将 内核缓冲区 的数据，copy 到 应用程序的 buffer；CPU 第三步：将 应用程序 buffer 中的数据，copy 到 socket buffer (网络发送缓冲区); CPU 第四次：将 socket buffer 的数据，copy 到 网卡，由 网卡进行网络传输。 DMA磁盘 —&gt; 内核 buf—&gt; 用户 buf—&gt; Socket buf—&gt; 网卡内核 buf —&gt; Socket buf —&gt; 网卡 Kafka 实现零拷贝，在模型中上下文切换数量减少一倍，只有 2次copy，只有DMA来进行数据搬运，而不需要CPU。第一次通过 DMA，从 磁盘 —&gt; 内核读缓冲区第二次根据 Socket的描述符信息，使用 DMA 直接从 内核缓冲区—&gt;写入到 网卡缓冲区零拷贝是尽量去减少上面数据的拷贝次数，减少拷贝的 CPU开销，减少用户态内核态的上下文切换次数，从而优化数据传输的性能。 同一份数据的 传输次数从 四次变成两次，并且没有通过 CPU来进行数据搬运，所有数据都通过 DMA来进行传输。没有在内存层面去复制数据，所以这个方法也被称为零拷贝。 DMA（Direct Memory Access） 技术：​ 在主板上放⼀块独立的芯片，在进行 内存 和 I&#x2F;O设备的数据传输 时，不再通过 CPU 控制数据传输，而直接通过 DMA控制器 ，传统的 从硬盘读取数据，然后再通过 网卡向外发送，需要进行四次数据传输，其中有两次是发生在内存里的缓冲区和对应的硬件设备之间，没法节省掉。但是还有两次，完全是通过 CPU在内存里面进行数据复制，在 Kafka里，通过 Java 的 NIO 里面 FileChannel的 transferTo方法调用，可以不用把 数据复制到应用程序的内存里面。通过DMA的方式，可以把 数据从内存缓冲区 直接写到 网卡的缓冲区里面。 ​ DMAC 是一个 协处理器芯片，通过这个芯片，CPU 只需要告诉 DMAC，我们要 传输什么数据，从哪里来，到哪里去，就可以放心离开了；后续的实际数据传输工作，都会有 DMAC 来完成。随着现代计算机各种外设硬件越来越多， 光一个通用的 DMAC 芯片不够了，我们在各个外设上都加上了 DMAC 芯片，使得 CPU 很少再需要关心数据传输的工作了。 数据传输工作用不到多少 CPU 核新的“计算”功能，发送数据使用sendfile： Page Cache 作用 缓存最近被访问的数据 预读功能 如果 producer 生产与 consumer消费 速度差不多，可以只对 broker page cache 读写来完成整个生产–消费过程，磁盘访问非常少，producer 生产消息到 Broker ，Broker 按偏移量写入数据，此时数据会先写入 page cache内存区域。consumer 消费消息时，Broker 将数据从 page cache 传输到 Socket buffer，再将 Socket Buffer的数据 copy到网卡，由网卡进行网络传输。 page cache中的数据会随着内核中 flusher 线程的调度写回到磁盘，不用担心数据丢失。如果 consumer要消费的消息不在page cache里，会去磁盘读取。 3.批量发送与压缩Producer 向 Broker 发送消息不是一条一条的发送， 而是进行批量发送，将消息缓存在本地，等到定条件 发送到 Broker；1.消息条数； 2.固定一段时间 Producer 执行流程如下图： Serialize：序列化传递的消息 (序列化后可提高网络传输效率) Partition：决定将消息写入主题的哪个分区 Compress：压缩消息，提高传输速度（生产者—&gt;代理），提高吞吐量，降低延迟并提高磁盘利用率 Accumulate：消息累计器，每个 Partition维护一个双端队列，队列保存将要发送的批次数据，Accumulate将数据累计到一定数量，或在一定时间内，将数据以批次的方式发送出去， 主题中的每个分区都有一个单独的累加器 &#x2F; 缓冲区。 Group Send：记录每个分区的消息数量，当达到定义大小 或达到定义的延迟时间时，将它们发送到的分组 压缩作用： 减少传输的数据量，减轻对网络的传输压力Producer、Broker 和 Consumer 使用相同的压缩算法， producer 向 Broker 写入数据，Consumer 向 Broker 读取数据时不用解压缩，当消息发送到Consumer 后才解压，这样将 节省大量网络开销Producer 压缩之后，Consumer 需进行解压，虽然增加 CPU的工作，但在对大数据处理上，瓶颈在网络而不是CPU，所以这个成本是值得的注意：「批量发送」+「数据压缩」一起使用，单条做数据压缩的话，效果不明显 4.Partition 并行和可扩展​ 每个 Partition是一个队列，同一个 Group下不同 Consumer并发消费 Paritition，Paritition分区是并行度最小单元，每增加一个 Paritition就增加了一个消费的并发。 Kafka 具有分区分配算法—StickyAssignor，保证分配尽量均衡，每一次重分配结果尽量与上一次分配结果保持一致。各个 Broker和 Consumer的处理不至于出现太大倾斜 分区多导致的问题：客户端&#x2F;服务器端 需要使用更多的内存：客户端 producer 有个参数 batch.size，默认是 16KB。它会为每个分区缓存消息，一旦满了就打包将消息批量发出。因为这个参数是分区级别的，如果分区数量变多，则 缓存所需的内存也会变得更多。 恢复数据慢：分区越多，每个 Broker上分配的分区也就越多，当发生 Broker 宕机，那么恢复时间将很长 5.高效的文件数据结构消息以 Topic为单位进行归类，各个 Topic之间是彼此独立的，互不影响。每个 Topic可以分为一个或多个分区，每个分区各自存在一个记录消息数据的日志文件,每个分区日志在物理上按大小被分成多个 Segment。 segment file 组成： index file 和 data file， 2 个文件一一对应，成对出现（索引文件 .index ，数据文件 .log）segment 文件命名规则：partition 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。index 采用稀疏索引，这样每个 index文件大小有限。Kafka 采用 mmap的方式，直接将 index文件映射到内存，这样对 index 就不需要操作磁盘IO。mmap的 Java实现对应MappedByteBuffer 。 Mmap: 一种 内存映射文件的方法​ 将一个文件或其它对象映射到 进程的地址空间，实现 文件磁盘地址和 进程虚拟地址空间中一段虚拟地址 一一对映关系。实现这样的映射关系后，进程可以采用 指针的方式读写操作这段内存，而系统会自动回写脏页面到对应的文件磁盘上，即对文件进行操作，不必调用 read, write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而实现不同进程间的文件共享。 Memory Mapped Files（mmap）： 将磁盘文件映射到内存, 用户通过修改内存达到修改磁盘文件的效果接收来自socket buffer的网络数据，应用进程不需要中间处理、直接进行持久化时。——可以使用mmap内存文件映射。原理：直接利用操作系统的 Page来实现文件到物理内存的直接映射, 完成映射之后对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。通过 mmap，进程像 读写硬盘一样读写内存（虚拟机内存），也不必关心内存的大小（有虚拟内存兜底），这种方式可以获取很大的 I&#x2F;O提升，省去了用户空间到 内核空间复制的开销。 Mmap问题：不可靠，写到 mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush的时候才把数据真正的写到硬盘。 解决：Kafka 提供一个参数——producer.type 来控制是不是主动flush；如果Kafka写入到mmap之后就立即flush然后再返回Producer叫同步(sync)；写入mmap之后立即返回 Producer不调用flush叫异步(async)。 mmap+write 方式持久化数使用 mmap+write 方式代替原来的 read+write 方式，mmap 是一种内存映射文件的方法Mmap将 磁盘文件映射到 内存，支持读和写，对 内存的操作会反映在磁盘文件上。原理：将 读缓冲区地址和 用户缓冲区地址进行映射，内核缓冲区 和 应用缓冲区共享，减少从读缓冲区到用户缓冲区的一次CPU拷贝 虚拟内存现代操作系统都使用虚拟内存，使用虚拟地址取代物理地址，这样做的好处是：1.一个以上的 虚拟地址可以指向同一个物理内存地址2.虚拟内存空间可大于实际可用的物理地址 利用第一条特性可以把 内核空间地址和 用户空间的虚拟地址映射到同一个物理地址，这样 DMA 就可以 填充对内核和用户空间进程同时可见的缓冲区了；省去内核与用户空间的往来拷贝， Java 也利用操作系统的此特性来提升性能，下面重点看看 Java 对零拷贝都有哪些支持。 6.优秀的网络模型（基于 Java NIO）Kafka 底层基于 Java NIO，采用 Reactor 线程模型，做的网络模型 RPC在传统阻塞 IO 模型中问题：1.每个连接都需要 独立线程处理，当并发数大时，创建线程数多，占用资源；2.采用阻塞IO模型，连接建立后，若当前线程没有数据可读，线程会阻塞在读操作上，造成资源浪费 针对传统阻塞IO模型的两个问题，解决方案： 1.基于 池化思想：避免为每个连接创建线程，连接完成后将业务处理交给线程池处理 2.基于 IO复用模型：多个连接共用同一个阻塞对象，不用等待所有的连接，遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理 Reactor 线程模型思想： 基于 IO复用 + 线程池​ Reactor 模型基于 池化思想，当 连接完成后 将业务处理交给线程池处理，避免为 每个连接创建线程；基于 IO 复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理。实现原理：Reactor 模式 ：处理并发 I&#x2F;O 常见模式，将所有要 处理的 IO 事件注册到一个中心 I&#x2F;O 多路复用器上，同时 主线程&#x2F;进程 阻塞在多路复用器上；一旦有 I&#x2F;O 事件到来或准备就绪 (文件描述符或 socket 可读、写)，多路复用器返回并将事先注册的相应 I&#x2F;O 事件分发到对应的处理器中。​ Reactor 利用事件驱动机制实现，应用程序需提供相应接口，并注册到Reactor 上，如果相应事件发生，Reactor将主动调用应用程序注册的接口。 epoll 模式已经可以使服务器并发几十万连接的同时，维持极高 TPS，为什么还需要 Reactor 模式？原因：原生的 I&#x2F;O 复用编程复杂性比较高（ epoll ）例如：编程中，处理请求 A 时，可能经过多个 I&#x2F;O 操作 A1-An，每经过一次 I&#x2F;O 操作，再调用 I&#x2F;O 复用时，I&#x2F;O 复用的调用返回里，可能不再有 A，而返回了请求 B。请求 A 会经常被请求 B 打断，处理请求 B 时，又被 C 打断。使得编程较为复杂。 Reactor 模型 主要分为三个角色：*Reactor： 把 IO 事件分配给对应的 handler 处理*Acceptor：处理客户端连接事件*Handler： 处理非阻塞的任务 Acceptor线程用于处理新的连接，Handler 线程处理业务逻辑I&#x2F;O 多路复用可以把多个 I&#x2F;O 阻塞，复用到同一个 select 阻塞上，从而使得系统在单线程情况下，可以同时处理多个客户端请求，不需要创建新的线程，降低了系统的资源开销 Reactor线程模型分类：根据 Reactor的数量和处理资源的线程数量的不同，分为三类： 单Reactor单线程模型；单Reactor多线程模型；多Reactor多线程模型。 单Reactor单线程模型：在Reactor中处理事件，并分发事件，如果连接事件交给acceptor处理，如果是读写事件和业务处理，就交给 handler处理，但始终只有一个线程执行所有的事情。问题：1.仅用一个线程处理请求，对于多核资源机器来说是有点浪费的。2.当处理读写任务的线程负载过高后，处理速度下降，事件会堆积，严重的会超时，可能导致客户端重新发送请求，性能越来越差。3.单线程也会有可靠性的问题。 单Reactor 多线程模型：和单线程模型主要区别： 把业务处理从之前的单一线程脱离出来，换成线程池处理。Reactor线程 只处理 连接事件和读写事件，业务处理交给 线程池处理，充分利用多核机器的资源，提高性能并且增加可靠性。问题：1.Reactor线程承担所有的事件，例如监听和响应，高并发场景下单线程存在性能问题 多Reactor多线程模型：和单Reactor多线程模型相比，把 Reactor线程拆分 mainReactor和 subReactor两个部分，mainReactor 只处理连接事件，mainRactor只处理连接事件，用一个线程来处理就好。读写事件交给subReactor来处理，处理读写事件的subReactor个数一般和CPU数量相等，一个subReactor对应一个线程，业务逻辑由线程池处理。业务逻辑还是由线程池来处理。这种模型使各个模块职责单一，降低耦合度，性能和稳定性都有提高 Reactor三种模式形象比喻：餐厅一般有接待员和服务员，接待员负责在门口接待顾客，服务员负责全程服务顾客单Reactor单线程模型：接待员和服务员是同一个人，一直为顾客服务。客流量较少适合 单Reactor多线程模型：一个接待员，多个服务员。客流量大，一个人忙不过来，由专门的接待员在门口接待顾客，然后安排好桌子后，由一个服务员一直服务，一般每个服务员负责一片中的几张桌子 多Reactor多线程模型：多个接待员，多个服务员。这种就是客流量太大了，一个接待员忙不过来了 推拉模式：Producer 与 Broker 是推方式; 推拉模式 指 Comsumer 和 Broker 之间的交互 拉模式的优点：1.消费者可以根据自身的情况来发起 拉取消息的请求, 假设当前消费者觉得自己消费不过来，可以根据一定的策略停止拉取，或者间隔拉取2.Broker 只管存生产者发来的消息，消费者主动发起，来一个请求就给它消息，从哪开始拿消息，拿多 少消费者都告诉它3.适合进行 消息批量发送，拉模式可以参考消费者请求的信息来 决定缓存多少消息之后批量发送; 拉模式的缺点：1.消息延迟，消费者去拉取消息，但消费者不知道消息到了没，它只能不断地拉取，但又不能很频繁地请求，太频繁就变成消费者在攻击 Broker , 因此需要降低请求频率，比如隔个 2 秒请求一次.2.消息忙请求，比如消息隔了几个小时才有，那么在几个小时之内消费者的 请求都是无效的，在做无用功 Kafka 是拉模式，业界基于推模式的消息队列 ActiveMQ Kafka 应对拉模式缺点：Kafka 中的长轮询：消费者 和 Broker 相互配合，拉取消息请求不满足条件的时候 hold 住，避免多次频繁的拉取动作，当消息一到就提醒返回；拉请求可以设置参数，使消费者在 “长轮询” 中阻塞等待；消费者去 Broker 拉消息，定义一个超时时间，如果有马上返回消息，如果没有消费者等着直到超时，然后再次发起拉消息请求。当没有消息时，Broker 建立一个延迟操作，等条件满足再返回。 这个延迟操作需要 检查机制，查看消息是否已经到了，有消息到了之后该执行的方法，执行完毕后进行什么操作的方法，超时后进行什么操作的方法；判断是否过期就是由 时间轮来推动判断的，在消息写入的时候提醒这些延迟请求消息来了。 推模式：消息从 Broker 推向 Consumer，即 Consumer 被动的接收消息，由 Broker 来主导消息的发送 推模式的优点：1.消息实 时性高， Broker 接受完消息之后可以立马推送给 Consumer2.对于 消费者使用来说更简单，有消息来了就会推过来 推模式的缺点：1.推送速率难以适应消费速率，以最快的速度推送消息，当生产者往 Broker 发送消息的速率大于消费者消费消息的速率时，消费者可能消费不过来2.不同消费者的消费速率不一样，身为 Broker 很难平衡每个消费者推送速率3.难以根据消费者的状态控制推送速率，适用于消息量不大，消费能力强，要求实时性高的情况","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"中间件/消息队列","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"Kafka-基础","slug":"C-中间件/消息队列/2.Kafka 消息队列-基础","date":"2021-05-08T13:55:19.000Z","updated":"2022-04-19T13:04:45.437Z","comments":true,"path":"2021/05/08/C-中间件/消息队列/2.Kafka 消息队列-基础/","link":"","permalink":"http://example.com/2021/05/08/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/2.Kafka%20%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Kafka消息队列-基础Kafka消息队列中，队列的名字叫 topic; 多个生产者往同一个队列 topic丢数据，多个消费者往同一个队列(topic)拿数据，为提高一个队列( topic)吞吐量，Kafka把topic进行分区 Partition，生产者往一个发布订阅的topic分区 Partition丢数据，消费者从分区(Partition)中取数据。 每个 topic下，可能有多个 partition分区: Topic 可以有多个分区，分区是最小的读取和存储结构， Consumer 是从Topic下的某个分区获得消息，Producer发送消息也是如此，数据发往哪个partition呢？ 写入的时候可以指定 partition，如果有指定，则写入对应的 partition 没有指定partition，但设置了数据key，则会根据key的值 hash出一个partition 没有指定 partition ，也没有指定 key ， 会随机选择一个分区，并尽可能一直使用该分区，待该分区的 batch已满或过了间隔时间，再随机一个分区进行使用 一台 Kafka服务器叫做 Broker，集群就是多台 Kafka服务器；一个 topic会分为多个partition，实际上 partition 会分布在不同的broker中，实现多机均匀负载。例子：往 topic里边存数据，这些数据会分到不同 partition上，这些 partition存在不同的broker上。如果其中一台 broker挂了，会丢失其中 partition上的数据；但 kafka把这些 partition都做了备份。如：现有三个partition，分别存在三台broker上，每个partition都会备份，这些备份散落在不同的broker上 红色块的 partition代表的是主分区，紫色的 partition块代表的是备份分区。生产者，消费者都是与主分区交互；备份分区仅用作于备份不做读写，如果某个Broker挂了，就会选举出其他 Broker的 partition来作为主分区，实现高可用每一个 Partition 其实都是一个文件，收到消息后 Kafka会把数据插入到文件末尾（虚框部分）缺点：没办法删除数据，所以 Kafka 是不会删除数据的，它会把所有的数据都保留下来，每个消费者对每个 Topic都有一个 offset 用来表示读取到了第几条数据， offset 是由对应的消费者维护，会保存到 Zookeeper 里面。 为避免磁盘被撑满，Kakfa 提供两种策略来删除数据：**1.「基于时间」 （默认七天）； ** 2.「基于 Partition 文件大小」 ​ 消息发往一个主题下的某个分区中，例如：某个主题下有 5 个队列，那么这个主题并发度就提高为 5 ，同时可以有 5 个消费者并行消费该主题的消息。消费者都是属于某个消费组的，一条消息会发往多个订阅这个主题的消费组如：两个消费组分别是Group 1 和 Group 2，它们都订阅 Topic-a，此时有一条消息发往 Topic-a，那么这两个消费组都能接收到这条消息。这条消息实际是 写入Topic中的某个分区，消费组中的某个消费者对应消费一个 Topic 的某个分区。每个消费组会有自己的 offset（消费点位）来标识消费到的位置， 在消费点位之前表明已经消费过。 这个offset是 分区级别的，每个消费组都会维护订阅的 Topic下的每个分区的offset。 kafka并发的粒度是 partition， 每个 partition对应一个消费者，多个消费者同时进行消费，以此来提高并发量。 消息轮询：消费者 通过轮询 API(poll) 向 服务器定时请求数据，一旦消费者订阅了主题，轮询就会处理群组协调、分区再均衡、发送心跳和获取数据，使得开发者只需要关注从分区返回的数据，然后进行业务处理。 Kafka的 Consumer Group 是采用Pull 方式来消费消息，每个Consumer 该消费哪个 Partition 的消息需要一套严格的机制来保证。Partition 可以水平无限扩展，随着 Partition 的扩展 Consumer消费的 Partition也会重新分配，这里涉及到 kafka消息消费分配策略，在 Kafka内部存在两种默认的分区分配策略：Range 和RoundRobin，当以下事件发生时，Kafka将会进行一次分区分配：1.同一个 Consumer Group内新增消费者2.订阅的主题新增Partition3.消费者离开当前所属的 Group，包括Shuts Down或Crashes **副本（Replica）： **为更好的做 负载均衡，Kafka 尽量将所有的 Partition均匀分配到整个集群上。部署方式：一个 Topic 的Partition数量大于Broker的数量，为提高Kafka的容错能力，需要将同一个 Partition的 Replica尽量分散到不同的机器。实际上，如果所有的 Replica 都在同一个Broker上，那一旦该 Broker宕机，该 Partition的所有 Replica都无法工作，也就达不到 备份的效果。同时，如果某个Broker宕机，需要保证它上面的负载可以被 均匀的分配到其它幸存的所有Broker上。 持久化：Kafka是将 partition数据写在 磁盘(记录消息日志)，是 追加写入，避免随机 I&#x2F;O 操作，寻址磁盘效率低。持久化时，partition会先缓存一部分, 放在page cache中，等到 足够多数据量&#x2F;等待一定的时间 再批量写入(flush)。消费者实际上也是从partition中取数据。 生产者,消费者 都是可以有多个的，多个消费者可以组成一个消费者组，如果一个消费者消费三个分区，有消费者组就可以 每个消费者去消费一个分区，消费者组中各个消费者并发消费，以此来提高吞吐量。 ​ 如果消费者组中的某个消费者挂了，那么其中有一个消费者就要消费两个 partition；如果只有三个partition，而消费者组有4个消费者，那么一个消费者会空闲。消费者组之间从逻辑上是独立的，如果多加入一个消费者组，无论是新增的消费者组还是原本的消费者组，都能消费topic的全部数据；​ 生产者往 topic里丢数据是存在partition上，而 partition持久化到磁盘是 IO顺序访问，并且是先写缓存，隔一段时间或者数据量足够大的时候才批量写入磁盘的。正常的读磁盘数据是需要将 内核态数据拷贝到用户态的，Kafka通过零拷贝方式，直接从内核空间（DMA）到内核空间-Socket buffer，少做了一半拷贝操作。 ​ offset 表示消费者的消费进度，每个消费者都有自己的 offset; 每次消费者消费的时候，都会提交这个offset。一个消费者组中的某个消费者挂了，但其所在分区可能有存活的消费者，存活的消费者继续去消费，但需要知道挂掉的消费者具体消费到了哪里，这里就需要offset。 Kafka 利用二分法来查找对应 offset 的消息位置： 按照二分法找到小于 offset的 segment 的.log 和.index 用目标 offset 减去文件名中的 offset得到消息在这个 segment 中的偏移量 再次用二分法在 index 文件中找到对应的索引 到 log 文件中，顺序查找，直到找到 offset 对应的消息 Kafka是分布式：往一个 topic丢数据实际上就是 往多个 broker的 partition存储数据，将 partition以消息日志的方式存储起来，通过 顺序访问IO和缓存(等到一定的量或时间) 才真正把数据写到磁盘上，以此来做持久化。单个 partition写入是有顺序的，要保证全局有序 只能写入一个partition； 要消费有序则消费者也只能有一个分布式无法避免 网络抖动&#x2F;机器宕机 等问题的发生，很有可能 消费者A读取数据，还没来得及消费就挂了。Zookeeper 发现消费者A挂了，让消费者B 去消费原本A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了(或消费者超时等等都有可能…)如果 业务上 不允许重复消费，最好 消费者那端做业务上的校验（如果已经消费过就不消费了） Kafka 和 其他消息队列的区别？ Kafka设计目标：高吞吐量 1、Kafka操作 序列文件 I &#x2F; O（序列文件 按顺序写，按顺序读），为保证顺序，强制点对点的按顺序传递消息，一个 consumer在分区 中只有一个位置。2、Kafka 不保存消息状态（消息是否被“消费”）一般消息系统需保存消息的状态，并且还需要以随机访问的形式更新消息的状态。而Kafka 保存Consumer在 Topic分区中的位置 offset，offset之前的消息是已“消费”的， offset之后为“未消费”的，offset 可以任意移动，以此消除随机IO。3、Kafka支持 点对点的 批量消息传递4、Kafka 消息存储在 page cache（大小为一页4K ）用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问 如何保证不丢失消息？生产者 ACK机制：Kafka 采用至少一次保证消息不会丢，但可能会重复传输；acks 的默认值即为1，代表消息被 leader 接收之后才算成功发送，可以配置 acks &#x3D; all 代表所有副本都接收到该消息之后，才算真正成功发送。 设置分区：为保证 leader 可以根据follower 同步消息，一般会为 topic设置 replication.factor &gt;&#x3D; 3；这样就可以保证每个分区(partition) 至少有 3个副本，以确保消息队列的安全性；单机情况下，通过持久化到磁盘来保证消息不丢失 。 发送消息：Kafka 支持在生产者一侧进行 本地 buffer，累积一定条数才发送，如果这里设置不当会丢消息的。生产者端设置：producer.type&#x3D;async, 默认是 sync；当设置为 async，会大幅提升性能，因为生产者会在本地缓冲消息，并适时批量发送； 如果对可靠性要求高，设置为 sync 同步发送 ；一般需要设置：min.insync.replicas&gt; 1 ，消息至少要被 写入到这么多 follower 才算成功，也是提升数据持久性的一个参数，与acks配合使用。但如果出现两者相等，还需要设置 replication.factor &#x3D; min.insync.replicas + 1 ，避免一个副本挂掉，整个分区无法工作的情况！ 消费者端：消息处理完成前提交offset，可能造成数据的丢失， Consumer默认自动提交 offset(位移)，在后台提交位移前一定要保证消息被正常处理。 如果处理耗时很长，建议把逻辑放到另一个线程中去做，异步提交ack 会提高消费者的响应速度，但容易造成消息丢失。为避免消息丢失，设置 enable.auto.commit&#x3D;false，关闭自动提交位移，在消息被完整处理之后再手动提交位移。 参考：Kafka总结–https://my.oschina.net/u/4377703/blog/4325442","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"中间件/消息队列","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"消息队列-基础","slug":"C-中间件/消息队列/1.消息队列（MQ）简介","date":"2021-05-07T13:55:19.000Z","updated":"2022-04-19T13:04:40.940Z","comments":true,"path":"2021/05/07/C-中间件/消息队列/1.消息队列（MQ）简介/","link":"","permalink":"http://example.com/2021/05/07/C-%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89%E7%AE%80%E4%BB%8B/","excerpt":"","text":"消息队列（MQ）简介生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息；因为消息的生产，消费都是异步的，只关心消息的发送和接收，没有业务逻辑的侵入，这样就实现了生产者和消费者的解耦。 主要作用：作用： 异步，解耦，削峰缺点： 可用性降低，增加系统复杂性（重复消费，消息丢失，消息的顺序消费），数据一致性问题1.系统可用性降低： 加个 MQ 进来，万一 MQ 挂了，整套系统崩溃2.系统复杂度提高： 怎么保证消息没有重复消费？怎么 处理消息丢失的情况？怎么保证消息传递的顺序性？3.数据一致性问题： A 系统处理完直接返回成功，别人以为你这个请求就成功了；但问题是，如果有ABC 三个系统，AB两个系统写库成功，结果 C 系统写库失败，会导致数据不一致。 异步： 解耦： 削峰： 事务一致性，分布式事务：把下单，优惠券，积分 都放在 一个事务里面，要成功一起成功，要失败一起失败 可用性：重试机制，下游的业务发生异常，会抛出异常并且要求重新发一次 接口幂等：分场景去考虑，强校验、弱校验，如跟金钱相关场景就做强校验。强校验：多个操作放在一个事务里，成功一起成功，失败一起失败。 每次消息过来都根据订单号+业务场景 唯一标识去流水表查，确认有没有这条流水，有就直接return； 没有则执行后面逻辑 。弱校验：一些不重要的场景，把 id+场景唯一标识 作为Redis的key，放到缓存里面（失效时间看场景），一定时间内的这个消息就去 Redis判断。 消息不丢失： 生产消息：生产者发送消息至 Broker，需要处理 Broker的响应 ack，如果 Broker返回写入失败，需要重试发送，当多次发送失败，需要作报警，日志记录等。存储消息：存储消息阶段需要在 消息刷盘之后再给生产者响应，假设消息写入缓存中就返回响应，那么机器突然断电这消息就没了，而生产者以为已经发送成功了。如果Broker是集群部署，有多副本机制，即消息不仅要写入当前Broker,还需要 写入副本机中。那配置成至少写入两台机子后再给生产者响应。这样就能保证存储的可靠了。消费消息： 消费者执行完业务逻辑之后，再发送给 Broker消费成功ack 总结：1.生产者 需要处理好 Broker的响应，出错情况下利用 重试、报警等手段。2.Broker 需要控制响应的时机，单机：消息刷盘后返回响应； 集群多副本：发送至两个副本及以上后再返回响应3.消费者需要在 执行完真正的业务逻辑之后再返回响应给Broker。但要注意 消息可靠性增强，性能就下降了，等待消息刷盘，多副本同步后返回都会影响性能。例如日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应。 处理重复消息：收到消息后 Broker已经写入，当时响应由于网络原因，生产者没有收到，然后生产者又重发一次，此时消息就重复了解决消息重复关键点就是 幂等：在业务上处理重复消息所带来的影响。 解决方法：1.记录关键key，比如订单ID，假如有重复消息过来，先判断这个ID是否已经被处理过（也可以用全局唯一ID）2.数据库的约束，唯一键 有序性：保证消息有序性：全局有序，部分有序； 消费方都不要开启并行消费 全局有序：一个生产者，一个队列分区，一个消费者保证消息的全局有序，只能由一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区），消费者也必须是单线程消费这个队列。这样才能全局有序！ 不过一般情况下不需要全局有序，参照局部有序的方式，生产者通过指定 partKey的方式将消息发送到某一个集群的某一个 partition，以实现消息的全局有序。 部分有序：将 Topic 内部划分成需要的队列数，把消息通过特定的策略 发往固定的队列中，然后 每个队列对应一个单线程处理的消费者。这样即完成部分有序的需求，又可以通过 队列数量的并发 来提高消息处理效率。 使用Hash取模法，让同一个订单发送到同一个队列中，同一个订单多步操作同步进行；顺序消费由消费者业务保证!!! 处理消息堆积：1.生产者的生产速度与 消费者的消费速度不匹配2.消息 消费失败反复重试3.消费者 消费能力弱，时间长消息积压本身消费能力较弱，优化消费逻辑，尝试批量消费，逻辑已优化了但还是慢，考虑水平扩容，增加Topic的队列数和消费者数量， 队列数一定增加，不然新增加消费者是没东西消费的。一个 Topic中一个队列只会分配给一个消费者。 实现MQ的有两种主流方式：JMS，AMQP两者间的区别和联系：1.JMS 定义了统一的接口，来对消息操作进行统一； AMQP 通过规定协议来统一数据交互的格式2.JMS限定了必须使用 Java语言； AMQP只是协议，不规定实现方式，因此是跨语言的。3.JMS规定了两种消息模型；而 AMQP的消息模型更加丰富 MQ： 消息队列AMQP： 协议： 实现方式：任何语言JMS： jdk标准 java 只支持两种数据模型，rocketMQ， activeMQ常见MQ产品： ActiveMQ：基于JMSRabbitMQ：基于AMQP协议，erlang语言开发，稳定性好RocketMQ：基于JMS，阿里巴巴产品，目前交由Apache基金会Kafka：分布式消息系统，高吞吐量 Kafka、ActiveMQ、RabbitMQ、RocketMQ 区别：","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"消息队列","slug":"中间件/消息队列","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}],"categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://example.com/categories/LeetCode/"},{"name":"排序","slug":"LeetCode/排序","permalink":"http://example.com/categories/LeetCode/%E6%8E%92%E5%BA%8F/"},{"name":"动态规划","slug":"LeetCode/动态规划","permalink":"http://example.com/categories/LeetCode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"滑动窗口","slug":"LeetCode/滑动窗口","permalink":"http://example.com/categories/LeetCode/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"递归","slug":"LeetCode/递归","permalink":"http://example.com/categories/LeetCode/%E9%80%92%E5%BD%92/"},{"name":"随笔","slug":"随笔","permalink":"http://example.com/categories/%E9%9A%8F%E7%AC%94/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Mysql","slug":"数据库/Mysql","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql/"},{"name":"网络","slug":"网络","permalink":"http://example.com/categories/%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Redis","slug":"中间件/Redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Redis/"},{"name":"Java语言","slug":"Java语言","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/"},{"name":"多线程","slug":"Java语言/多线程","permalink":"http://example.com/categories/Java%E8%AF%AD%E8%A8%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"消息队列","slug":"中间件/消息队列","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://example.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"动态规划","slug":"动态规划","permalink":"http://example.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://example.com/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"递归","slug":"递归","permalink":"http://example.com/tags/%E9%80%92%E5%BD%92/"},{"name":"随笔","slug":"随笔","permalink":"http://example.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"},{"name":"网络","slug":"网络","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"消息队列","slug":"消息队列","permalink":"http://example.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]}